{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "residuals_as_output.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oT0bzHJTn2Ew"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owsdW-Kynwnh"
      },
      "source": [
        "# Install (important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHrRQCrcEgJv",
        "outputId": "3f189d63-b408-4146-f84a-8d9878c00d29"
      },
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 1121, done.\u001b[K\n",
            "remote: Counting objects: 100% (417/417), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 1121 (delta 247), reused 398 (delta 238), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (1121/1121), 8.29 MiB | 37.39 MiB/s, done.\n",
            "Resolving deltas: 100% (673/673), done.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT0bzHJTn2Ew"
      },
      "source": [
        "# LatentODE on residuals\n",
        "\n",
        "d1d2d3d4d5d6d7 as input, m1m2m3m4m5m6m7m8m9m10 as output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEE7mP36oEo_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWmEfCVLn18T"
      },
      "source": [
        "# Rough"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQFKP1KWoCYK"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "from pandas import concat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "from torchdiffeq.torchdiffeq import odeint\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dict_tickers = {\n",
        "    'Apple': 'AAPL',\n",
        "    'Microsoft': 'MSFT',\n",
        "    'Google': 'GOOG',\n",
        "    'Bitcoin': 'BTC-USD',\n",
        "    'Facebook': 'FB',\n",
        "    'Walmart': 'WMT',\n",
        "    'Amazon': 'AMZN',\n",
        "    'CVS': 'CVS',\n",
        "    'Berkshire': 'BRK-B',\n",
        "    'ExxonMobil': 'XOM',\n",
        "    'AtandT': 'T',\n",
        "    'Costco': 'COST',\n",
        "    'Walgreens': 'WBA',\n",
        "    'Kroger': 'KR',\n",
        "    'JPMorgan': 'JPM',\n",
        "    'Verizon': 'VZ',\n",
        "    'FordMotor': 'F',\n",
        "    'GeneralMotors': 'GM',\n",
        "    'Dell': 'DELL',\n",
        "    'BankOfAmerica': 'BAC',\n",
        "    'Target': 'TGT',\n",
        "    'GeneralElectric': 'GE',\n",
        "    'JohnsonandJohnson': 'JNJ',\n",
        "    'Nvidia': 'NVDA',\n",
        "    'Intel': 'INTC',\n",
        "}\n",
        "\n",
        "def stockDataTransformer(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    df.set_index('Date', inplace=True)\n",
        "    df1 = df[['Open', 'Close']].copy()\n",
        "    data = df1.values\n",
        "    n_samples = data.shape[0]//10*10\n",
        "    reshape_number = n_samples*data.shape[1]//10\n",
        "    data1 = data[:n_samples].reshape((reshape_number, 10))\n",
        "    return data1\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \"\"\"\n",
        "    Frame a time series as a supervised learning dataset.\n",
        "    Arguments:\n",
        "        data: Sequence of observations as a list or NumPy array.\n",
        "        n_in: Number of lag observations as input (X).\n",
        "        n_out: Number of observations as output (y).\n",
        "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
        "    Returns:\n",
        "        Pandas DataFrame of series framed for supervised learning.\n",
        "    \"\"\"\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "def get_median(array, axis = 1):\n",
        "    # https://numpy.org/doc/stable/reference/generated/numpy.median.html\n",
        "    return np.median(array, axis = axis).reshape(len(array), 1)  #, keepdims=True)\n",
        "\n",
        "def get_residuals(data):\n",
        "    c5 = data[:-1, -1].reshape((data_size-1, 1))\n",
        "    residual_data = data[1:] - c5\n",
        "    return residual_data\n",
        "\n",
        "def split_data(perc_train, perc_valid, lag, data_orig, data_m1, n_features_orig, n_features_median):\n",
        "    values = data_m1\n",
        "    \n",
        "    sizeOfReframed = len(data_m1)\n",
        "    len_train = int(perc_train*sizeOfReframed) # int(sizeOfReframed - len_test) # - len_valid)\n",
        "    train_data_orig = data_orig[:len_train, :]\n",
        "    # valid = values[len_train:len_valid+len_train, :]\n",
        "    test_data_orig = data_orig[len_train:, :]  # [len_valid+len_train:, :]\n",
        "    # n_features = n_features\n",
        "    \n",
        "    train_data_ml = values[:len_train, :]\n",
        "    test_data_ml = values[len_train:, :] \n",
        "    # split into input and outputs\n",
        "    n_obs = lag * n_features_orig\n",
        "    n_obs_median = (lag+forecast) * n_features_median\n",
        "    train_X, train_y = train_data_orig[:, :n_obs], train_data_ml[:, :n_obs_median]\n",
        "    test_X, test_y = test_data_orig[:, :n_obs], test_data_ml[:, :n_obs_median]\n",
        "    # valid_X, valid_y = valid[:, :n_obs], valid[:, -1]\n",
        "    print(train_X.shape, len(train_X), train_y.shape)\n",
        "    \n",
        "    # reshape input to be 3D [samples, features, lag]\n",
        "    train_X = train_X.reshape((train_X.shape[0], n_features_orig, lag))\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_features_orig, lag))\n",
        "    # valid_X = valid_X.reshape((valid_X.shape[0], lag, n_features))\n",
        "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)  # , valid_X.shape, valid_y.shape)\n",
        "    \n",
        "    # Get the reconstruction train_y, test_y and extrapolated train_y, test_y\n",
        "    train_y_recon, train_y_extrapol = train_y[:, :lag], train_y[:, lag:]\n",
        "    test_y_recon, test_y_extrapol = test_y[:, :lag], test_y[:, lag:]\n",
        "    dataload = {\n",
        "        'train_data_orig': train_data_orig,\n",
        "        'test_data_orig': test_data_orig,\n",
        "        'train_data_ml': train_data_ml,\n",
        "        'test_data_ml': test_data_ml,\n",
        "        # 'valid': valid,\n",
        "        'train_X': train_X,\n",
        "        'train_y': train_y,\n",
        "        'test_X': test_X,\n",
        "        'test_y': test_y,\n",
        "        'n_features_orig': n_features_orig,\n",
        "        'n_features_median': n_features_median,\n",
        "        'n_obs': n_obs,\n",
        "        'n_obs_median': n_obs_median,\n",
        "        # 'valid_X': valid_X,\n",
        "        # 'valid_y': valid_y,\n",
        "        'train_y_recon': train_y_recon,\n",
        "        'train_y_extrapol': train_y_extrapol,\n",
        "        'test_y_recon': test_y_recon,\n",
        "        'test_y_extrapol': test_y_extrapol\n",
        "    }\n",
        "    \n",
        "    return dataload\n",
        "\n",
        "# https://discuss.pytorch.org/t/rmse-loss-function/16540/3\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss\n",
        "class LatentODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=4, nhidden=20):\n",
        "        super(LatentODEfunc, self).__init__()\n",
        "        self.elu = nn.ELU(inplace=True)\n",
        "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
        "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
        "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.fc1(x).to(device)\n",
        "        out = self.elu(out).to(device)\n",
        "        out = self.fc2(out).to(device)\n",
        "        out = self.elu(out).to(device)\n",
        "        out = self.fc3(out).to(device)\n",
        "        return out\n",
        "\n",
        "class RecognitionRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=4, obs_dim=5, nhidden=25, nbatch=1):\n",
        "        super(RecognitionRNN, self).__init__()\n",
        "        self.nhidden = nhidden\n",
        "        self.nbatch = nbatch\n",
        "        self.i2h = nn.Linear(obs_dim + nhidden, nhidden)\n",
        "        self.i2h = self.i2h.float()\n",
        "        self.h2o = nn.Linear(nhidden, latent_dim * 2)\n",
        "        self.h2o = self.h2o.float()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        combined = torch.cat((x, h), dim=1).to(device)\n",
        "        h = torch.tanh(self.i2h(combined.float())).to(device)\n",
        "        out = self.h2o(h).to(device)\n",
        "        return out, h\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.nbatch, self.nhidden)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=4, obs_dim=5, nhidden=20):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
        "        self.fc2 = nn.Linear(nhidden, obs_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.fc1(z).to(device)\n",
        "        out = self.relu(out).to(device)\n",
        "        out = self.fc2(out).to(device)\n",
        "        return out\n",
        "\n",
        "class RunningAverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = None\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        if self.val is None:\n",
        "            self.avg = val\n",
        "        else:\n",
        "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
        "        self.val = val\n",
        "\n",
        "\n",
        "def log_normal_pdf(x, mean, logvar):\n",
        "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device).to(device)\n",
        "    const = torch.log(const).to(device)\n",
        "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
        "\n",
        "def normal_kl(mu1, lv1, mu2, lv2):\n",
        "    v1 = torch.exp(lv1)\n",
        "    v2 = torch.exp(lv2)\n",
        "    lstd1 = lv1 / 2.\n",
        "    lstd2 = lv2 / 2.\n",
        "\n",
        "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
        "    return kl.to(device)\n",
        "\n",
        "def train(loss_str, niters):\n",
        "    loss_list = []\n",
        "    for itr in range(1, niters + 1):\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "        # backward in time to infer q(z_0)\n",
        "        h = rec.initHidden().to(device)  # (# nbatches_train, rnn_hidden)\n",
        "        for t_r in reversed(range(train_X.shape[2])):  # input_dimension\n",
        "            obs = train_X[:, :, t_r].to(device)\n",
        "            # obs = torch.reshape(obs, (1, 1)).to(device)\n",
        "            out, h = rec.forward(obs, h)\n",
        "        qz0_mean, qz0_logvar = out[:, :latent_dim].to(device), out[:, latent_dim:].to(device)\n",
        "        epsilon = torch.randn(qz0_mean.size()).to(device)\n",
        "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
        "\n",
        "        # forward in time and solve ode for reconstructions\n",
        "        pred_z = odeint(func, z0, t.to(device)).permute(1, 0, 2)  # [:, -1, :]\n",
        "        pred_x = dec(pred_z).to(device)\n",
        "        pred_x = torch.reshape(pred_x, (train_X.shape[0], lag+forecast)).to(device)\n",
        "\n",
        "        # compute loss\n",
        "        if loss_str == 'mse':\n",
        "            loss = torch.nn.MSELoss()(pred_x.float(), train_X[i, :, :].float().to(device)).float()\n",
        "        elif loss_str == 'elbo':\n",
        "            noise_std_ = torch.zeros(pred_x.size()).to(device) + noise_std\n",
        "            noise_logvar = 2. * torch.log(noise_std_).to(device)\n",
        "            logpx = log_normal_pdf(\n",
        "                train_y[:, 0, :].to(device), pred_x, noise_logvar).sum(-1)  # .sum(-1)\n",
        "            pz0_mean = pz0_logvar = torch.zeros(z0.size()).to(device)\n",
        "            analytic_kl = normal_kl(qz0_mean, qz0_logvar,\n",
        "                                    pz0_mean, pz0_logvar).sum(-1)\n",
        "            loss = torch.mean(-logpx + analytic_kl, dim=0).to(device)\n",
        "            # loss = torch.reshape(loss, (1, 1)).to(device)\n",
        "        loss_list.append(loss)\n",
        "            # loss_ = torch.mean(torch.cat([x.float() for x in loss_list])).to(device)  \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # loss_meter.update(loss.item())\n",
        "        if itr%10==0:\n",
        "            print('Iter: {}, running: {:.4f}'.format(itr, loss.item()))\n",
        "    return loss_list\n",
        "\n",
        "def train_loss(h):\n",
        "    train_loss = 0.0\n",
        "    predictions = []\n",
        "    \n",
        "    for t_r in reversed(range(train_X.shape[2])):\n",
        "        obs = train_X[:, :, t_r].to(device)\n",
        "        # obs = torch.reshape(obs, (1, 1)).to(device)\n",
        "        out, h = rec.forward(obs, h)\n",
        "\n",
        "    qz0_mean, qz0_logvar = out[:, :latent_dim].to(device), out[:, latent_dim:].to(device)\n",
        "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
        "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
        "\n",
        "    # forward in time and solve ode for reconstructions\n",
        "    pred_z = odeint(func, z0, t.to(device)).permute(1, 0, 2)\n",
        "    pred_x = dec(pred_z).to(device)\n",
        "    pred_x = torch.reshape(pred_x, (pred_x.shape[0], 1, lag+forecast))\n",
        "    pred_x_recon = pred_x[:, :, :lag]\n",
        "    pred_x_extrapol = pred_x[:, :, lag:]\n",
        "    rmse = RMSELoss()\n",
        "    # loss = torch.nn.MSELoss()(pred_x, train_X[:, :, :].to(device))\n",
        "    loss_recon = rmse(pred_x_recon, train_y_recon)\n",
        "    loss_extrapol = rmse(pred_x_extrapol, train_y_extrapol)\n",
        "    # train_loss += loss\n",
        "    # predictions.append(pred_x)\n",
        "    \n",
        "    # train_loss = torch.sqrt(train_loss)\n",
        "    # train_pred = torch.cat([x.float() for x in predictions])\n",
        "    # train_pred = torch.reshape(train_pred, (train_pred.shape[0], 1, lag))\n",
        "    with torch.no_grad():\n",
        "        print('Train: Reconstruction Loss')\n",
        "        print('Total Train Loss {:.6f}'.format(loss_recon.item()))\n",
        "        print('Train: Extrapolation Loss')\n",
        "        print('Total Train Extrapolation Loss {:.6f}'.format(loss_extrapol.item()))\n",
        "    return pred_x, pred_x_recon, pred_x_extrapol\n",
        "\n",
        "def test_loss(h, t_test):\n",
        "    # print(h.shape)\n",
        "    test_loss = 0.0\n",
        "    predictions = []\n",
        "    rmse = RMSELoss()\n",
        "    for t_r in reversed(range(test_X.shape[2])):\n",
        "        obs = test_X[:, :, t_r].to(device)\n",
        "        # obs = torch.reshape(obs, (1, 1)).to(device)\n",
        "        out, h = rec.forward(obs, h)\n",
        "    qz0_mean, qz0_logvar = out[:, :latent_dim].to(device), out[:, latent_dim:].to(device)\n",
        "    epsilon = torch.randn(qz0_mean.size()).to(device)\n",
        "    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
        "\n",
        "    # forward in time and solve ode for reconstructions\n",
        "    pred_z = odeint(func, z0, t_test).permute(1, 0, 2).to(device)\n",
        "    pred_x = dec(pred_z).to(device)\n",
        "    pred_x = torch.reshape(pred_x, (pred_x.shape[0], 1, lag+forecast))\n",
        "    pred_x_recon = pred_x[:, :, :lag]\n",
        "    pred_x_extrapol = pred_x[:, :, lag:]\n",
        "    # pred_test_X = torch.reshape(pred_test_X, (pred_test_X.shape[0], pred_test_X.shape[1]))\n",
        "    # pred_test_y = torch.reshape(pred_test_y, (1, pred_test_y.shape[0], 1, lag))\n",
        "    # print(test_pred_y.shape)\n",
        "    rmse = RMSELoss()\n",
        "    # loss = torch.nn.MSELoss()(pred_x, train_X[i, :, :].to(device))\n",
        "    loss_recon = rmse(pred_x_recon, test_y_recon)\n",
        "    loss_extrapol = rmse(pred_x_extrapol, test_y_extrapol)\n",
        "\n",
        "    # loss = torch.nn.MSELoss()(pred_x, torch.reshape(test_X[i, :, :].to(device), (1, 5))).to(device)\n",
        "    # test_loss += loss\n",
        "    # predictions.append(pred_x)\n",
        "    \n",
        "    # test_loss = torch.sqrt(test_loss)\n",
        "    # test_pred = torch.cat([x.float() for x in predictions])\n",
        "    \n",
        "    # loss = torch.nn.MSELoss()(test_pred_y[train_size-test_size:, batch_time2-2, :], label_batch_y[train_size-test_size:, batch_time2-2, :])\n",
        "    with torch.no_grad():\n",
        "        print('Test: Reconstruction Loss')\n",
        "        print('Total Loss {:.6f}'.format(loss_recon.item()))\n",
        "        print('Test: Extrapolation Loss')\n",
        "        print('Total Loss {:.6f}'.format(loss_extrapol.item()))\n",
        "    return pred_x, pred_x_recon, pred_x_extrapol\n",
        "\n",
        "def plot_train_recon(i, train_y_recon, pred_y_recon, fig, axes):\n",
        "    t_ = torch.linspace(1., train_y_recon.shape[0], train_y_recon.shape[0])\n",
        "    plt.figure()\n",
        "    plt.plot(t_.numpy(), train_y_recon.cpu().numpy()[:, :, i-1], 'g', label = f\"orig_week{i}\")\n",
        "    with torch.no_grad():\n",
        "        rmse = np.sqrt(((train_y_recon.cpu().numpy()[:, :, i-1] - pred_y_recon.cpu().numpy()[:, :, i-1]) ** 2).mean())\n",
        "        plt.plot(t_.numpy(), pred_y_recon.cpu().numpy()[:, :, i-1], '--', label = f\"recon_week{i}\")\n",
        "    plt.title(f\"Trial No. {trial}: Train Recon: {tickerName}'s Median Stock price for week{i}: RMSE {rmse}\")\n",
        "    plt.legend(framealpha=1, frameon=True);\n",
        "    plt.savefig(f\"plots-latentode/Trial No. {trial}: Train Recon: {tickerName}'s Median Stock price for week{i}.pdf\", dpi = 150)\n",
        "    plt.show()\n",
        "\n",
        "def plot_train_extrapol(i, train_y_extrapol, pred_y_extrapol, fig, axes):\n",
        "    t_ = torch.linspace(1., train_y_extrapol.shape[0], train_y_extrapol.shape[0])\n",
        "    plt.figure()\n",
        "    plt.plot(t_.numpy(), train_y_extrapol.cpu().numpy()[:, :, i-1-lag], 'g', label = f\"orig_week{i}\")\n",
        "    with torch.no_grad():\n",
        "        rmse = np.sqrt(((train_y_extrapol.cpu().numpy()[:, :, i-1-lag] - pred_y_extrapol.cpu().numpy()[:, :, i-1-lag]) ** 2).mean())\n",
        "        plt.plot(t_.numpy(), pred_y_extrapol.cpu().numpy()[:, :, i-1-lag], '--', label = f\"extrapol_week{i}\")\n",
        "    plt.title(f\"Trial No. {trial}: Train Extrapol: {tickerName}'s Median Stock price for week{i}: RMSE {rmse}\")\n",
        "    plt.legend(framealpha=1, frameon=True);\n",
        "    plt.savefig(f\"plots-latentode/Trial No. {trial}: Train Extrapol: {tickerName}'s Median Stock price for week{i}.pdf\", dpi = 150)\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_recon(i, test_y_recon, pred_y_recon, fig, axes):\n",
        "    t_ = torch.linspace(1., test_y_recon.shape[0], test_y_recon.shape[0])\n",
        "    plt.figure()\n",
        "    plt.plot(t_.numpy(), test_y_recon.cpu().numpy()[:, :, i-1], 'g', label = f\"orig_week{i}\")\n",
        "    with torch.no_grad():\n",
        "        rmse = np.sqrt(((test_y_recon.cpu().numpy()[:, :, i-1] - pred_y_recon.cpu().numpy()[:, :, i-1]) ** 2).mean())\n",
        "        plt.plot(t_.numpy(), pred_y_recon.cpu().numpy()[:, :, i-1], '--', label = f\"recon_week{i} : RMSE {rmse}\")\n",
        "    plt.title(f\"Trial No. {trial}: Test Recon: {tickerName}'s Median Stock price for week{i}: RMSE {rmse}\")\n",
        "    plt.legend(framealpha=1, frameon=True);\n",
        "    plt.savefig(f\"plots-latentode/Trial No. {trial}: Test Recon: {tickerName}'s Median Stock price for week{i}.pdf\", dpi = 150)\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_extrapol(i, test_y_extrapol, pred_y_extrapol, fig, axes):\n",
        "    t_ = torch.linspace(1., test_y_extrapol.shape[0], test_y_extrapol.shape[0])\n",
        "    plt.figure()\n",
        "    plt.plot(t_.numpy(), test_y_extrapol.cpu().numpy()[:, :, i-1-lag], 'g', label = f\"orig_week{i}\")\n",
        "    with torch.no_grad():\n",
        "        rmse = np.sqrt(((test_y_extrapol.cpu().numpy()[:, :, i-1-lag] - pred_y_extrapol.cpu().numpy()[:, :, i-1-lag]) ** 2).mean())\n",
        "        plt.plot(t_.numpy(), pred_y_extrapol.cpu().numpy()[:, :, i-1-lag], '--', label = f\"extrapol_week{i} : RMSE {rmse}\")\n",
        "    plt.title(f\"Trial No. {trial}: Test Extrapol: {tickerName}'s  Median Stock price for week{i}: RMSE {rmse}\")\n",
        "    plt.legend(framealpha=1, frameon=True);\n",
        "    plt.savefig(f\"plots-latentode/Trial No. {trial}: Test Extrapol: {tickerName}'s  Median Stock price for week{i}.pdf\", dpi = 150)\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss(loss_list):\n",
        "    plt.plot(loss_list)\n",
        "    plt.title(f'{tickerName}: Train Loss (Recon+Extrapol')\n",
        "    plt.ylabel('ELBO Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.savefig(f\"plots-latentode/{tickerName}: Trial No. {trial}: ELBO Train Loss.pdf\", dpi = 150)\n",
        "    plt.show()\n",
        "\n",
        "def rmse_table(recon_rmse_filepath, extrapol_rmse_filepath, train_y_recon, pred_train_recon, train_y_extrapol, pred_train_extrapol, test_y_recon, pred_test_recon, test_y_extrapol, pred_test_extrapol):\n",
        "    recon_rmse_data = {\n",
        "        'week': list(),\n",
        "        'train_recon_rmse': list(),\n",
        "        'test_recon_rmse': list()\n",
        "    }\n",
        "\n",
        "    extrapol_rmse_data = {\n",
        "        'week': list(),\n",
        "        'train_extrapol_rmse': list(),\n",
        "        'test_extrapol_rmse': list()\n",
        "    }\n",
        "    for i in range(1, lag+forecast+1):\n",
        "        with torch.no_grad():\n",
        "            if i<=lag:\n",
        "                recon_rmse_data['week'].append(i)\n",
        "                train_recon_rmse = np.sqrt(((train_y_recon.cpu().numpy()[:, :, i-1] - pred_train_recon.cpu().numpy()[:, :, i-1]) ** 2).mean())\n",
        "                recon_rmse_data['train_recon_rmse'].append(train_recon_rmse)\n",
        "                test_recon_rmse = np.sqrt(((test_y_recon.cpu().numpy()[:, :, i-1] - pred_test_recon.cpu().numpy()[:, :, i-1]) ** 2).mean())\n",
        "                recon_rmse_data['test_recon_rmse'].append(test_recon_rmse)\n",
        "            elif i>lag:\n",
        "                extrapol_rmse_data['week'].append(i)\n",
        "                train_extrapol_rmse = np.sqrt(((train_y_extrapol.cpu().numpy()[:, :, i-1-lag] - pred_train_extrapol.cpu().numpy()[:, :, i-1-lag]) ** 2).mean())\n",
        "                extrapol_rmse_data['train_extrapol_rmse'].append(train_extrapol_rmse)\n",
        "                test_extrapol_rmse = np.sqrt(((test_y_extrapol.cpu().numpy()[:, :, i-1-lag] - pred_test_extrapol.cpu().numpy()[:, :, i-1-lag]) ** 2).mean())\n",
        "                extrapol_rmse_data['test_extrapol_rmse'].append(test_extrapol_rmse)\n",
        "    recon_rmse_df = pd.DataFrame(recon_rmse_data)\n",
        "    recon_rmse_df.to_csv(recon_rmse_filepath)\n",
        "    extrapol_rmse_df = pd.DataFrame(extrapol_rmse_data)\n",
        "    extrapol_rmse_df.to_csv(extrapol_rmse_filepath)\n",
        "\n",
        "    return recon_rmse_data, extrapol_rmse_data\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoI8L26qC3z",
        "outputId": "90b06d3e-f777-4a77-8608-f80998383989"
      },
      "source": [
        "# FileName\n",
        "tickerName = 'ExxonMobil'\n",
        "# Filepath\n",
        "filepath = f\"raw-stock-data/{tickerName}.csv\"\n",
        "# Get the data in the required format\n",
        "data = stockDataTransformer(filepath)\n",
        "print('Data after Data Transformation')\n",
        "# # Total Data Size\n",
        "data_size = data.shape[0]\n",
        "\n",
        "print(pd.DataFrame(data))\n",
        "print('\\n')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data after Data Transformation\n",
            "              0          1          2  ...          7          8          9\n",
            "0      0.178288   0.179010   0.179010  ...   0.180453   0.180453   0.180814\n",
            "1      0.180814   0.181536   0.181536  ...   0.179731   0.179731   0.177927\n",
            "2      0.177927   0.178649   0.178649  ...   0.177566   0.177566   0.176483\n",
            "3      0.176483   0.173957   0.173957  ...   0.167821   0.166378   0.164212\n",
            "4      0.163852   0.162769   0.162769  ...   0.164573   0.164573   0.164212\n",
            "...         ...        ...        ...  ...        ...        ...        ...\n",
            "2549  41.166637  40.800957  40.508416  ...  38.853703  39.447934  40.819241\n",
            "2550  40.362144  39.868473  39.676488  ...  40.289005  40.142736  39.813622\n",
            "2551  39.959889  40.252434  39.429652  ...  38.625149  38.707430  39.740482\n",
            "2552  40.362140  40.087875  39.676486  ...  40.691257  41.596317  41.111790\n",
            "2553  41.447394  41.102467  40.552445  ...  39.750713  39.704109  39.554951\n",
            "\n",
            "[2554 rows x 10 columns]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezfm7bBBsC3G",
        "outputId": "8f85489f-b51e-44a1-a522-d3d938752b9c"
      },
      "source": [
        "data[:-1, -1].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2553,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "xtqgZVLtrYuh",
        "outputId": "58006e8a-3b8b-4efe-c151-063806476dc2"
      },
      "source": [
        "pd.DataFrame(data[1:] - data[:-1, -1].reshape((2553, 1)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.633554e-07</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>-0.000722</td>\n",
              "      <td>-0.000722</td>\n",
              "      <td>-0.001444</td>\n",
              "      <td>-1.443646e-03</td>\n",
              "      <td>-0.001083</td>\n",
              "      <td>-0.001083</td>\n",
              "      <td>-0.002887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.975615e-08</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.164857e-08</td>\n",
              "      <td>-0.000361</td>\n",
              "      <td>-0.000361</td>\n",
              "      <td>-0.001444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.464962e-08</td>\n",
              "      <td>-0.002526</td>\n",
              "      <td>-0.002526</td>\n",
              "      <td>-0.002165</td>\n",
              "      <td>-0.002887</td>\n",
              "      <td>-0.003248</td>\n",
              "      <td>-3.248055e-03</td>\n",
              "      <td>-0.008662</td>\n",
              "      <td>-0.010105</td>\n",
              "      <td>-0.012271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.608387e-04</td>\n",
              "      <td>-0.001444</td>\n",
              "      <td>-0.001444</td>\n",
              "      <td>-0.002526</td>\n",
              "      <td>-0.002526</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>7.218651e-04</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.165352e-03</td>\n",
              "      <td>-0.003970</td>\n",
              "      <td>-0.003970</td>\n",
              "      <td>-0.004692</td>\n",
              "      <td>-0.005414</td>\n",
              "      <td>-0.010466</td>\n",
              "      <td>-1.046623e-02</td>\n",
              "      <td>-0.009384</td>\n",
              "      <td>-0.009744</td>\n",
              "      <td>-0.013353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2548</th>\n",
              "      <td>8.776312e-01</td>\n",
              "      <td>0.511951</td>\n",
              "      <td>0.219411</td>\n",
              "      <td>0.191982</td>\n",
              "      <td>0.237692</td>\n",
              "      <td>-0.502815</td>\n",
              "      <td>-7.862182e-01</td>\n",
              "      <td>-1.435303</td>\n",
              "      <td>-0.841072</td>\n",
              "      <td>0.530235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2549</th>\n",
              "      <td>-4.570961e-01</td>\n",
              "      <td>-0.950768</td>\n",
              "      <td>-1.142753</td>\n",
              "      <td>-0.868492</td>\n",
              "      <td>-0.703933</td>\n",
              "      <td>-1.115326</td>\n",
              "      <td>-1.298167e+00</td>\n",
              "      <td>-0.530235</td>\n",
              "      <td>-0.676505</td>\n",
              "      <td>-1.005619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2550</th>\n",
              "      <td>1.462670e-01</td>\n",
              "      <td>0.438812</td>\n",
              "      <td>-0.383970</td>\n",
              "      <td>-1.535870</td>\n",
              "      <td>-2.184950</td>\n",
              "      <td>-1.343880</td>\n",
              "      <td>-1.371314e+00</td>\n",
              "      <td>-1.188473</td>\n",
              "      <td>-1.106192</td>\n",
              "      <td>-0.073139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2551</th>\n",
              "      <td>6.216572e-01</td>\n",
              "      <td>0.347393</td>\n",
              "      <td>-0.063996</td>\n",
              "      <td>0.155411</td>\n",
              "      <td>-0.219414</td>\n",
              "      <td>-0.027431</td>\n",
              "      <td>4.753917e-01</td>\n",
              "      <td>0.950775</td>\n",
              "      <td>1.855835</td>\n",
              "      <td>1.371307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2552</th>\n",
              "      <td>3.356047e-01</td>\n",
              "      <td>-0.009323</td>\n",
              "      <td>-0.559345</td>\n",
              "      <td>-1.016144</td>\n",
              "      <td>-1.398362</td>\n",
              "      <td>-0.839016</td>\n",
              "      <td>-8.669903e-01</td>\n",
              "      <td>-1.361076</td>\n",
              "      <td>-1.407681</td>\n",
              "      <td>-1.556839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2553 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0         1         2  ...         7         8         9\n",
              "0    -1.633554e-07  0.000722  0.000722  ... -0.001083 -0.001083 -0.002887\n",
              "1     2.975615e-08  0.000722  0.000722  ... -0.000361 -0.000361 -0.001444\n",
              "2     5.464962e-08 -0.002526 -0.002526  ... -0.008662 -0.010105 -0.012271\n",
              "3    -3.608387e-04 -0.001444 -0.001444  ...  0.000361  0.000361  0.000000\n",
              "4    -2.165352e-03 -0.003970 -0.003970  ... -0.009384 -0.009744 -0.013353\n",
              "...            ...       ...       ...  ...       ...       ...       ...\n",
              "2548  8.776312e-01  0.511951  0.219411  ... -1.435303 -0.841072  0.530235\n",
              "2549 -4.570961e-01 -0.950768 -1.142753  ... -0.530235 -0.676505 -1.005619\n",
              "2550  1.462670e-01  0.438812 -0.383970  ... -1.188473 -1.106192 -0.073139\n",
              "2551  6.216572e-01  0.347393 -0.063996  ...  0.950775  1.855835  1.371307\n",
              "2552  3.356047e-01 -0.009323 -0.559345  ... -1.361076 -1.407681 -1.556839\n",
              "\n",
              "[2553 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrBQ9QQ5si7l",
        "outputId": "b480f9f8-7b1d-4618-9546-881d9fa00f1e"
      },
      "source": [
        "print('Get Residuals')\n",
        "residual_data = get_residuals(data)\n",
        "print(pd.DataFrame(residual_data))\n",
        "print('\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get Residuals\n",
            "                 0         1         2  ...         7         8         9\n",
            "0    -1.633554e-07  0.000722  0.000722  ... -0.001083 -0.001083 -0.002887\n",
            "1     2.975615e-08  0.000722  0.000722  ... -0.000361 -0.000361 -0.001444\n",
            "2     5.464962e-08 -0.002526 -0.002526  ... -0.008662 -0.010105 -0.012271\n",
            "3    -3.608387e-04 -0.001444 -0.001444  ...  0.000361  0.000361  0.000000\n",
            "4    -2.165352e-03 -0.003970 -0.003970  ... -0.009384 -0.009744 -0.013353\n",
            "...            ...       ...       ...  ...       ...       ...       ...\n",
            "2548  8.776312e-01  0.511951  0.219411  ... -1.435303 -0.841072  0.530235\n",
            "2549 -4.570961e-01 -0.950768 -1.142753  ... -0.530235 -0.676505 -1.005619\n",
            "2550  1.462670e-01  0.438812 -0.383970  ... -1.188473 -1.106192 -0.073139\n",
            "2551  6.216572e-01  0.347393 -0.063996  ...  0.950775  1.855835  1.371307\n",
            "2552  3.356047e-01 -0.009323 -0.559345  ... -1.361076 -1.407681 -1.556839\n",
            "\n",
            "[2553 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xYdwh-LoCuR",
        "outputId": "7252ecda-096b-4c1d-decc-79709fb61717"
      },
      "source": [
        "print('We do not need the first row')\n",
        "data = data[1:]\n",
        "print(data.shape)\n",
        "print(pd.DataFrame(data))\n",
        "print('\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We do not need the first row\n",
            "(2553, 10)\n",
            "              0          1          2  ...          7          8          9\n",
            "0      0.180814   0.181536   0.181536  ...   0.179731   0.179731   0.177927\n",
            "1      0.177927   0.178649   0.178649  ...   0.177566   0.177566   0.176483\n",
            "2      0.176483   0.173957   0.173957  ...   0.167821   0.166378   0.164212\n",
            "3      0.163852   0.162769   0.162769  ...   0.164573   0.164573   0.164212\n",
            "4      0.162047   0.160242   0.160242  ...   0.154829   0.154468   0.150859\n",
            "...         ...        ...        ...  ...        ...        ...        ...\n",
            "2548  41.166637  40.800957  40.508416  ...  38.853703  39.447934  40.819241\n",
            "2549  40.362144  39.868473  39.676488  ...  40.289005  40.142736  39.813622\n",
            "2550  39.959889  40.252434  39.429652  ...  38.625149  38.707430  39.740482\n",
            "2551  40.362140  40.087875  39.676486  ...  40.691257  41.596317  41.111790\n",
            "2552  41.447394  41.102467  40.552445  ...  39.750713  39.704109  39.554951\n",
            "\n",
            "[2553 rows x 10 columns]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOdYpBqSoCsA",
        "outputId": "e7624dde-c333-4541-878f-9ad837c5ee02"
      },
      "source": [
        "lag = 7\n",
        "forecast = 3\n",
        "data_orig = series_to_supervised(data, lag, forecast).values\n",
        "print('Data Original after series to supervised on data')\n",
        "print(data_orig.shape)\n",
        "print(pd.DataFrame(data_orig))\n",
        "print('\\n')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Original after series to supervised on data\n",
            "(2544, 100)\n",
            "             0          1          2   ...         97         98         99\n",
            "0      0.180814   0.181536   0.181536  ...   0.158799   0.158799   0.159521\n",
            "1      0.177927   0.178649   0.178649  ...   0.165656   0.165656   0.166739\n",
            "2      0.176483   0.173957   0.173957  ...   0.166739   0.166378   0.165656\n",
            "3      0.163852   0.162769   0.162769  ...   0.161686   0.161686   0.161325\n",
            "4      0.162047   0.160242   0.160242  ...   0.156272   0.155912   0.155190\n",
            "...         ...        ...        ...  ...        ...        ...        ...\n",
            "2539  41.352184  41.020363  41.523178  ...  38.853703  39.447934  40.819241\n",
            "2540  40.590692  41.450043  41.642029  ...  40.289005  40.142736  39.813622\n",
            "2541  41.815729  41.971142  42.656795  ...  38.625149  38.707430  39.740482\n",
            "2542  42.839633  43.251026  43.881827  ...  40.691257  41.596317  41.111790\n",
            "2543  48.343151  48.928242  48.909956  ...  39.750713  39.704109  39.554951\n",
            "\n",
            "[2544 rows x 100 columns]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gScGzgoCcl",
        "outputId": "f16bcc16-9f55-492a-bed2-f12366bb0354"
      },
      "source": [
        "# median data will be on residual data\n",
        "median_data = get_median(residual_data)\n",
        "print('Median of residual data')\n",
        "# Median data for each week\n",
        "print(median_data.shape)\n",
        "print(pd.DataFrame(median_data, columns = ['median_residual_week']).head(10))\n",
        "print('\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median data\n",
            "(2553, 1)\n",
            "   median_residual_week\n",
            "0         -9.022579e-04\n",
            "1          1.487808e-08\n",
            "2         -3.067564e-03\n",
            "3         -1.804194e-04\n",
            "4         -7.398589e-03\n",
            "5         -2.526443e-03\n",
            "6          3.609175e-03\n",
            "7         -1.443535e-03\n",
            "8          2.887196e-03\n",
            "9          5.413856e-04\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXf9SgykoCaV",
        "outputId": "50856661-df8c-4750-9c40-22a4420fb9fa"
      },
      "source": [
        "# Convert median_data to (n_samples, 5) matrix\n",
        "data_m1 = series_to_supervised(median_data, lag, forecast).values\n",
        "print('Median residual data after series to supervised')\n",
        "print(data_m1.shape)\n",
        "print(pd.DataFrame(data_m1, columns = [f\"week i+{i}\" for i in range(1, lag+forecast+1)]))\n",
        "print('\\n')\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median residual data after series to supervised\n",
            "(2544, 10)\n",
            "          week i+1      week i+2  week i+3  ...  week i+8  week i+9  week i+10\n",
            "0    -9.022579e-04  1.487808e-08 -0.003068  ... -0.001444  0.002887   0.000541\n",
            "1     1.487808e-08 -3.067564e-03 -0.000180  ...  0.002887  0.000541   0.004150\n",
            "2    -3.067564e-03 -1.804194e-04 -0.007399  ...  0.000541  0.004150  -0.000722\n",
            "3    -1.804194e-04 -7.398589e-03 -0.002526  ...  0.004150 -0.000722  -0.003248\n",
            "4    -7.398589e-03 -2.526443e-03  0.003609  ... -0.000722 -0.003248  -0.000902\n",
            "...            ...           ...       ...  ...       ...       ...        ...\n",
            "2539 -2.049312e+00  2.386072e+00  1.119902  ... -0.077702 -0.420532   0.205697\n",
            "2540  2.386072e+00  1.119902e+00  2.642056  ... -0.420532  0.205697  -0.909630\n",
            "2541  1.119902e+00  2.642056e+00 -6.358294  ...  0.205697 -0.909630  -1.147332\n",
            "2542  2.642056e+00 -6.358294e+00 -0.333685  ... -0.909630 -1.147332   0.411392\n",
            "2543 -6.358294e+00 -3.336849e-01 -1.581568  ... -1.147332  0.411392  -0.941567\n",
            "\n",
            "[2544 rows x 10 columns]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjBDU3Xfu1Kp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK9CH0k8u1Or"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsoS_SQUu1QO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjMiydPbu1SE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Bm1eV8u1Vg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aAwL7O4n1sv"
      },
      "source": [
        ""
      ]
    }
  ]
}