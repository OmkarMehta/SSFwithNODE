{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "time_series_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install this (important)"
      ],
      "metadata": {
        "id": "uA-p-8kPspwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 1132, done.\u001b[K\n",
            "remote: Counting objects: 100% (428/428), done.\u001b[K\n",
            "remote: Compressing objects: 100% (188/188), done.\u001b[K\n",
            "remote: Total 1132 (delta 253), reused 401 (delta 240), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (1132/1132), 8.29 MiB | 30.32 MiB/s, done.\n",
            "Resolving deltas: 100% (679/679), done.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mModaxDbsFH9",
        "outputId": "0b0b1aa1-b7e9-4bc8-efef-167646e1ef2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "!pip install yfinance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23918 sha256=40607f535fcf5d584598b3c9ca1fcdf402c9edfc7282a57d69dcd09c3c2f6910\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.63\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsnxSsoMzQrp",
        "outputId": "36d388ff-e461-4c29-f4ef-55603f71213b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K Means"
      ],
      "metadata": {
        "id": "MmW7-fNXvpjK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "rwJslKhovvNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rough of K Means\n",
        "\n",
        "1. Get Open and Close Price of asset (o, c) for each trading day.\n",
        "2. Transform it into sequences.\n",
        "    - $d_{i} : {o_{1}c_{1} ... o_{5}c_{5}}$\n",
        "    - where $d_{i}$ is a sequence of o and c for the week `i`.\n",
        "3. Transform $d_{i}$ to sequences of lag * len($d_{i}$) length.\n",
        "4. Normalize these sequences to a range (0, 1).\n",
        "5. Clustering algorithm. "
      ],
      "metadata": {
        "id": "BcAd1jnYvt7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# 1. Get Open and Close Price of asset (o, c) for each trading day.\n",
        "# libraries\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yf\n",
        "import os\n",
        "\n",
        "print(f\"Get Open and Close Price of Assets\")\n",
        "def download_raw_stock_data(filepath, tickers, start, end, period = '1d'):\n",
        "    \"\"\"\n",
        "    Download Stock tickers\n",
        "    :Parameters:\n",
        "        filepath: str\n",
        "            path to store the raw data\n",
        "        tickers : str, list\n",
        "            List of tickers to download\n",
        "        period: str\n",
        "            the frequency at which to gather the data; common options would include ‘1d’ (daily), ‘1mo’ (monthly), ‘1y’ (yearly)\n",
        "        start: str\n",
        "            the date to start gathering the data. For example ‘2010–1–1’\n",
        "        end: str\n",
        "            the date to end gathering the data. For example ‘2020–1–25’\n",
        "    \n",
        "    \"\"\"\n",
        "    #define the ticker symbol\n",
        "    tickerSymbol = tickers\n",
        "\n",
        "    #get data on this ticker\n",
        "    tickerData = yf.Ticker(tickerSymbol)\n",
        "\n",
        "    #get the historical prices for this ticker\n",
        "    tickerDf = tickerData.history(period=period, start=start, end=end)\n",
        "    tickerDf.to_csv(filepath)\n",
        "\n",
        "dict_tickers = {\n",
        "    'Apple': 'AAPL',\n",
        "    'Microsoft': 'MSFT',\n",
        "    'Google': 'GOOG',\n",
        "    'Bitcoin': 'BTC-USD',\n",
        "    'Facebook': 'FB',\n",
        "    'Walmart': 'WMT',\n",
        "    'Amazon': 'AMZN',\n",
        "    'CVS': 'CVS',\n",
        "    'Berkshire': 'BRK-B',\n",
        "    'ExxonMobil': 'XOM',\n",
        "    'AtandT': 'T',\n",
        "    'Costco': 'COST',\n",
        "    'Walgreens': 'WBA',\n",
        "    'Kroger': 'KR',\n",
        "    'JPMorgan': 'JPM',\n",
        "    'Verizon': 'VZ',\n",
        "    'FordMotor': 'F',\n",
        "    'GeneralMotors': 'GM',\n",
        "    'Dell': 'DELL',\n",
        "    'BankOfAmerica': 'BAC',\n",
        "    'Target': 'TGT',\n",
        "    'GeneralElectric': 'GE',\n",
        "    'JohnsonandJohnson': 'JNJ',\n",
        "    'Nvidia': 'NVDA',\n",
        "    'Intel': 'INTC',\n",
        "}\n",
        "\n",
        "path = f\"raw-stock-data/data-1970-2021\"\n",
        "if not os.path.exists(path):\n",
        "    # https://appdividend.com/2021/07/03/how-to-create-directory-if-not-exist-in-python/\n",
        "    # Create a new directory\n",
        "    os.makedirs(path)\n",
        "    print(f\"{path} directory is created\")\n",
        "period = '1d'\n",
        "start='1970-1-1'\n",
        "end='2021-8-31'\n",
        "for tickerName, ticker in dict_tickers.items():\n",
        "    tickerName = tickerName\n",
        "    ticker = ticker\n",
        "    filepath = f\"{path}/{tickerName}.csv\"\n",
        "    download_raw_stock_data(filepath, ticker, start, end, period)\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(f\"The size of each asset\")\n",
        "import pandas as pd\n",
        "for tickerName in dict_tickers.keys():\n",
        "    df = pd.read_csv(f\"{path}/{tickerName}.csv\")\n",
        "    print(f\"{tickerName} size: {len(df)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get Open and Close Price of Assets\n",
            "\n",
            "\n",
            "The size of each asset\n",
            "Apple size: 10266\n",
            "Microsoft size: 8940\n",
            "Google size: 4288\n",
            "Bitcoin size: 2537\n",
            "Facebook size: 2336\n",
            "Walmart size: 12340\n",
            "Amazon size: 6114\n",
            "CVS size: 12237\n",
            "Berkshire size: 6371\n",
            "ExxonMobil size: 13030\n",
            "AtandT size: 9522\n",
            "Costco size: 8859\n",
            "Walgreens size: 10454\n",
            "Kroger size: 13030\n",
            "JPMorgan size: 10454\n",
            "Verizon size: 9522\n",
            "FordMotor size: 12420\n",
            "GeneralMotors size: 2713\n",
            "Dell size: 1268\n",
            "BankOfAmerica size: 12199\n",
            "Target size: 12238\n",
            "GeneralElectric size: 13031\n",
            "JohnsonandJohnson size: 13032\n",
            "Nvidia size: 5690\n",
            "Intel size: 10453\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYHu8FG1w9E9",
        "outputId": "a8f59762-66d5-4b92-a37b-28434b6ea7d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "len(dict_tickers.keys())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0mxiP_J4LvW",
        "outputId": "87042013-bd2e-4cdb-f68b-1b0bf24c0015"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2. Get weekly data.\n",
        "# 3. Transform $d_{i}$ to sequences of lag * len($d_{i}$) length.\n",
        "\n",
        "def stockDataTransformer(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    df.set_index('Date', inplace=True)\n",
        "    df1 = df[['Open', 'Close']].copy()\n",
        "    data = df1.values\n",
        "    n_samples = data.shape[0]//10*10\n",
        "    reshape_number = n_samples*data.shape[1]//10\n",
        "    data1 = data[:n_samples].reshape((reshape_number, 10))\n",
        "    return data1\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \"\"\"\n",
        "    Frame a time series as a supervised learning dataset.\n",
        "    Arguments:\n",
        "        data: Sequence of observations as a list or NumPy array.\n",
        "        n_in: Number of lag observations as input (X).\n",
        "        n_out: Number of observations as output (y).\n",
        "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
        "    Returns:\n",
        "        Pandas DataFrame of series framed for supervised learning.\n",
        "    \"\"\"\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "BL0nozG8ynms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "from pandas import concat\n",
        "week_sequence = {}\n",
        "lag = 5\n",
        "for tickerName in dict_tickers.keys():\n",
        "    filepath = f\"{path}/{tickerName}.csv\"\n",
        "    # Get the data in the required format\n",
        "    data = stockDataTransformer(filepath)\n",
        "    print(f\"{tickerName} data.shape {data.shape}\")\n",
        "    data_orig = series_to_supervised(data, lag).values\n",
        "    print(f'{tickerName} Data Original after series to supervised on data')\n",
        "    print(data_orig.shape)\n",
        "    week_sequence[tickerName] = data_orig"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple data.shape (2052, 10)\n",
            "Apple Data Original after series to supervised on data\n",
            "(2047, 60)\n",
            "Microsoft data.shape (1788, 10)\n",
            "Microsoft Data Original after series to supervised on data\n",
            "(1783, 60)\n",
            "Google data.shape (856, 10)\n",
            "Google Data Original after series to supervised on data\n",
            "(851, 60)\n",
            "Bitcoin data.shape (506, 10)\n",
            "Bitcoin Data Original after series to supervised on data\n",
            "(501, 60)\n",
            "Facebook data.shape (466, 10)\n",
            "Facebook Data Original after series to supervised on data\n",
            "(461, 60)\n",
            "Walmart data.shape (2468, 10)\n",
            "Walmart Data Original after series to supervised on data\n",
            "(2463, 60)\n",
            "Amazon data.shape (1222, 10)\n",
            "Amazon Data Original after series to supervised on data\n",
            "(1217, 60)\n",
            "CVS data.shape (2446, 10)\n",
            "CVS Data Original after series to supervised on data\n",
            "(2441, 60)\n",
            "Berkshire data.shape (1274, 10)\n",
            "Berkshire Data Original after series to supervised on data\n",
            "(1269, 60)\n",
            "ExxonMobil data.shape (2606, 10)\n",
            "ExxonMobil Data Original after series to supervised on data\n",
            "(2601, 60)\n",
            "AtandT data.shape (1904, 10)\n",
            "AtandT Data Original after series to supervised on data\n",
            "(1899, 60)\n",
            "Costco data.shape (1770, 10)\n",
            "Costco Data Original after series to supervised on data\n",
            "(1765, 60)\n",
            "Walgreens data.shape (2090, 10)\n",
            "Walgreens Data Original after series to supervised on data\n",
            "(2085, 60)\n",
            "Kroger data.shape (2606, 10)\n",
            "Kroger Data Original after series to supervised on data\n",
            "(2601, 60)\n",
            "JPMorgan data.shape (2090, 10)\n",
            "JPMorgan Data Original after series to supervised on data\n",
            "(2085, 60)\n",
            "Verizon data.shape (1904, 10)\n",
            "Verizon Data Original after series to supervised on data\n",
            "(1899, 60)\n",
            "FordMotor data.shape (2484, 10)\n",
            "FordMotor Data Original after series to supervised on data\n",
            "(2479, 60)\n",
            "GeneralMotors data.shape (542, 10)\n",
            "GeneralMotors Data Original after series to supervised on data\n",
            "(537, 60)\n",
            "Dell data.shape (252, 10)\n",
            "Dell Data Original after series to supervised on data\n",
            "(247, 60)\n",
            "BankOfAmerica data.shape (2438, 10)\n",
            "BankOfAmerica Data Original after series to supervised on data\n",
            "(2433, 60)\n",
            "Target data.shape (2446, 10)\n",
            "Target Data Original after series to supervised on data\n",
            "(2441, 60)\n",
            "GeneralElectric data.shape (2606, 10)\n",
            "GeneralElectric Data Original after series to supervised on data\n",
            "(2601, 60)\n",
            "JohnsonandJohnson data.shape (2606, 10)\n",
            "JohnsonandJohnson Data Original after series to supervised on data\n",
            "(2601, 60)\n",
            "Nvidia data.shape (1138, 10)\n",
            "Nvidia Data Original after series to supervised on data\n",
            "(1127, 60)\n",
            "Intel data.shape (2090, 10)\n",
            "Intel Data Original after series to supervised on data\n",
            "(2085, 60)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8q5WFNK0eDZ",
        "outputId": "4a894c21-4a54-441d-d2f6-77abf6f0d47c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "data = week_sequence['Apple']\n",
        "# 4. Bundle all sequences together\n",
        "for tickerName in week_sequence.keys():\n",
        "    if tickerName != 'Apple':\n",
        "        data1 = week_sequence[tickerName]\n",
        "        data = np.concatenate((data, data1))\n",
        "        print(f\"data.shape {data.shape}\")\n",
        " "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.shape (3830, 60)\n",
            "data.shape (4681, 60)\n",
            "data.shape (5182, 60)\n",
            "data.shape (5643, 60)\n",
            "data.shape (8106, 60)\n",
            "data.shape (9323, 60)\n",
            "data.shape (11764, 60)\n",
            "data.shape (13033, 60)\n",
            "data.shape (15634, 60)\n",
            "data.shape (17533, 60)\n",
            "data.shape (19298, 60)\n",
            "data.shape (21383, 60)\n",
            "data.shape (23984, 60)\n",
            "data.shape (26069, 60)\n",
            "data.shape (27968, 60)\n",
            "data.shape (30447, 60)\n",
            "data.shape (30984, 60)\n",
            "data.shape (31231, 60)\n",
            "data.shape (33664, 60)\n",
            "data.shape (36105, 60)\n",
            "data.shape (38706, 60)\n",
            "data.shape (41307, 60)\n",
            "data.shape (42434, 60)\n",
            "data.shape (44519, 60)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvIdGj4r1chm",
        "outputId": "1e0983eb-893f-4a84-b22a-21c29b6ed59c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "data_df = pd.DataFrame(data)\n",
        "data_df.to_csv(f\"all_assets_sequences.csv\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "M_wWh2OJFJaB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44519, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgcw0tj54F6g",
        "outputId": "0a7c75ef-d5f4-4917-d36c-e42de2b4e923"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# import numpy as np\n",
        "# a1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "# a2 = np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
        "# a3 = np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
        "# np.concatenate((a1, a2, a3))"
      ],
      "outputs": [],
      "metadata": {
        "id": "AbdkOC5Uzde6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "data_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.095789</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.088790</td>\n",
              "      <td>0.088353</td>\n",
              "      <td>0.090540</td>\n",
              "      <td>0.090540</td>\n",
              "      <td>0.093165</td>\n",
              "      <td>0.093165</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.103662</td>\n",
              "      <td>0.103662</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.124219</td>\n",
              "      <td>0.124219</td>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.123345</td>\n",
              "      <td>0.122907</td>\n",
              "      <td>0.119846</td>\n",
              "      <td>0.119408</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.118534</td>\n",
              "      <td>0.118096</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.106287</td>\n",
              "      <td>0.105849</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.110660</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.106724</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.114597</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.103662</td>\n",
              "      <td>0.103662</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.124219</td>\n",
              "      <td>0.124219</td>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.123345</td>\n",
              "      <td>0.122907</td>\n",
              "      <td>0.119846</td>\n",
              "      <td>0.119408</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.118534</td>\n",
              "      <td>0.118096</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.106287</td>\n",
              "      <td>0.105849</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.110660</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.106724</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.114597</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.104974</td>\n",
              "      <td>0.104537</td>\n",
              "      <td>0.099725</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.093165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.125969</td>\n",
              "      <td>0.123345</td>\n",
              "      <td>0.122907</td>\n",
              "      <td>0.119846</td>\n",
              "      <td>0.119408</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.120720</td>\n",
              "      <td>0.118534</td>\n",
              "      <td>0.118096</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.106287</td>\n",
              "      <td>0.105849</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.110660</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.106724</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.114597</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.104974</td>\n",
              "      <td>0.104537</td>\n",
              "      <td>0.099725</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.093165</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.096226</td>\n",
              "      <td>0.095352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.108036</td>\n",
              "      <td>0.106287</td>\n",
              "      <td>0.105849</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.110660</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.106724</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.114597</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.104974</td>\n",
              "      <td>0.104537</td>\n",
              "      <td>0.099725</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.093165</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.096226</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.092728</td>\n",
              "      <td>0.092290</td>\n",
              "      <td>0.091853</td>\n",
              "      <td>0.091415</td>\n",
              "      <td>0.090103</td>\n",
              "      <td>0.089228</td>\n",
              "      <td>0.091415</td>\n",
              "      <td>0.091415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.106724</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.107161</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.111535</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.113722</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.115034</td>\n",
              "      <td>0.114597</td>\n",
              "      <td>0.113284</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.112847</td>\n",
              "      <td>0.111972</td>\n",
              "      <td>0.108911</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>0.104974</td>\n",
              "      <td>0.104537</td>\n",
              "      <td>0.099725</td>\n",
              "      <td>0.098851</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.093165</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.096664</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100163</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.096226</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.092728</td>\n",
              "      <td>0.092290</td>\n",
              "      <td>0.091853</td>\n",
              "      <td>0.091415</td>\n",
              "      <td>0.090103</td>\n",
              "      <td>0.089228</td>\n",
              "      <td>0.091415</td>\n",
              "      <td>0.091415</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>0.090103</td>\n",
              "      <td>0.089665</td>\n",
              "      <td>0.085292</td>\n",
              "      <td>0.084854</td>\n",
              "      <td>0.086166</td>\n",
              "      <td>0.086166</td>\n",
              "      <td>0.083979</td>\n",
              "      <td>0.083105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        57        58        59\n",
              "0  0.100600  0.100600  0.095789  ...  0.114597  0.113284  0.112847\n",
              "1  0.098851  0.098851  0.103662  ...  0.098851  0.093602  0.093165\n",
              "2  0.125969  0.125969  0.123345  ...  0.100600  0.096226  0.095352\n",
              "3  0.113284  0.112847  0.108473  ...  0.089228  0.091415  0.091415\n",
              "4  0.107161  0.106724  0.107161  ...  0.086166  0.083979  0.083105\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "M5MG5n5AG2u6",
        "outputId": "08738d99-bc4b-476e-9504-f15b68b6593d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# 4. Normalize these sequences to a range (0, 1).\n",
        "from sklearn import preprocessing \n",
        "# https://www.journaldev.com/45109/normalize-data-in-python\n",
        "# Normalizes the sample\n",
        "data_normalized = preprocessing.normalize(data_df)\n",
        "data_normalized_df = pd.DataFrame(data_normalized)\n",
        "data_normalized_df.to_csv(f\"all_assets_sequences_lag{lag+1}.csv\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "qoi5Czkuyr9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 5. Clustering algorithm. "
      ],
      "outputs": [],
      "metadata": {
        "id": "7VlMi0yZyr0n"
      }
    }
  ]
}