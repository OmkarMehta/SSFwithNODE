{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "latentode_irregular_understanding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5c977df63f64382823626dbbeaa27f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c15ed6530fd4447a9a9e5a093e0004b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aebd2d40bf6e419db2b11104bef0b27c",
              "IPY_MODEL_5f14890f9c1242739e743aa8cf9d9517",
              "IPY_MODEL_6d0424cefc324ba5af56bf7797bc0b30"
            ]
          }
        },
        "c15ed6530fd4447a9a9e5a093e0004b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aebd2d40bf6e419db2b11104bef0b27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_073bf8533c2c45b4ba0f7f98efe6bd9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0ca5901e60a4063a25ff2c974ecb707"
          }
        },
        "5f14890f9c1242739e743aa8cf9d9517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ee754ddf3064368b3fa4bc82996a8c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 341150653,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 341150653,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d45742a15fa48798d5f6dd73d1f3ad0"
          }
        },
        "6d0424cefc324ba5af56bf7797bc0b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f8f243bc4664db1b9dc43590d20f14c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 341150720/? [00:05&lt;00:00, 72233385.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65987adf83b24eb39e5d214823f4ba75"
          }
        },
        "073bf8533c2c45b4ba0f7f98efe6bd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0ca5901e60a4063a25ff2c974ecb707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ee754ddf3064368b3fa4bc82996a8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d45742a15fa48798d5f6dd73d1f3ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f8f243bc4664db1b9dc43590d20f14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65987adf83b24eb39e5d214823f4ba75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVJodaa_8mQs"
      },
      "source": [
        "# Import this (important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhfJy5RA8pHw",
        "outputId": "4ac85703-72dc-4985-a314-30232fe5e657"
      },
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 1138, done.\u001b[K\n",
            "remote: Counting objects: 100% (434/434), done.\u001b[K\n",
            "remote: Compressing objects: 100% (194/194), done.\u001b[K\n",
            "remote: Total 1138 (delta 256), reused 400 (delta 240), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (1138/1138), 8.29 MiB | 8.71 MiB/s, done.\n",
            "Resolving deltas: 100% (682/682), done.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnIz6ghoAA9H"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf82UlO58phm"
      },
      "source": [
        "# Rough"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4d8700-2uyv"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8U0VQjD2hH8"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fDkAwSb2-N2"
      },
      "source": [
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from generate_timeseries import Periodic_1d\n",
        "from torch.distributions import uniform\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from mujoco_physics import HopperPhysics\n",
        "from physionet import PhysioNet, variable_time_collate_fn, get_data_min_max\n",
        "from person_activity import PersonActivity, variable_time_collate_fn_activity\n",
        "\n",
        "from sklearn import model_selection\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w5cfx1I8uz2"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NljGxF4I3YGF"
      },
      "source": [
        "n = 1000  # size of dataset\n",
        "niters = 500  # number of iterations\n",
        "lr = 1e-3  # Starting Learning Rate\n",
        "b = 50  # batch_size\n",
        "viz = True  # show plots while training\n",
        "# save: path for saving checkpoints\n",
        "# load: ID of the experiment to load for evaluation\n",
        "random_seed = 1991 # random seed\n",
        "# dataset = Dataset to load. Available: physionet, activity, hopper, periodic\n",
        "sample_tp = None # number of time points to sub-sample.  If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\n",
        "c = None # Cut out the section of the timeline of the specified length (in number of points\n",
        "# quantization: Quantization on the physionet dataset.\" \"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\n",
        "latent_ode = None # latent ode with ode-rnn encoder\n",
        "# z0-encoder = odernn # Type of encoder for Latent ODE model: odernn or rnn\n",
        "# classic-rnn\n",
        "# rnn-cell\n",
        "# input-decay\n",
        "# ode-rnn # Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\n",
        "# rnn-vae  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\n",
        "latents = 10 # size of the latent state\n",
        "rec_dims = 20 # dimensionality of the recognition model (ODE or RNN)\n",
        "rec_layers = 1 # Number of layers in ODE func in recognition ODE\n",
        "gen_layers = 1 # Number of layers in ODE func in generative ODE\n",
        "units = 100 # Number of units per layer in ODE func\n",
        "gru_units = 100 # Number of units per layer in each of GRU update networks\n",
        "poisson = 'store_true' # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
        "classif = 'store_true' # Include binary classification loss -- used for Physionet dataset for hospiral mortality\n",
        "linear_classif = 'store_true' # If using a classifier, use a linear classifier instead of 1-layer NN\n",
        "extrap = 'store_true' # Set extrapolation mode. If this flag is not set, run interpolation mode\n",
        "timepoints = 100 # total number of timepoints\n",
        "max_tp = 5. # We subsample points in the interval [0, args.max_tp]\n",
        "noise_weight = 0.01 # Noise amplitude for generated traejctories\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4nhr13w7k3h",
        "outputId": "48146850-bf94-433b-fab8-049704dcebb2"
      },
      "source": [
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f03000d14b0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkVaoUde_8Py"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb7DmLfLASpy"
      },
      "source": [
        "from torch.distributions import uniform\n",
        "n_total_tp = 100\n",
        "max_t_extrap = max_tp/timepoints * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj5lZq4Y7x2V",
        "outputId": "29a9f073-c73a-457c-e6d2-8cf9473a1999"
      },
      "source": [
        "distribution = uniform.Uniform(torch.Tensor([0.0]),torch.Tensor([max_t_extrap]))\n",
        "time_steps_extrap =  distribution.sample(torch.Size([n_total_tp-1]))[:,0]\n",
        "print(time_steps_extrap)\n",
        "print(time_steps_extrap.shape)\n",
        "time_steps_extrap = torch.cat((torch.Tensor([0.0]), time_steps_extrap))\n",
        "print(time_steps_extrap.shape)\n",
        "time_steps_extrap = torch.sort(time_steps_extrap)[0]\n",
        "print(time_steps_extrap.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.7851, 3.3443, 0.1417, 1.3734, 3.0917, 0.3541, 2.0763, 0.4173, 3.6215,\n",
            "        3.9683, 3.6055, 3.8517, 1.5262, 1.1137, 3.9579, 1.0563, 3.9331, 4.4630,\n",
            "        3.0525, 4.4004, 2.8379, 1.0336, 0.1935, 2.1825, 0.0623, 0.8038, 0.1491,\n",
            "        2.8308, 4.4699, 4.7802, 0.0876, 2.9323, 0.6113, 4.8144, 0.1380, 0.2273,\n",
            "        0.5352, 1.8769, 0.4140, 0.9900, 1.5855, 2.3460, 0.2538, 1.5439, 4.2902,\n",
            "        3.2616, 2.5595, 4.6672, 3.3973, 2.9913, 1.8209, 4.3530, 3.2576, 3.6419,\n",
            "        2.3678, 1.2531, 1.5027, 0.8094, 2.2725, 3.1943, 0.9322, 0.1816, 3.5082,\n",
            "        1.3179, 3.5005, 3.7536, 4.8195, 0.2850, 4.3183, 3.9178, 1.1724, 2.6610,\n",
            "        1.8388, 0.0661, 2.3603, 1.7746, 4.1492, 0.1078, 4.0930, 2.2240, 2.0680,\n",
            "        1.2015, 3.2396, 1.0108, 2.0369, 0.2006, 1.9468, 0.9870, 0.1718, 2.8426,\n",
            "        3.3702, 4.5436, 1.2397, 1.8489, 4.0469, 2.2679, 2.1030, 1.8386, 1.4328])\n",
            "torch.Size([99])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8UO_7BmEDal"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKVYI0ng-B6d"
      },
      "source": [
        "# Run Model of the author"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "eBYSErWB-E6H",
        "outputId": "4ba946bc-21c4-483f-a64c-4a8f09aca5a8"
      },
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=300)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='periodic', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttorch.manual_seed(args.random_seed)\n",
        "\tnp.random.seed(args.random_seed)\n",
        "\n",
        "\texperimentID = args.load\n",
        "\tif experimentID is None:\n",
        "\t\t# Make a new experiment ID\n",
        "\t\texperimentID = int(SystemRandom().random()*100000)\n",
        "\tckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
        "\n",
        "\tstart = time.time()\n",
        "\tprint(\"Sampling dataset of {} training examples\".format(args.n))\n",
        "\t\n",
        "\tinput_command = sys.argv\n",
        "\tind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
        "\tif len(ind) == 1:\n",
        "\t\tind = ind[0]\n",
        "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
        "\tinput_command = \" \".join(input_command)\n",
        "\n",
        "\tutils.makedirs(\"results/\")\n",
        "\n",
        "\t##################################################################\n",
        "\tdata_obj = parse_datasets(args, device)\n",
        "\tinput_dim = data_obj[\"input_dim\"]\n",
        "\n",
        "\tclassif_per_tp = False\n",
        "\tif (\"classif_per_tp\" in data_obj):\n",
        "\t\t# do classification per time point rather than on a time series as a whole\n",
        "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "\tif args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
        "\n",
        "\tn_labels = 1\n",
        "\tif args.classif:\n",
        "\t\tif (\"n_labels\" in data_obj):\n",
        "\t\t\tn_labels = data_obj[\"n_labels\"]\n",
        "\t\telse:\n",
        "\t\t\traise Exception(\"Please provide number of labels for classification task\")\n",
        "\n",
        "\t##################################################################\n",
        "\t# Create the model\n",
        "\tobsrv_std = 0.01\n",
        "\tif args.dataset == \"hopper\":\n",
        "\t\tobsrv_std = 1e-3 \n",
        "\n",
        "\tobsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "\n",
        "\tz0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
        "\n",
        "\tif args.rnn_vae:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
        "\n",
        "\t\t# Create RNN-VAE model\n",
        "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
        "\t\t\tdevice = device, \n",
        "\t\t\trec_dims = args.rec_dims, \n",
        "\t\t\tconcat_mask = True, \n",
        "\t\t\tobsrv_std = obsrv_std,\n",
        "\t\t\tz0_prior = z0_prior,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\n",
        "\n",
        "\telif args.classic_rnn:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
        "\t\t# Create RNN model\n",
        "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\telif args.ode_rnn:\n",
        "\t\t# Create ODE-GRU model\n",
        "\t\tn_ode_gru_dims = args.latents\n",
        "\t\t\t\t\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
        "\n",
        "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
        "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\trec_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = input_dim, \n",
        "\t\t\tlatent_dim = n_ode_gru_dims,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
        "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\t\n",
        "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
        "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\telif args.latent_ode:\n",
        "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels)\n",
        "\telse:\n",
        "\t\traise Exception(\"Model not specified\")\n",
        "\n",
        "\t##################################################################\n",
        "\n",
        "\tif args.viz:\n",
        "\t\tviz = Visualizations(device)\n",
        "\n",
        "\t##################################################################\n",
        "\t\n",
        "\t#Load checkpoint and evaluate the model\n",
        "\tif args.load is not None:\n",
        "\t\tutils.get_ckpt_model(ckpt_path, model, device)\n",
        "\t\texit()\n",
        "\n",
        "\t##################################################################\n",
        "\t# Training\n",
        "\n",
        "\tlog_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
        "\tif not os.path.exists(\"logs/\"):\n",
        "\t\tutils.makedirs(\"logs/\")\n",
        "\tlogger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(__file__))\n",
        "\tlogger.info(input_command)\n",
        "\n",
        "\toptimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
        "\n",
        "\tnum_batches = data_obj[\"n_train_batches\"]\n",
        "\n",
        "\tfor itr in range(1, num_batches * (args.niters + 1)):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tutils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
        "\n",
        "\t\twait_until_kl_inc = 10\n",
        "\t\tif itr // num_batches < wait_until_kl_inc:\n",
        "\t\t\tkl_coef = 0.\n",
        "\t\telse:\n",
        "\t\t\tkl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
        "\n",
        "\t\tbatch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
        "\t\ttrain_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)\n",
        "\t\ttrain_res[\"loss\"].backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\tn_iters_to_viz = 1\n",
        "\t\tif itr % (n_iters_to_viz * num_batches) == 0:\n",
        "\t\t\twith torch.no_grad():\n",
        "\n",
        "\t\t\t\ttest_res = compute_loss_all_batches(model, \n",
        "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
        "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
        "\t\t\t\t\texperimentID = experimentID,\n",
        "\t\t\t\t\tdevice = device,\n",
        "\t\t\t\t\tn_traj_samples = 3, kl_coef = kl_coef)\n",
        "\n",
        "\t\t\t\tmessage = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
        "\t\t\t\t\titr//num_batches, \n",
        "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
        "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
        "\t\t \t\n",
        "\t\t\t\tlogger.info(\"Experiment \" + str(experimentID))\n",
        "\t\t\t\tlogger.info(message)\n",
        "\t\t\t\tlogger.info(\"KL coef: {}\".format(kl_coef))\n",
        "\t\t\t\tlogger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
        "\t\t\t\tlogger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif \"auc\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
        "\n",
        "\t\t\t\tif \"mse\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
        "\n",
        "\t\t\t\tif \"accuracy\" in train_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
        "\n",
        "\t\t\t\tif \"accuracy\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
        "\n",
        "\t\t\t\tif \"pois_likelihood\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
        "\n",
        "\t\t\t\tif \"ce_loss\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
        "\n",
        "\t\t\ttorch.save({\n",
        "\t\t\t\t'args': args,\n",
        "\t\t\t\t'state_dict': model.state_dict(),\n",
        "\t\t\t}, ckpt_path)\n",
        "\n",
        "\n",
        "\t\t\t# Plotting\n",
        "\t\t\tif args.viz:\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\ttest_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])\n",
        "\n",
        "\t\t\t\t\tprint(\"plotting....\")\n",
        "\t\t\t\t\tif isinstance(model, LatentODE) and (args.dataset == \"periodic\"): #and not args.classic_rnn and not args.ode_rnn:\n",
        "\t\t\t\t\t\tplot_id = itr // num_batches // n_iters_to_viz\n",
        "\t\t\t\t\t\tviz.draw_all_plots_one_dim(test_dict, model, \n",
        "\t\t\t\t\t\t\tplot_name = file_name + \"_\" + str(experimentID) + \"_{:03d}\".format(plot_id) + \".png\",\n",
        "\t\t\t\t\t\t \texperimentID = experimentID, save=True)\n",
        "\t\t\t\t\t\tplt.pause(0.01)\n",
        "\ttorch.save({\n",
        "\t\t'args': args,\n",
        "\t\t'state_dict': model.state_dict(),\n",
        "\t}, ckpt_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: Latent ODE [-h] [-n N] [--niters NITERS] [--lr LR] [-b BATCH_SIZE]\n",
            "                  [--viz] [--save SAVE] [--load LOAD] [-r RANDOM_SEED]\n",
            "                  [--dataset DATASET] [-s SAMPLE_TP] [-c CUT_TP]\n",
            "                  [--quantization QUANTIZATION] [--latent-ode]\n",
            "                  [--z0-encoder Z0_ENCODER] [--classic-rnn]\n",
            "                  [--rnn-cell RNN_CELL] [--input-decay] [--ode-rnn]\n",
            "                  [--rnn-vae] [-l LATENTS] [--rec-dims REC_DIMS]\n",
            "                  [--rec-layers REC_LAYERS] [--gen-layers GEN_LAYERS]\n",
            "                  [-u UNITS] [-g GRU_UNITS] [--poisson] [--classif]\n",
            "                  [--linear-classif] [--extrap] [-t TIMEPOINTS]\n",
            "                  [--max-t MAX_T] [--noise-weight NOISE_WEIGHT]\n",
            "Latent ODE: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b3795be3-3477-4bee-97ed-b38edd553d61.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG4mctCz-Fv7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juPmjjMF_7oA"
      },
      "source": [
        "# Break it down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0fP80LJ_928",
        "outputId": "52b905e5-3797-4839-81d1-9a975add84da"
      },
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 1138, done.\u001b[K\n",
            "remote: Counting objects: 100% (434/434), done.\u001b[K\n",
            "remote: Compressing objects: 100% (194/194), done.\u001b[K\n",
            "remote: Total 1138 (delta 256), reused 400 (delta 240), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (1138/1138), 8.29 MiB | 30.65 MiB/s, done.\n",
            "Resolving deltas: 100% (682/682), done.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFjl3iKBAECB"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHuQH-oTADRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ca094d-4dca-4399-ea0e-723e8b13ab27"
      },
      "source": [
        "# run_models.py\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "import sys\n",
        "# print(sys.argv[1:])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are inside HopperPhysics class\n",
            "T is 200\n",
            "dim is {D}\n",
            "n_training_samples is 10000\n",
            "training_file name is training.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNCXSGE0OSjP"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaYoHqr9AX-P"
      },
      "source": [
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=300)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='hopper', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "sys.argv = ['-f']\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)  # saves in 'experiments/' folder"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdatPwwYOVx5"
      },
      "source": [
        "## Manual seed, experimentID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu69paaHCAS4",
        "outputId": "b6bf145c-dee8-44fe-df0a-4086f7f770a4"
      },
      "source": [
        "torch.manual_seed(args.random_seed)\n",
        "np.random.seed(args.random_seed)\n",
        "\n",
        "experimentID = args.load  # None\n",
        "print(f\"experimentID is {experimentID}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "experimentID is None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYDzsdK9B-NF",
        "outputId": "0fc61ece-a0dc-4bb4-adb1-4368527ad508"
      },
      "source": [
        "if experimentID is None:\n",
        "\t\t# Make a new experiment ID\n",
        "\t\texperimentID = int(SystemRandom().random()*100000) # from random import SystemRandom\n",
        "print(f\"experimentID is {experimentID}\")\n",
        "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt') \n",
        "print(f\"ckpt_path is {ckpt_path}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "experimentID is 99276\n",
            "ckpt_path is experiments/experiment_99276.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3hevLCAC2tS",
        "outputId": "2ea1f4b4-14d7-44d1-cfb5-5571190c093a"
      },
      "source": [
        "start = time.time()\n",
        "print(\"Sampling dataset of {} training examples\".format(args.n))  # n is size of the dataset"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling dataset of 100 training examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rCv2MoGjKL",
        "outputId": "84a79d24-8fd3-4d4b-a8e6-9524753fba66"
      },
      "source": [
        "print(f\"args is {str(args)}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args is Namespace(batch_size=50, classic_rnn=False, classif=False, cut_tp=None, dataset='hopper', extrap=False, gen_layers=1, gru_units=100, input_decay=False, latent_ode=False, latents=6, linear_classif=False, load=None, lr=0.01, max_t=5.0, n=100, niters=300, noise_weight=0.01, ode_rnn=False, poisson=False, quantization=0.1, random_seed=1991, rec_dims=20, rec_layers=1, rnn_cell='gru', rnn_vae=False, sample_tp=None, save='experiments/', timepoints=100, units=100, viz=False, z0_encoder='odernn')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7TpUY3BLIP",
        "outputId": "38cddf9f-bbbd-4ee7-a4da-3401ed87d0b8"
      },
      "source": [
        "input_command = sys.argv\n",
        "print(f\"input_command is {input_command}\")\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_command is ['-f']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcTvI3I2GVlj",
        "outputId": "67a998af-c62e-48f3-b784-42c92b233258"
      },
      "source": [
        "ind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
        "print(f\"ind is {ind}\")\n",
        "print(f\"len(ind) is {len(ind)}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ind is []\n",
            "len(ind) is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvrwritSGX56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2f048e-e9b1-4987-9372-abbd093baf4f"
      },
      "source": [
        "if len(ind) == 1:\n",
        "\t\tind = ind[0]\n",
        "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
        "input_command = \" \".join(input_command)\n",
        "print(f\"input_command is {input_command}\")\n",
        "utils.makedirs(\"results/\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_command is -f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxDMKpNObYB"
      },
      "source": [
        "## parse_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5c977df63f64382823626dbbeaa27f8",
            "c15ed6530fd4447a9a9e5a093e0004b6",
            "aebd2d40bf6e419db2b11104bef0b27c",
            "5f14890f9c1242739e743aa8cf9d9517",
            "6d0424cefc324ba5af56bf7797bc0b30",
            "073bf8533c2c45b4ba0f7f98efe6bd9e",
            "e0ca5901e60a4063a25ff2c974ecb707",
            "5ee754ddf3064368b3fa4bc82996a8c8",
            "3d45742a15fa48798d5f6dd73d1f3ad0",
            "6f8f243bc4664db1b9dc43590d20f14c",
            "65987adf83b24eb39e5d214823f4ba75"
          ]
        },
        "id": "XsSKx1IeG4Wn",
        "outputId": "191baa96-0726-4fd1-fa85-6111cc25effe"
      },
      "source": [
        "data_obj = parse_datasets(args, device)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the function parse_datasets from parse_datasets.py\n",
            "Inputs are (args, device)\n",
            "dataset_name is hopper\n",
            "\n",
            "\n",
            "args.timepoints is 100\n",
            "args.extrap is False\n",
            "n_total_tp = args.timepoints + args.extrap  --> is 100\n",
            "\n",
            "\n",
            "args.max_t is 5.0\n",
            "max_t_extrap = args.max_t / args.timepoints * n_total_tp --> 5.0\n",
            "\n",
            "\n",
            "if dataset_name == 'hopper'\n",
            "root is data\n",
            "Let's download\n",
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "Downloading the dataset [325MB] ...\n",
            "data/HopperPhysics is generated\n",
            "Downloading data from this url: http://www.cs.toronto.edu/~rtqichen/datasets/HopperPhysics/training.pt\n",
            "\n",
            "\n",
            "Downloading http://www.cs.toronto.edu/~rtqichen/datasets/HopperPhysics/training.pt to data/HopperPhysics/training.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c977df63f64382823626dbbeaa27f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/341150653 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "data_file is data/HopperPhysics/training.pt\n",
            "Using torch.Tensor(torch.load(data_file)).to(device) to get self.data\n",
            "self.data.shape is torch.Size([10000, 200, 14])\n",
            "\n",
            "\n",
            "Using normalize_data()\n",
            "data.shape is torch.Size([10000, 200, 14])\n",
            "reshaped = data.reshape(-1, data.size(-1))\n",
            "reshaped.shape is torch.Size([2000000, 14])\n",
            "att_min = torch.min(reshaped, 0)[0]\n",
            "att_min.shape is torch.Size([14])\n",
            "att_max = torch.max(reshaped, 0)[0]\n",
            "att_max.shape is torch.Size([14])\n",
            "data_norm = (data - att_min) / att_max\n",
            "dataset.shape is torch.Size([100, 200, 14])\n",
            "\n",
            "\n",
            "n_tp_data = dataset[:].shape[1]\n",
            "n_tp_data is 200\n",
            "\n",
            "\n",
            "time_steps.shape is torch.Size([200])\n",
            "time_steps = time_steps / len(time_steps)\n",
            "time_steps.shape is torch.Size([200])\n",
            "\n",
            "\n",
            "if not args.extrap\n",
            "# Creating dataset for interpolation\n",
            "# sample time points from different parts of the timeline, \n",
            "# so that the model learns from different parts of hopper trajectory\n",
            "n_traj = len(dataset)\n",
            "n_traj is 100\n",
            "n_tp_data = dataset.shape[1]\n",
            "n_tp_data is 200\n",
            "n_reduced_tp = args.timepoints\n",
            "n_reduced_tp is 100\n",
            "\n",
            "\n",
            "start_ind = np.random.randint(0, high=n_tp_data - n_reduced_tp +1, size=n_traj)\n",
            "start_ind.shape is (100,)\n",
            "end_ind = start_ind + n_reduced_tp\n",
            "end_ind.shape is (100,)\n",
            "for i in range(n_traj):\n",
            "   sliced.append(dataset[i, start_ind[i] : end_ind[i], :])\n",
            "dataset = torch.stack(sliced).to(device)\n",
            "dataset.shape is torch.Size([100, 100, 14])\n",
            "time_steps = time_steps[:n_reduced_tp]\n",
            "time_steps.shape is torch.Size([100])\n",
            "\n",
            "\n",
            "Using split_train_test()\n",
            "train_y.shape is torch.Size([80, 100, 14])\n",
            "test_y.shape is torch.Size([20, 100, 14])\n",
            "n_samples is 100\n",
            "input_dim is 14\n",
            "batch_size = min(args.batch_size, args.n)\n",
            "batch_size is 50\n",
            "\n",
            "\n",
            "Using DataLoader from from torch.utils.data import DataLoader: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
            "collate_fn (callable, optional) – merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\n",
            "data_objects has following keys: dict_keys(['dataset_obj', 'train_dataloader', 'test_dataloader', 'input_dim', 'n_train_batches', 'n_test_batches'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVOzGMhYqRlo",
        "outputId": "8c193e67-d4d2-4fee-e64a-61b798456650"
      },
      "source": [
        "input_dim = data_obj[\"input_dim\"]\n",
        "n_train_batches = data_obj['n_train_batches']\n",
        "n_test_batches = data_obj['n_test_batches']\n",
        "print(f\"input_dim is {input_dim}\")\n",
        "print(f\"n_train_batches is {n_train_batches}\")\n",
        "print(f\"n_test_batches is {n_test_batches}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_dim is 14\n",
            "n_train_batches is 2\n",
            "n_test_batches is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW_Hbre8Hs8z",
        "outputId": "bfbf0a6f-c5f3-4ede-e798-eae7c0b8e8c5"
      },
      "source": [
        "data_obj.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dataset_obj', 'train_dataloader', 'test_dataloader', 'input_dim', 'n_train_batches', 'n_test_batches'])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9acAJ4xhH_0b"
      },
      "source": [
        "classif_per_tp = False\n",
        "if (\"classif_per_tp\" in data_obj):\n",
        "  # do classification per time point rather than on a time series as a whole\n",
        "  classif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "  raise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
        "\n",
        "n_labels = 1\n",
        "if args.classif:\n",
        "  if (\"n_labels\" in data_obj):\n",
        "    n_labels = data_obj[\"n_labels\"]\n",
        "  else:\n",
        "    raise Exception(\"Please provide number of labels for classification task\")\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmrRsoTWI2Z4",
        "outputId": "d2b1a632-6193-4646-d181-cfd579bfd91f"
      },
      "source": [
        "print(f\"n_labels is {n_labels}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_labels is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGFg8VmZIt3N",
        "outputId": "6671f02f-b534-4abc-c896-2ef295924f4b"
      },
      "source": [
        "obsrv_std = 0.01\n",
        "if args.dataset == \"hopper\":\n",
        "  obsrv_std = 1e-3 \n",
        "\n",
        "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "print(f\"obsrv_std is {obsrv_std}\")\n",
        "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
        "print(f\"z0_prior is {z0_prior}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obsrv_std is tensor([0.0010])\n",
            "z0_prior is Normal(loc: tensor([0.]), scale: tensor([1.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es2YTFkSI0_D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "braJwCR6RTrz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRFpJMNPRTnl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Srlw66gRTlC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UulIfhotRTim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRVi3J2POA-d"
      },
      "source": [
        "# For Stock Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5RUn7XROEik"
      },
      "source": [
        "# run_models.py\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "import sys\n",
        "# print(sys.argv[1:])\n",
        "\n",
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=300)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='hopper', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "sys.argv = ['-f']\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AklWRbrvOgYp"
      },
      "source": [
        "def parse_datasets(args, device):\n",
        "    def basic_collate_fn(batch, time_steps, args = args, device = device, data_type = \"train\"):\n",
        "        batch = torch.stack(batch)\n",
        "        data_dict = {\n",
        "          \"data\": batch, \n",
        "          \"time_steps\": time_steps}\n",
        "\n",
        "        data_dict = utils.split_and_subsample_batch(data_dict, args, data_type = data_type)\n",
        "        return data_dict\n",
        "    dataset_name = args.dataset\n",
        "\n",
        "    n_total_tp = args.timepoints + args.extrap\n",
        "    max_t_extrap = args.max_t / args.timepoints * n_total_tp\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}