{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVJodaa_8mQs"
      },
      "source": [
        "# Import this (important)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhfJy5RA8pHw",
        "outputId": "4ac85703-72dc-4985-a314-30232fe5e657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'torchdiffeq'...\n",
            "remote: Enumerating objects: 1138, done.\u001b[K\n",
            "remote: Counting objects: 100% (434/434), done.\u001b[K\n",
            "remote: Compressing objects: 100% (194/194), done.\u001b[K\n",
            "remote: Total 1138 (delta 256), reused 400 (delta 240), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (1138/1138), 8.29 MiB | 8.71 MiB/s, done.\n",
            "Resolving deltas: 100% (682/682), done.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ],
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnIz6ghoAA9H"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf82UlO58phm"
      },
      "source": [
        "# Rough"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4d8700-2uyv"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "c8U0VQjD2hH8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fDkAwSb2-N2"
      },
      "outputs": [],
      "source": [
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from generate_timeseries import Periodic_1d\n",
        "from torch.distributions import uniform\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from mujoco_physics import HopperPhysics\n",
        "from physionet import PhysioNet, variable_time_collate_fn, get_data_min_max\n",
        "from person_activity import PersonActivity, variable_time_collate_fn_activity\n",
        "\n",
        "from sklearn import model_selection\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w5cfx1I8uz2"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NljGxF4I3YGF"
      },
      "outputs": [],
      "source": [
        "n = 1000  # size of dataset\n",
        "niters = 500  # number of iterations\n",
        "lr = 1e-3  # Starting Learning Rate\n",
        "b = 50  # batch_size\n",
        "viz = True  # show plots while training\n",
        "# save: path for saving checkpoints\n",
        "# load: ID of the experiment to load for evaluation\n",
        "random_seed = 1991 # random seed\n",
        "# dataset = Dataset to load. Available: physionet, activity, hopper, periodic\n",
        "sample_tp = None # number of time points to sub-sample.  If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\n",
        "c = None # Cut out the section of the timeline of the specified length (in number of points\n",
        "# quantization: Quantization on the physionet dataset.\" \"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\n",
        "latent_ode = None # latent ode with ode-rnn encoder\n",
        "# z0-encoder = odernn # Type of encoder for Latent ODE model: odernn or rnn\n",
        "# classic-rnn\n",
        "# rnn-cell\n",
        "# input-decay\n",
        "# ode-rnn # Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\n",
        "# rnn-vae  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\n",
        "latents = 10 # size of the latent state\n",
        "rec_dims = 20 # dimensionality of the recognition model (ODE or RNN)\n",
        "rec_layers = 1 # Number of layers in ODE func in recognition ODE\n",
        "gen_layers = 1 # Number of layers in ODE func in generative ODE\n",
        "units = 100 # Number of units per layer in ODE func\n",
        "gru_units = 100 # Number of units per layer in each of GRU update networks\n",
        "poisson = 'store_true' # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
        "classif = 'store_true' # Include binary classification loss -- used for Physionet dataset for hospiral mortality\n",
        "linear_classif = 'store_true' # If using a classifier, use a linear classifier instead of 1-layer NN\n",
        "extrap = 'store_true' # Set extrapolation mode. If this flag is not set, run interpolation mode\n",
        "timepoints = 100 # total number of timepoints\n",
        "max_tp = 5. # We subsample points in the interval [0, args.max_tp]\n",
        "noise_weight = 0.01 # Noise amplitude for generated traejctories\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4nhr13w7k3h",
        "outputId": "48146850-bf94-433b-fab8-049704dcebb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f03000d14b0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkVaoUde_8Py"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb7DmLfLASpy"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import uniform\n",
        "n_total_tp = 100\n",
        "max_t_extrap = max_tp/timepoints * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj5lZq4Y7x2V",
        "outputId": "29a9f073-c73a-457c-e6d2-8cf9473a1999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.7851, 3.3443, 0.1417, 1.3734, 3.0917, 0.3541, 2.0763, 0.4173, 3.6215,\n",
            "        3.9683, 3.6055, 3.8517, 1.5262, 1.1137, 3.9579, 1.0563, 3.9331, 4.4630,\n",
            "        3.0525, 4.4004, 2.8379, 1.0336, 0.1935, 2.1825, 0.0623, 0.8038, 0.1491,\n",
            "        2.8308, 4.4699, 4.7802, 0.0876, 2.9323, 0.6113, 4.8144, 0.1380, 0.2273,\n",
            "        0.5352, 1.8769, 0.4140, 0.9900, 1.5855, 2.3460, 0.2538, 1.5439, 4.2902,\n",
            "        3.2616, 2.5595, 4.6672, 3.3973, 2.9913, 1.8209, 4.3530, 3.2576, 3.6419,\n",
            "        2.3678, 1.2531, 1.5027, 0.8094, 2.2725, 3.1943, 0.9322, 0.1816, 3.5082,\n",
            "        1.3179, 3.5005, 3.7536, 4.8195, 0.2850, 4.3183, 3.9178, 1.1724, 2.6610,\n",
            "        1.8388, 0.0661, 2.3603, 1.7746, 4.1492, 0.1078, 4.0930, 2.2240, 2.0680,\n",
            "        1.2015, 3.2396, 1.0108, 2.0369, 0.2006, 1.9468, 0.9870, 0.1718, 2.8426,\n",
            "        3.3702, 4.5436, 1.2397, 1.8489, 4.0469, 2.2679, 2.1030, 1.8386, 1.4328])\n",
            "torch.Size([99])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "distribution = uniform.Uniform(torch.Tensor([0.0]),torch.Tensor([max_t_extrap]))\n",
        "time_steps_extrap =  distribution.sample(torch.Size([n_total_tp-1]))[:,0]\n",
        "print(time_steps_extrap)\n",
        "print(time_steps_extrap.shape)\n",
        "time_steps_extrap = torch.cat((torch.Tensor([0.0]), time_steps_extrap))\n",
        "print(time_steps_extrap.shape)\n",
        "time_steps_extrap = torch.sort(time_steps_extrap)[0]\n",
        "print(time_steps_extrap.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8UO_7BmEDal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKVYI0ng-B6d"
      },
      "source": [
        "# Run Model of the author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "eBYSErWB-E6H",
        "outputId": "4ba946bc-21c4-483f-a64c-4a8f09aca5a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: Latent ODE [-h] [-n N] [--niters NITERS] [--lr LR] [-b BATCH_SIZE]\n",
            "                  [--viz] [--save SAVE] [--load LOAD] [-r RANDOM_SEED]\n",
            "                  [--dataset DATASET] [-s SAMPLE_TP] [-c CUT_TP]\n",
            "                  [--quantization QUANTIZATION] [--latent-ode]\n",
            "                  [--z0-encoder Z0_ENCODER] [--classic-rnn]\n",
            "                  [--rnn-cell RNN_CELL] [--input-decay] [--ode-rnn]\n",
            "                  [--rnn-vae] [-l LATENTS] [--rec-dims REC_DIMS]\n",
            "                  [--rec-layers REC_LAYERS] [--gen-layers GEN_LAYERS]\n",
            "                  [-u UNITS] [-g GRU_UNITS] [--poisson] [--classif]\n",
            "                  [--linear-classif] [--extrap] [-t TIMEPOINTS]\n",
            "                  [--max-t MAX_T] [--noise-weight NOISE_WEIGHT]\n",
            "Latent ODE: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b3795be3-3477-4bee-97ed-b38edd553d61.json\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=300)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='periodic', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttorch.manual_seed(args.random_seed)\n",
        "\tnp.random.seed(args.random_seed)\n",
        "\n",
        "\texperimentID = args.load\n",
        "\tif experimentID is None:\n",
        "\t\t# Make a new experiment ID\n",
        "\t\texperimentID = int(SystemRandom().random()*100000)\n",
        "\tckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
        "\n",
        "\tstart = time.time()\n",
        "\tprint(\"Sampling dataset of {} training examples\".format(args.n))\n",
        "\t\n",
        "\tinput_command = sys.argv\n",
        "\tind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
        "\tif len(ind) == 1:\n",
        "\t\tind = ind[0]\n",
        "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
        "\tinput_command = \" \".join(input_command)\n",
        "\n",
        "\tutils.makedirs(\"results/\")\n",
        "\n",
        "\t##################################################################\n",
        "\tdata_obj = parse_datasets(args, device)\n",
        "\tinput_dim = data_obj[\"input_dim\"]\n",
        "\n",
        "\tclassif_per_tp = False\n",
        "\tif (\"classif_per_tp\" in data_obj):\n",
        "\t\t# do classification per time point rather than on a time series as a whole\n",
        "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "\tif args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
        "\n",
        "\tn_labels = 1\n",
        "\tif args.classif:\n",
        "\t\tif (\"n_labels\" in data_obj):\n",
        "\t\t\tn_labels = data_obj[\"n_labels\"]\n",
        "\t\telse:\n",
        "\t\t\traise Exception(\"Please provide number of labels for classification task\")\n",
        "\n",
        "\t##################################################################\n",
        "\t# Create the model\n",
        "\tobsrv_std = 0.01\n",
        "\tif args.dataset == \"hopper\":\n",
        "\t\tobsrv_std = 1e-3 \n",
        "\n",
        "\tobsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "\n",
        "\tz0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
        "\n",
        "\tif args.rnn_vae:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
        "\n",
        "\t\t# Create RNN-VAE model\n",
        "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
        "\t\t\tdevice = device, \n",
        "\t\t\trec_dims = args.rec_dims, \n",
        "\t\t\tconcat_mask = True, \n",
        "\t\t\tobsrv_std = obsrv_std,\n",
        "\t\t\tz0_prior = z0_prior,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\n",
        "\n",
        "\telif args.classic_rnn:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
        "\t\t# Create RNN model\n",
        "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\telif args.ode_rnn:\n",
        "\t\t# Create ODE-GRU model\n",
        "\t\tn_ode_gru_dims = args.latents\n",
        "\t\t\t\t\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
        "\n",
        "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
        "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\trec_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = input_dim, \n",
        "\t\t\tlatent_dim = n_ode_gru_dims,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
        "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\t\n",
        "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
        "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "\telif args.latent_ode:\n",
        "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels)\n",
        "\telse:\n",
        "\t\traise Exception(\"Model not specified\")\n",
        "\n",
        "\t##################################################################\n",
        "\n",
        "\tif args.viz:\n",
        "\t\tviz = Visualizations(device)\n",
        "\n",
        "\t##################################################################\n",
        "\t\n",
        "\t#Load checkpoint and evaluate the model\n",
        "\tif args.load is not None:\n",
        "\t\tutils.get_ckpt_model(ckpt_path, model, device)\n",
        "\t\texit()\n",
        "\n",
        "\t##################################################################\n",
        "\t# Training\n",
        "\n",
        "\tlog_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
        "\tif not os.path.exists(\"logs/\"):\n",
        "\t\tutils.makedirs(\"logs/\")\n",
        "\tlogger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(__file__))\n",
        "\tlogger.info(input_command)\n",
        "\n",
        "\toptimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
        "\n",
        "\tnum_batches = data_obj[\"n_train_batches\"]\n",
        "\n",
        "\tfor itr in range(1, num_batches * (args.niters + 1)):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tutils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
        "\n",
        "\t\twait_until_kl_inc = 10\n",
        "\t\tif itr // num_batches < wait_until_kl_inc:\n",
        "\t\t\tkl_coef = 0.\n",
        "\t\telse:\n",
        "\t\t\tkl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
        "\n",
        "\t\tbatch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
        "\t\ttrain_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)\n",
        "\t\ttrain_res[\"loss\"].backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\tn_iters_to_viz = 1\n",
        "\t\tif itr % (n_iters_to_viz * num_batches) == 0:\n",
        "\t\t\twith torch.no_grad():\n",
        "\n",
        "\t\t\t\ttest_res = compute_loss_all_batches(model, \n",
        "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
        "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
        "\t\t\t\t\texperimentID = experimentID,\n",
        "\t\t\t\t\tdevice = device,\n",
        "\t\t\t\t\tn_traj_samples = 3, kl_coef = kl_coef)\n",
        "\n",
        "\t\t\t\tmessage = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
        "\t\t\t\t\titr//num_batches, \n",
        "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
        "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
        "\t\t \t\n",
        "\t\t\t\tlogger.info(\"Experiment \" + str(experimentID))\n",
        "\t\t\t\tlogger.info(message)\n",
        "\t\t\t\tlogger.info(\"KL coef: {}\".format(kl_coef))\n",
        "\t\t\t\tlogger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
        "\t\t\t\tlogger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif \"auc\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
        "\n",
        "\t\t\t\tif \"mse\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
        "\n",
        "\t\t\t\tif \"accuracy\" in train_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
        "\n",
        "\t\t\t\tif \"accuracy\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
        "\n",
        "\t\t\t\tif \"pois_likelihood\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
        "\n",
        "\t\t\t\tif \"ce_loss\" in test_res:\n",
        "\t\t\t\t\tlogger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
        "\n",
        "\t\t\ttorch.save({\n",
        "\t\t\t\t'args': args,\n",
        "\t\t\t\t'state_dict': model.state_dict(),\n",
        "\t\t\t}, ckpt_path)\n",
        "\n",
        "\n",
        "\t\t\t# Plotting\n",
        "\t\t\tif args.viz:\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\ttest_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])\n",
        "\n",
        "\t\t\t\t\tprint(\"plotting....\")\n",
        "\t\t\t\t\tif isinstance(model, LatentODE) and (args.dataset == \"periodic\"): #and not args.classic_rnn and not args.ode_rnn:\n",
        "\t\t\t\t\t\tplot_id = itr // num_batches // n_iters_to_viz\n",
        "\t\t\t\t\t\tviz.draw_all_plots_one_dim(test_dict, model, \n",
        "\t\t\t\t\t\t\tplot_name = file_name + \"_\" + str(experimentID) + \"_{:03d}\".format(plot_id) + \".png\",\n",
        "\t\t\t\t\t\t \texperimentID = experimentID, save=True)\n",
        "\t\t\t\t\t\tplt.pause(0.01)\n",
        "\ttorch.save({\n",
        "\t\t'args': args,\n",
        "\t\t'state_dict': model.state_dict(),\n",
        "\t}, ckpt_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG4mctCz-Fv7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juPmjjMF_7oA"
      },
      "source": [
        "# Break it down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0fP80LJ_928",
        "outputId": "54ffaba5-1862-46ae-aed0-990773a9f517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'torchdiffeq' already exists and is not an empty directory.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Attempting uninstall: torchdiffeq\n",
            "    Found existing installation: torchdiffeq 0.2.2\n",
            "    Can't uninstall 'torchdiffeq'. No files were found to uninstall.\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py\n"
          ]
        }
      ],
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFjl3iKBAECB"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "mHuQH-oTADRa"
      },
      "outputs": [],
      "source": [
        "# run_models.py\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "import sys\n",
        "# print(sys.argv[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNCXSGE0OSjP"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "xaYoHqr9AX-P"
      },
      "outputs": [],
      "source": [
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=300)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='hopper', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', default = True, action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "sys.argv = ['-f']\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)  # saves in 'experiments/' folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdatPwwYOVx5"
      },
      "source": [
        "## Manual seed, experimentID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu69paaHCAS4",
        "outputId": "27021f69-0b3e-4db5-87e8-0eee73cbee11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experimentID is None\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(args.random_seed)\n",
        "np.random.seed(args.random_seed)\n",
        "\n",
        "experimentID = args.load  # None\n",
        "print(f\"experimentID is {experimentID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYDzsdK9B-NF",
        "outputId": "86ec92be-d82a-4090-ca75-503374d9bc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experimentID is 34150\n",
            "ckpt_path is experiments/experiment_34150.ckpt\n"
          ]
        }
      ],
      "source": [
        "if experimentID is None:\n",
        "\t\t# Make a new experiment ID\n",
        "\t\texperimentID = int(SystemRandom().random()*100000) # from random import SystemRandom\n",
        "print(f\"experimentID is {experimentID}\")\n",
        "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt') \n",
        "print(f\"ckpt_path is {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3hevLCAC2tS",
        "outputId": "de339ab1-ae0e-4977-ab9e-400bec9bf365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling dataset of 100 training examples\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "print(\"Sampling dataset of {} training examples\".format(args.n))  # n is size of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rCv2MoGjKL",
        "outputId": "d6232bf1-8800-4bb1-8595-cef6d8819890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type of args is <class 'argparse.Namespace'>\n",
            "args is Namespace(batch_size=50, classic_rnn=False, classif=False, cut_tp=None, dataset='hopper', extrap=False, gen_layers=1, gru_units=100, input_decay=False, latent_ode=True, latents=6, linear_classif=False, load=None, lr=0.01, max_t=5.0, n=100, niters=300, noise_weight=0.01, ode_rnn=False, poisson=False, quantization=0.1, random_seed=1991, rec_dims=20, rec_layers=1, rnn_cell='gru', rnn_vae=False, sample_tp=None, save='experiments/', timepoints=100, units=100, viz=False, z0_encoder='odernn')\n"
          ]
        }
      ],
      "source": [
        "print(f\"type of args is {type(args)}\")\n",
        "print(f\"args is {str(args)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7TpUY3BLIP",
        "outputId": "05e84d67-490e-40ef-b9cb-28ff69ec80e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_command is ['-f']\n"
          ]
        }
      ],
      "source": [
        "input_command = sys.argv\n",
        "print(f\"input_command is {input_command}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcTvI3I2GVlj",
        "outputId": "4f017cea-c8ca-40e8-b5ab-51d0a678cba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ind is []\n",
            "len(ind) is 0\n"
          ]
        }
      ],
      "source": [
        "ind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
        "print(f\"ind is {ind}\")\n",
        "print(f\"len(ind) is {len(ind)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvrwritSGX56",
        "outputId": "40c61bcb-9885-40af-de23-20dfd8016c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_command is -f\n"
          ]
        }
      ],
      "source": [
        "if len(ind) == 1:\n",
        "\t\tind = ind[0]\n",
        "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
        "input_command = \" \".join(input_command)\n",
        "print(f\"input_command is {input_command}\")\n",
        "utils.makedirs(\"results/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNxDMKpNObYB"
      },
      "source": [
        "## parse_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsSKx1IeG4Wn",
        "outputId": "2e9a9a44-ca2f-44ca-a5e8-70775d6efa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the function parse_datasets from parse_datasets.py\n",
            "Inputs are (args, device)\n",
            "dataset_name is hopper\n",
            "\n",
            "\n",
            "args.timepoints is 100\n",
            "args.extrap is False\n",
            "n_total_tp = args.timepoints + args.extrap  --> is 100\n",
            "\n",
            "\n",
            "args.max_t is 5.0\n",
            "max_t_extrap = args.max_t / args.timepoints * n_total_tp --> 5.0\n",
            "\n",
            "\n",
            "if dataset_name == 'hopper'\n",
            "root is data\n",
            "Let's download\n",
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "data_file is data/HopperPhysics/training.pt\n",
            "Using torch.Tensor(torch.load(data_file)).to(device) to get self.data\n",
            "self.data.shape is torch.Size([10000, 200, 14])\n",
            "\n",
            "\n",
            "Using normalize_data()\n",
            "data.shape is torch.Size([10000, 200, 14])\n",
            "reshaped = data.reshape(-1, data.size(-1))\n",
            "reshaped.shape is torch.Size([2000000, 14])\n",
            "att_min = torch.min(reshaped, 0)[0]\n",
            "att_min.shape is torch.Size([14])\n",
            "att_max = torch.max(reshaped, 0)[0]\n",
            "att_max.shape is torch.Size([14])\n",
            "data_norm = (data - att_min) / att_max\n",
            "dataset.shape is torch.Size([100, 200, 14])\n",
            "\n",
            "\n",
            "n_tp_data = dataset[:].shape[1]\n",
            "n_tp_data is 200\n",
            "\n",
            "\n",
            "time_steps.shape is torch.Size([200])\n",
            "time_steps = time_steps / len(time_steps)\n",
            "time_steps.shape is torch.Size([200])\n",
            "\n",
            "\n",
            "if not args.extrap\n",
            "# Creating dataset for interpolation\n",
            "# sample time points from different parts of the timeline, \n",
            "# so that the model learns from different parts of hopper trajectory\n",
            "n_traj = len(dataset)\n",
            "n_traj is 100\n",
            "n_tp_data = dataset.shape[1]\n",
            "n_tp_data is 200\n",
            "n_reduced_tp = args.timepoints\n",
            "n_reduced_tp is 100\n",
            "\n",
            "\n",
            "start_ind = np.random.randint(0, high=n_tp_data - n_reduced_tp +1, size=n_traj)\n",
            "start_ind.shape is (100,)\n",
            "end_ind = start_ind + n_reduced_tp\n",
            "end_ind.shape is (100,)\n",
            "for i in range(n_traj):\n",
            "   sliced.append(dataset[i, start_ind[i] : end_ind[i], :])\n",
            "dataset = torch.stack(sliced).to(device)\n",
            "dataset.shape is torch.Size([100, 100, 14])\n",
            "time_steps = time_steps[:n_reduced_tp]\n",
            "time_steps.shape is torch.Size([100])\n",
            "\n",
            "\n",
            "Using split_train_test()\n",
            "train_y.shape is torch.Size([80, 100, 14])\n",
            "test_y.shape is torch.Size([20, 100, 14])\n",
            "n_samples is 100\n",
            "input_dim is 14\n",
            "batch_size = min(args.batch_size, args.n)\n",
            "batch_size is 50\n",
            "\n",
            "\n",
            "Using DataLoader from from torch.utils.data import DataLoader: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
            "collate_fn (callable, optional) – merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\n",
            "data_objects has following keys: dict_keys(['dataset_obj', 'train_dataloader', 'test_dataloader', 'input_dim', 'n_train_batches', 'n_test_batches'])\n"
          ]
        }
      ],
      "source": [
        "data_obj = parse_datasets(args, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVOzGMhYqRlo",
        "outputId": "27636303-38a4-4003-f1d4-13ba0fbc39f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim is 14\n",
            "n_train_batches is 2\n",
            "n_test_batches is 1\n"
          ]
        }
      ],
      "source": [
        "input_dim = data_obj[\"input_dim\"]\n",
        "n_train_batches = data_obj['n_train_batches']\n",
        "n_test_batches = data_obj['n_test_batches']\n",
        "print(f\"input_dim is {input_dim}\")\n",
        "print(f\"n_train_batches is {n_train_batches}\")\n",
        "print(f\"n_test_batches is {n_test_batches}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW_Hbre8Hs8z",
        "outputId": "432af5c9-dda2-4c6b-a632-40b515b98bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['dataset_obj', 'train_dataloader', 'test_dataloader', 'input_dim', 'n_train_batches', 'n_test_batches'])"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_obj.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG8UQWqRytd"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "9acAJ4xhH_0b"
      },
      "outputs": [],
      "source": [
        "classif_per_tp = False\n",
        "if (\"classif_per_tp\" in data_obj):\n",
        "  # do classification per time point rather than on a time series as a whole\n",
        "  classif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "  raise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
        "\n",
        "n_labels = 1\n",
        "if args.classif:\n",
        "  if (\"n_labels\" in data_obj):\n",
        "    n_labels = data_obj[\"n_labels\"]\n",
        "  else:\n",
        "    raise Exception(\"Please provide number of labels for classification task\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmrRsoTWI2Z4",
        "outputId": "8a56ccb6-c51c-4ff7-991c-e523d2454b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_labels is 1\n"
          ]
        }
      ],
      "source": [
        "print(f\"n_labels is {n_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGFg8VmZIt3N",
        "outputId": "372760e4-ebef-4cac-fdef-22b59b0f11f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obsrv_std is tensor([0.0010])\n",
            "z0_prior is Normal(loc: tensor([0.]), scale: tensor([1.]))\n"
          ]
        }
      ],
      "source": [
        "obsrv_std = 0.01\n",
        "if args.dataset == \"hopper\":\n",
        "  obsrv_std = 1e-3 \n",
        "\n",
        "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "print(f\"obsrv_std is {obsrv_std}\")\n",
        "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
        "print(f\"z0_prior is {z0_prior}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es2YTFkSI0_D",
        "outputId": "205e1ee2-6a49-49d6-af44-fb0f5e607435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inside create_LatentODE_model\n",
            "dim is 6\n",
            "\n",
            "\n",
            "Making ode_func_net\n",
            "Inside create_net function\n",
            "n_input for layers is 6\n",
            "n_units for layers is 100\n",
            "n_layers is 1\n",
            "nonlinear is <class 'torch.nn.modules.activation.Tanh'>\n",
            "for i in range(n_layers):\n",
            "    layers.append(nonlinear())\n",
            "    layers.append(nn.Linear(n_units, n_units))\n",
            "layers.append(nonlinear())\n",
            "layers.append(nn.Linear(n_units, n_outputs))\n",
            "n_outputs is 6\n",
            "Making gen_ode_func\n",
            "Inside ODEFunc class\n",
            "input_dim is 14\n",
            "latent_dim is 6\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Making ode_func_net for odernn\n",
            "Inside create_net function\n",
            "n_input for layers is 20\n",
            "n_units for layers is 100\n",
            "n_layers is 1\n",
            "nonlinear is <class 'torch.nn.modules.activation.Tanh'>\n",
            "for i in range(n_layers):\n",
            "    layers.append(nonlinear())\n",
            "    layers.append(nn.Linear(n_units, n_units))\n",
            "layers.append(nonlinear())\n",
            "layers.append(nn.Linear(n_units, n_outputs))\n",
            "n_outputs is 20\n",
            "Making rec_ode_func using ODEFunc\n",
            "Inside ODEFunc class\n",
            "input_dim is 28\n",
            "latent_dim is 20\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside DiffeqSolver\n",
            "Inside GRU unit\n",
            "\n",
            "\n",
            "self.update_gate = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "self.reset_gate = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "self.new_state_net = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside DiffeqSolver\n"
          ]
        }
      ],
      "source": [
        "if args.latent_ode:\n",
        "    model = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
        "            classif_per_tp = classif_per_tp,\n",
        "            n_labels = n_labels)\n",
        "else:\n",
        "\traise Exception(\"Model not specified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Ws47_S1R99",
        "outputId": "ddc514fe-a50d-4fe4-a96a-13d08ea96410"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "/content\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n",
            "-f\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimizer is Adamax (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.01\n",
            "    weight_decay: 0\n",
            ")\n",
            "num_batches is 2\n"
          ]
        }
      ],
      "source": [
        "file_name = os.path.abspath('')\n",
        "log_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
        "if not os.path.exists(\"logs/\"):\n",
        "    utils.makedirs(\"logs/\")\n",
        "logger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(''))\n",
        "logger.info(input_command)\n",
        "\n",
        "optimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
        "print(f\"optimizer is {optimizer}\")\n",
        "num_batches = data_obj[\"n_train_batches\"]\n",
        "print(f\"num_batches is {num_batches}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "0rGaP-051NC2",
        "outputId": "11347b4c-52fa-4ed5-dbd8-7af50de53f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning rate is 0.00999\n",
            "kl_coef is 0.0\n",
            "Using basic_collate_fn function\n",
            "Inputs are (batch, time_steps, args = args, device = device, data_type = 'train')\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-313-89f659c0a1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mkl_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwait_until_kl_inc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"kl_coef is {kl_coef}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_dataloader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_all_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_traj_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/utils.py\u001b[0m in \u001b[0;36mget_next_batch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;31m# Make the union of all time points and perform normalization across the whole dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/utils.py\u001b[0m in \u001b[0;36minf_generator\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/lib/parse_datasets.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"collate_fn (callable, optional) – merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     train_dataloader = DataLoader(train_y, batch_size = batch_size, shuffle=False,\n\u001b[0;32m--> 144\u001b[0;31m         collate_fn= lambda batch: basic_collate_fn(batch, time_steps, data_type = \"train\"))\n\u001b[0m\u001b[1;32m    145\u001b[0m     test_dataloader = DataLoader(test_y, batch_size = n_samples, shuffle=False,\n\u001b[1;32m    146\u001b[0m         collate_fn= lambda batch: basic_collate_fn(batch, time_steps, data_type = \"test\"))\n",
            "\u001b[0;32m/content/lib/parse_datasets.py\u001b[0m in \u001b[0;36mbasic_collate_fn\u001b[0;34m(batch, time_steps, args, device, data_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using basic_collate_fn function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Inputs are (batch, time_steps, args = args, device = device, data_type = 'train')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"batch.shape is {batch.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# print(f\"batch is {batch}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"timesteps are {timesteps}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "for itr in range(1, num_batches * (args.niters + 1)):\n",
        "    optimizer.zero_grad()\n",
        "    utils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
        "    print(f\"learning rate is {optimizer.param_groups[0]['lr']}\")\n",
        "    wait_until_kl_inc = 10\n",
        "    if itr // num_batches < wait_until_kl_inc:\n",
        "        kl_coef = 0.\n",
        "    else:\n",
        "        kl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
        "    print(f\"kl_coef is {kl_coef}\")\n",
        "    batch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
        "    train_res = model.compute_all_losses(batch_dict, n_traj_samples = 1, kl_coef = kl_coef)\n",
        "    train_res[\"loss\"].backward()\n",
        "    optimizer.step()\n",
        "    n_iters_to_viz = 1\n",
        "\n",
        "    if itr % (n_iters_to_viz * num_batches) == 0:\n",
        "    \twith torch.no_grad():\n",
        "            test_res = compute_loss_all_batches(model, \n",
        "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
        "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
        "\t\t\t\t\texperimentID = experimentID,\n",
        "\t\t\t\t\tdevice = device,\n",
        "\t\t\t\t\tn_traj_samples = 1, kl_coef = kl_coef)\n",
        "            message = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
        "\t\t\t\t\titr//num_batches, \n",
        "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
        "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
        "            \n",
        "            logger.info(\"Experiment \" + str(experimentID))\n",
        "            logger.info(message)\n",
        "            logger.info(\"KL coef: {}\".format(kl_coef))\n",
        "            logger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
        "            logger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
        "\n",
        "            if \"auc\" in test_res:\n",
        "                logger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
        "\n",
        "            if \"mse\" in test_res:\n",
        "                logger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
        "\n",
        "            if \"accuracy\" in train_res:\n",
        "                logger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
        "\n",
        "            if \"accuracy\" in test_res:\n",
        "                logger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
        "\n",
        "            if \"pois_likelihood\" in test_res:\n",
        "                logger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
        "\n",
        "            if \"ce_loss\" in test_res:\n",
        "                logger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
        "\n",
        "\n",
        "            torch.save({\n",
        "\t\t\t\t'args': args,\n",
        "\t\t\t\t'state_dict': model.state_dict(),\n",
        "\t\t\t}, ckpt_path)\n",
        "    \n",
        "torch.save({\n",
        "    'args': args,\n",
        "    'state_dict': model.state_dict(),\n",
        "}, ckpt_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "braJwCR6RTrz"
      },
      "outputs": [],
      "source": [
        "t1 = torch.tensor([1,2,3,4]) \n",
        "t2 = torch.tensor([5,6,7,8]) \n",
        "t3 = torch.tensor([9,10,11,12])\n",
        "\n",
        "t = torch.stack(\n",
        "    (t1,t2,t3)\n",
        "    ,dim=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRFpJMNPRTnl",
        "outputId": "5287c4c9-fd93-4b38-ea7e-3102413e31fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1],\n",
              "         [2],\n",
              "         [3],\n",
              "         [4]]), tensor([[ 5,  9],\n",
              "         [ 6, 10],\n",
              "         [ 7, 11],\n",
              "         [ 8, 12]]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "utils.split_last_dim(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7Srlw66gRTlC"
      },
      "outputs": [],
      "source": [
        "from lib import utils as utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulIfhotRTim",
        "outputId": "eadc9d8e-b958-49f9-afe1-cb2a403c3491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1],\n",
              "         [2],\n",
              "         [3],\n",
              "         [4]]), tensor([[ 5,  9],\n",
              "         [ 6, 10],\n",
              "         [ 7, 11],\n",
              "         [ 8, 12]]))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "utils.split_last_dim(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRVi3J2POA-d"
      },
      "source": [
        "# For Stock Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdhXnHBitsXf",
        "outputId": "cb119209-1949-4b71-81fa-fda6afcea48e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'torchdiffeq' already exists and is not an empty directory.\n",
            "Obtaining file:///content/torchdiffeq\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq==0.2.2) (3.7.4.3)\n",
            "Installing collected packages: torchdiffeq\n",
            "  Attempting uninstall: torchdiffeq\n",
            "    Found existing installation: torchdiffeq 0.2.2\n",
            "    Can't uninstall 'torchdiffeq'. No files were found to uninstall.\n",
            "  Running setup.py develop for torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.2\n",
            "_impl  __init__.py  __pycache__\n"
          ]
        }
      ],
      "source": [
        "# Install the latest version of author's repo neural ode implementation\n",
        "!git clone https://github.com/rtqichen/torchdiffeq.git\n",
        "!cd torchdiffeq && pip install -e .\n",
        "!ls torchdiffeq/torchdiffeq\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE5l_KMEuJeR"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9_9gEN7qtxuC"
      },
      "outputs": [],
      "source": [
        "# run_models.py\n",
        "import os\n",
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import torch.optim as optim\n",
        "\n",
        "import lib.utils as utils\n",
        "# from lib.plotting import *\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "# from lib.ode_rnn import *\n",
        "# from lib.create_latent_ode_model import create_LatentODE_model\n",
        "# from lib.parse_datasets import parse_datasets\n",
        "# from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "# from mujoco_physics import HopperPhysics\n",
        "\n",
        "from lib.utils import compute_loss_all_batches\n",
        "\n",
        "import sys\n",
        "# print(sys.argv[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8wEQAF0uHYF"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m5RUn7XROEik"
      },
      "outputs": [],
      "source": [
        "# Generative model for noisy data based on ODE\n",
        "parser = argparse.ArgumentParser('Latent ODE')\n",
        "parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
        "parser.add_argument('--niters', type=int, default=10)\n",
        "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=50)\n",
        "parser.add_argument('--viz', action='store_true', help=\"Show plots while training\")\n",
        "\n",
        "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
        "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
        "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='hopper', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
        "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
        "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
        "\n",
        "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
        "\t\"Used for periodic function demo.\")\n",
        "\n",
        "parser.add_argument('--quantization', type=float, default=0.1, help=\"Quantization on the physionet dataset.\"\n",
        "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
        "\n",
        "parser.add_argument('--latent-ode', default = True, action='store_true', help=\"Run Latent ODE seq2seq model\")\n",
        "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
        "\n",
        "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
        "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
        "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
        "\n",
        "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
        "\n",
        "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
        "\n",
        "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
        "parser.add_argument('--rec-dims', type=int, default=20, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
        "\n",
        "parser.add_argument('--rec-layers', type=int, default=1, help=\"Number of layers in ODE func in recognition ODE\")\n",
        "parser.add_argument('--gen-layers', type=int, default=1, help=\"Number of layers in ODE func in generative ODE\")\n",
        "\n",
        "parser.add_argument('-u', '--units', type=int, default=100, help=\"Number of units per layer in ODE func\")\n",
        "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
        "\n",
        "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
        "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
        "\n",
        "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
        "parser.add_argument('--extrap', default = False, action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
        "\n",
        "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
        "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
        "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
        "\n",
        "sys.argv = ['-f']\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# file_name = os.path.basename(__file__)[:-3]\n",
        "utils.makedirs(args.save)  # saves in 'experiments/' folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNEj_b_nuDHe"
      },
      "source": [
        "## Manual seed, experimentID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AklWRbrvOgYp",
        "outputId": "331d8326-f549-407a-ece1-e413e8851391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experimentID is None\n",
            "experimentID is 46595\n",
            "ckpt_path is experiments/experiment_46595.ckpt\n",
            "Sampling dataset of 100 training examples\n",
            "args is Namespace(batch_size=50, classic_rnn=False, classif=False, cut_tp=None, dataset='hopper', extrap=False, gen_layers=1, gru_units=100, input_decay=False, latent_ode=True, latents=6, linear_classif=False, load=None, lr=0.01, max_t=5.0, n=100, niters=10, noise_weight=0.01, ode_rnn=False, poisson=False, quantization=0.1, random_seed=1991, rec_dims=20, rec_layers=1, rnn_cell='gru', rnn_vae=False, sample_tp=None, save='experiments/', timepoints=100, units=100, viz=False, z0_encoder='odernn')\n",
            "input_command is ['-f']\n",
            "ind is []\n",
            "len(ind) is 0\n",
            "input_command is -f\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(args.random_seed)\n",
        "np.random.seed(args.random_seed)\n",
        "\n",
        "experimentID = args.load  # None\n",
        "print(f\"experimentID is {experimentID}\")\n",
        "\n",
        "if experimentID is None:\n",
        "\t\t# Make a new experiment ID\n",
        "\t\texperimentID = int(SystemRandom().random()*100000) # from random import SystemRandom\n",
        "print(f\"experimentID is {experimentID}\")\n",
        "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt') \n",
        "print(f\"ckpt_path is {ckpt_path}\")\n",
        "\n",
        "start = time.time()\n",
        "print(\"Sampling dataset of {} training examples\".format(args.n))  # n is size of the dataset\n",
        "\n",
        "print(f\"args is {str(args)}\")\n",
        "\n",
        "input_command = sys.argv\n",
        "print(f\"input_command is {input_command}\")\n",
        "\n",
        "ind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
        "print(f\"ind is {ind}\")\n",
        "print(f\"len(ind) is {len(ind)}\")\n",
        "\n",
        "if len(ind) == 1:\n",
        "\t\tind = ind[0]\n",
        "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
        "input_command = \" \".join(input_command)\n",
        "print(f\"input_command is {input_command}\")\n",
        "utils.makedirs(\"results/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6eEFp6q2onU"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Fl56I3uVGJ",
        "outputId": "88a0652c-73d0-4b1e-c25a-7026730238d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.64)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.3)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTD8BTd02qeX",
        "outputId": "bd2b98a9-8ef9-404f-b64a-d5c3d6c361f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get Open and Close Price of Assets\n",
            "\n",
            "\n",
            "The size of each asset\n",
            "Apple size: 5450\n",
            "Microsoft size: 5450\n",
            "Google size: 4288\n",
            "Bitcoin size: 2537\n",
            "Facebook size: 2336\n",
            "Walmart size: 5450\n",
            "Amazon size: 5450\n",
            "CVS size: 5450\n",
            "Berkshire size: 5450\n",
            "ExxonMobil size: 5450\n",
            "AtandT size: 5450\n",
            "Costco size: 5450\n",
            "Walgreens size: 5450\n",
            "Kroger size: 5450\n",
            "JPMorgan size: 5450\n",
            "Verizon size: 5450\n",
            "FordMotor size: 5450\n",
            "GeneralMotors size: 2713\n",
            "Dell size: 1268\n",
            "BankOfAmerica size: 5450\n",
            "Target size: 5450\n",
            "GeneralElectric size: 5450\n",
            "JohnsonandJohnson size: 5450\n",
            "Nvidia size: 5451\n",
            "Intel size: 5450\n",
            "Apple data.shape (1090, 10)\n",
            "Apple Data Original after series to supervised on data (1085, 60)\n",
            "Apple Median data\n",
            "Apple median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Apple Median data after series to supervised\n",
            "Apple data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Microsoft data.shape (1090, 10)\n",
            "Microsoft Data Original after series to supervised on data (1085, 60)\n",
            "Microsoft Median data\n",
            "Microsoft median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Microsoft Median data after series to supervised\n",
            "Microsoft data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Google data.shape (856, 10)\n",
            "Google Data Original after series to supervised on data (851, 60)\n",
            "Google Median data\n",
            "Google median_data.shape (856, 1)\n",
            "\n",
            "\n",
            "Google Median data after series to supervised\n",
            "Google data_m1.shape (851, 6)\n",
            "\n",
            "\n",
            "Bitcoin data.shape (506, 10)\n",
            "Bitcoin Data Original after series to supervised on data (501, 60)\n",
            "Bitcoin Median data\n",
            "Bitcoin median_data.shape (506, 1)\n",
            "\n",
            "\n",
            "Bitcoin Median data after series to supervised\n",
            "Bitcoin data_m1.shape (501, 6)\n",
            "\n",
            "\n",
            "Facebook data.shape (466, 10)\n",
            "Facebook Data Original after series to supervised on data (461, 60)\n",
            "Facebook Median data\n",
            "Facebook median_data.shape (466, 1)\n",
            "\n",
            "\n",
            "Facebook Median data after series to supervised\n",
            "Facebook data_m1.shape (461, 6)\n",
            "\n",
            "\n",
            "Walmart data.shape (1090, 10)\n",
            "Walmart Data Original after series to supervised on data (1085, 60)\n",
            "Walmart Median data\n",
            "Walmart median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Walmart Median data after series to supervised\n",
            "Walmart data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Amazon data.shape (1090, 10)\n",
            "Amazon Data Original after series to supervised on data (1085, 60)\n",
            "Amazon Median data\n",
            "Amazon median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Amazon Median data after series to supervised\n",
            "Amazon data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "CVS data.shape (1090, 10)\n",
            "CVS Data Original after series to supervised on data (1085, 60)\n",
            "CVS Median data\n",
            "CVS median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "CVS Median data after series to supervised\n",
            "CVS data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Berkshire data.shape (1090, 10)\n",
            "Berkshire Data Original after series to supervised on data (1085, 60)\n",
            "Berkshire Median data\n",
            "Berkshire median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Berkshire Median data after series to supervised\n",
            "Berkshire data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "ExxonMobil data.shape (1090, 10)\n",
            "ExxonMobil Data Original after series to supervised on data (1085, 60)\n",
            "ExxonMobil Median data\n",
            "ExxonMobil median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "ExxonMobil Median data after series to supervised\n",
            "ExxonMobil data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "AtandT data.shape (1090, 10)\n",
            "AtandT Data Original after series to supervised on data (1085, 60)\n",
            "AtandT Median data\n",
            "AtandT median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "AtandT Median data after series to supervised\n",
            "AtandT data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Costco data.shape (1090, 10)\n",
            "Costco Data Original after series to supervised on data (1085, 60)\n",
            "Costco Median data\n",
            "Costco median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Costco Median data after series to supervised\n",
            "Costco data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Walgreens data.shape (1090, 10)\n",
            "Walgreens Data Original after series to supervised on data (1085, 60)\n",
            "Walgreens Median data\n",
            "Walgreens median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Walgreens Median data after series to supervised\n",
            "Walgreens data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Kroger data.shape (1090, 10)\n",
            "Kroger Data Original after series to supervised on data (1085, 60)\n",
            "Kroger Median data\n",
            "Kroger median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Kroger Median data after series to supervised\n",
            "Kroger data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "JPMorgan data.shape (1090, 10)\n",
            "JPMorgan Data Original after series to supervised on data (1085, 60)\n",
            "JPMorgan Median data\n",
            "JPMorgan median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "JPMorgan Median data after series to supervised\n",
            "JPMorgan data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Verizon data.shape (1090, 10)\n",
            "Verizon Data Original after series to supervised on data (1085, 60)\n",
            "Verizon Median data\n",
            "Verizon median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Verizon Median data after series to supervised\n",
            "Verizon data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "FordMotor data.shape (1090, 10)\n",
            "FordMotor Data Original after series to supervised on data (1085, 60)\n",
            "FordMotor Median data\n",
            "FordMotor median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "FordMotor Median data after series to supervised\n",
            "FordMotor data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "GeneralMotors data.shape (542, 10)\n",
            "GeneralMotors Data Original after series to supervised on data (537, 60)\n",
            "GeneralMotors Median data\n",
            "GeneralMotors median_data.shape (542, 1)\n",
            "\n",
            "\n",
            "GeneralMotors Median data after series to supervised\n",
            "GeneralMotors data_m1.shape (537, 6)\n",
            "\n",
            "\n",
            "Dell data.shape (252, 10)\n",
            "Dell Data Original after series to supervised on data (247, 60)\n",
            "Dell Median data\n",
            "Dell median_data.shape (252, 1)\n",
            "\n",
            "\n",
            "Dell Median data after series to supervised\n",
            "Dell data_m1.shape (247, 6)\n",
            "\n",
            "\n",
            "BankOfAmerica data.shape (1090, 10)\n",
            "BankOfAmerica Data Original after series to supervised on data (1085, 60)\n",
            "BankOfAmerica Median data\n",
            "BankOfAmerica median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "BankOfAmerica Median data after series to supervised\n",
            "BankOfAmerica data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Target data.shape (1090, 10)\n",
            "Target Data Original after series to supervised on data (1085, 60)\n",
            "Target Median data\n",
            "Target median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Target Median data after series to supervised\n",
            "Target data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "GeneralElectric data.shape (1090, 10)\n",
            "GeneralElectric Data Original after series to supervised on data (1085, 60)\n",
            "GeneralElectric Median data\n",
            "GeneralElectric median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "GeneralElectric Median data after series to supervised\n",
            "GeneralElectric data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "JohnsonandJohnson data.shape (1090, 10)\n",
            "JohnsonandJohnson Data Original after series to supervised on data (1085, 60)\n",
            "JohnsonandJohnson Median data\n",
            "JohnsonandJohnson median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "JohnsonandJohnson Median data after series to supervised\n",
            "JohnsonandJohnson data_m1.shape (1085, 6)\n",
            "\n",
            "\n",
            "Nvidia data.shape (1090, 10)\n",
            "Nvidia Data Original after series to supervised on data (1079, 60)\n",
            "Nvidia Median data\n",
            "Nvidia median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Nvidia Median data after series to supervised\n",
            "Nvidia data_m1.shape (1079, 6)\n",
            "\n",
            "\n",
            "Intel data.shape (1090, 10)\n",
            "Intel Data Original after series to supervised on data (1085, 60)\n",
            "Intel Median data\n",
            "Intel median_data.shape (1090, 1)\n",
            "\n",
            "\n",
            "Intel Median data after series to supervised\n",
            "Intel data_m1.shape (1085, 6)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Get Open and Close Price of asset (o, c) for each trading day.\n",
        "# libraries\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yf\n",
        "import os\n",
        "\n",
        "print(f\"Get Open and Close Price of Assets\")\n",
        "def download_raw_stock_data(filepath, tickers, start, end, period = '1d'):\n",
        "    \"\"\"\n",
        "    Download Stock tickers\n",
        "    :Parameters:\n",
        "        filepath: str\n",
        "            path to store the raw data\n",
        "        tickers : str, list\n",
        "            List of tickers to download\n",
        "        period: str\n",
        "            the frequency at which to gather the data; common options would include ‘1d’ (daily), ‘1mo’ (monthly), ‘1y’ (yearly)\n",
        "        start: str\n",
        "            the date to start gathering the data. For example ‘2010–1–1’\n",
        "        end: str\n",
        "            the date to end gathering the data. For example ‘2020–1–25’\n",
        "    \n",
        "    \"\"\"\n",
        "    #define the ticker symbol\n",
        "    tickerSymbol = tickers\n",
        "\n",
        "    #get data on this ticker\n",
        "    tickerData = yf.Ticker(tickerSymbol)\n",
        "\n",
        "    #get the historical prices for this ticker\n",
        "    tickerDf = tickerData.history(period=period, start=start, end=end)\n",
        "    tickerDf.to_csv(filepath)\n",
        "\n",
        "dict_tickers = {\n",
        "    'Apple': 'AAPL',\n",
        "    'Microsoft': 'MSFT',\n",
        "    'Google': 'GOOG',\n",
        "    'Bitcoin': 'BTC-USD',\n",
        "    'Facebook': 'FB',\n",
        "    'Walmart': 'WMT',\n",
        "    'Amazon': 'AMZN',\n",
        "    'CVS': 'CVS',\n",
        "    'Berkshire': 'BRK-B',\n",
        "    'ExxonMobil': 'XOM',\n",
        "    'AtandT': 'T',\n",
        "    'Costco': 'COST',\n",
        "    'Walgreens': 'WBA',\n",
        "    'Kroger': 'KR',\n",
        "    'JPMorgan': 'JPM',\n",
        "    'Verizon': 'VZ',\n",
        "    'FordMotor': 'F',\n",
        "    'GeneralMotors': 'GM',\n",
        "    'Dell': 'DELL',\n",
        "    'BankOfAmerica': 'BAC',\n",
        "    'Target': 'TGT',\n",
        "    'GeneralElectric': 'GE',\n",
        "    'JohnsonandJohnson': 'JNJ',\n",
        "    'Nvidia': 'NVDA',\n",
        "    'Intel': 'INTC',\n",
        "}\n",
        "\n",
        "path = f\"raw-stock-data/data-2000-2021\"\n",
        "if not os.path.exists(path):\n",
        "    # https://appdividend.com/2021/07/03/how-to-create-directory-if-not-exist-in-python/\n",
        "    # Create a new directory\n",
        "    os.makedirs(path)\n",
        "    print(f\"{path} directory is created\")\n",
        "period = '1d'\n",
        "start='2000-1-1'\n",
        "end='2021-8-31'\n",
        "for tickerName, ticker in dict_tickers.items():\n",
        "    tickerName = tickerName\n",
        "    ticker = ticker\n",
        "    filepath = f\"{path}/{tickerName}.csv\"\n",
        "    download_raw_stock_data(filepath, ticker, start, end, period)\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(f\"The size of each asset\")\n",
        "import pandas as pd\n",
        "for tickerName in dict_tickers.keys():\n",
        "    df = pd.read_csv(f\"{path}/{tickerName}.csv\")\n",
        "    print(f\"{tickerName} size: {len(df)}\")\n",
        "\n",
        "# 2. Get weekly data.\n",
        "# 3. Transform $d_{i}$ to sequences of lag * len($d_{i}$) length.\n",
        "\n",
        "def stockDataTransformer(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    df.set_index('Date', inplace=True)\n",
        "    df1 = df[['Open', 'Close']].copy()\n",
        "    data = df1.values\n",
        "    n_samples = data.shape[0]//10*10\n",
        "    reshape_number = n_samples*data.shape[1]//10\n",
        "    data1 = data[:n_samples].reshape((reshape_number, 10))\n",
        "    return data1\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \"\"\"\n",
        "    Frame a time series as a supervised learning dataset.\n",
        "    Arguments:\n",
        "        data: Sequence of observations as a list or NumPy array.\n",
        "        n_in: Number of lag observations as input (X).\n",
        "        n_out: Number of observations as output (y).\n",
        "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
        "    Returns:\n",
        "        Pandas DataFrame of series framed for supervised learning.\n",
        "    \"\"\"\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "def split_data(perc_train, perc_valid, lag, data_orig, data_m1, n_features_orig, n_features_median):\n",
        "    values = data_m1\n",
        "    \n",
        "    sizeOfReframed = len(data_m1)\n",
        "    len_train = int(perc_train*sizeOfReframed) # int(sizeOfReframed - len_test) # - len_valid)\n",
        "    train_data_orig = data_orig[:len_train, :]\n",
        "    # valid = values[len_train:len_valid+len_train, :]\n",
        "    test_data_orig = data_orig[len_train:, :]  # [len_valid+len_train:, :]\n",
        "    # n_features = n_features\n",
        "    \n",
        "    train_data_ml = values[:len_train, :]\n",
        "    test_data_ml = values[len_train:, :] \n",
        "    # split into input and outputs\n",
        "    n_obs = lag * n_features_orig\n",
        "    n_obs_median = (lag+forecast) * n_features_median\n",
        "    train_X, train_y = train_data_orig[:, :n_obs], train_data_ml[:, :n_obs_median]\n",
        "    test_X, test_y = test_data_orig[:, :n_obs], test_data_ml[:, :n_obs_median]\n",
        "    # valid_X, valid_y = valid[:, :n_obs], valid[:, -1]\n",
        "    print(train_X.shape, len(train_X), train_y.shape)\n",
        "    \n",
        "    # reshape input to be 3D [samples, features, lag]\n",
        "    train_X = train_X.reshape((train_X.shape[0], n_features_orig, lag))\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_features_orig, lag))\n",
        "    # valid_X = valid_X.reshape((valid_X.shape[0], lag, n_features))\n",
        "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)  # , valid_X.shape, valid_y.shape)\n",
        "    \n",
        "    # Get the reconstruction train_y, test_y and extrapolated train_y, test_y\n",
        "    train_y_recon, train_y_extrapol = train_y[:, :lag], train_y[:, lag:]\n",
        "    test_y_recon, test_y_extrapol = test_y[:, :lag], test_y[:, lag:]\n",
        "    dataload = {\n",
        "        'train_data_orig': train_data_orig,\n",
        "        'test_data_orig': test_data_orig,\n",
        "        'train_data_ml': train_data_ml,\n",
        "        'test_data_ml': test_data_ml,\n",
        "        # 'valid': valid,\n",
        "        'train_X': train_X,\n",
        "        'train_y': train_y,\n",
        "        'test_X': test_X,\n",
        "        'test_y': test_y,\n",
        "        'n_features_orig': n_features_orig,\n",
        "        'n_features_median': n_features_median,\n",
        "        'n_obs': n_obs,\n",
        "        'n_obs_median': n_obs_median,\n",
        "        # 'valid_X': valid_X,\n",
        "        # 'valid_y': valid_y,\n",
        "        'train_y_recon': train_y_recon,\n",
        "        'train_y_extrapol': train_y_extrapol,\n",
        "        'test_y_recon': test_y_recon,\n",
        "        'test_y_extrapol': test_y_extrapol\n",
        "    }\n",
        "    \n",
        "    return dataload\n",
        "\n",
        "def get_median(array, axis = 1):\n",
        "    # https://numpy.org/doc/stable/reference/generated/numpy.median.html\n",
        "    return np.median(array, axis = axis).reshape(data_size, 1)  #, keepdims=True)\n",
        "\n",
        "from pandas import concat\n",
        "import numpy as np\n",
        "week_sequence = {}\n",
        "median_data_dict = {}\n",
        "lag = 5\n",
        "for tickerName in dict_tickers.keys():\n",
        "    filepath = f\"{path}/{tickerName}.csv\"\n",
        "    # Get the data in the required format\n",
        "    data = stockDataTransformer(filepath)\n",
        "    # # Total Data Size\n",
        "    data_size = data.shape[0]\n",
        "    print(f\"{tickerName} data.shape {data.shape}\")\n",
        "    data_orig = series_to_supervised(data, lag).values\n",
        "    print(f'{tickerName} Data Original after series to supervised on data {data_orig.shape}')\n",
        "    week_sequence[tickerName] = data_orig\n",
        "\n",
        "    median_data = get_median(data)\n",
        "    print(f'{tickerName} Median data')\n",
        "    # Median data for each week\n",
        "    print(f\"{tickerName} median_data.shape {median_data.shape}\")\n",
        "    # print(pd.DataFrame(median_data, columns = ['median_stockprice_week']).head(10))\n",
        "    print('\\n')\n",
        "\n",
        "    # Convert median_data to (n_samples, 5) matrix\n",
        "    data_m1 = series_to_supervised(median_data, lag).values\n",
        "    median_data_dict[tickerName] = data_m1\n",
        "    print(f'{tickerName} Median data after series to supervised')\n",
        "    print(f\"{tickerName} data_m1.shape {data_m1.shape}\")\n",
        "    # print(pd.DataFrame(data_m1, columns = [f\"week i+{i}\" for i in range(1, lag+forecast+1)]))\n",
        "    print('\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s-4blJV2sss",
        "outputId": "ecbc0084-4ce6-4ecc-eda3-910bd41030ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape (2170, 60)\n",
            "data.shape (3021, 60)\n",
            "data.shape (3522, 60)\n",
            "data.shape (3983, 60)\n",
            "data.shape (5068, 60)\n",
            "data.shape (6153, 60)\n",
            "data.shape (7238, 60)\n",
            "data.shape (8323, 60)\n",
            "data.shape (9408, 60)\n",
            "data.shape (10493, 60)\n",
            "data.shape (11578, 60)\n",
            "data.shape (12663, 60)\n",
            "data.shape (13748, 60)\n",
            "data.shape (14833, 60)\n",
            "data.shape (15918, 60)\n",
            "data.shape (17003, 60)\n",
            "data.shape (17540, 60)\n",
            "data.shape (17787, 60)\n",
            "data.shape (18872, 60)\n",
            "data.shape (19957, 60)\n",
            "data.shape (21042, 60)\n",
            "data.shape (22127, 60)\n",
            "data.shape (23206, 60)\n",
            "data.shape (24291, 60)\n",
            "data.shape (2170, 6)\n",
            "data.shape (3021, 6)\n",
            "data.shape (3522, 6)\n",
            "data.shape (3983, 6)\n",
            "data.shape (5068, 6)\n",
            "data.shape (6153, 6)\n",
            "data.shape (7238, 6)\n",
            "data.shape (8323, 6)\n",
            "data.shape (9408, 6)\n",
            "data.shape (10493, 6)\n",
            "data.shape (11578, 6)\n",
            "data.shape (12663, 6)\n",
            "data.shape (13748, 6)\n",
            "data.shape (14833, 6)\n",
            "data.shape (15918, 6)\n",
            "data.shape (17003, 6)\n",
            "data.shape (17540, 6)\n",
            "data.shape (17787, 6)\n",
            "data.shape (18872, 6)\n",
            "data.shape (19957, 6)\n",
            "data.shape (21042, 6)\n",
            "data.shape (22127, 6)\n",
            "data.shape (23206, 6)\n",
            "data.shape (24291, 6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "data = week_sequence['Apple']\n",
        "# 4. Bundle all sequences together\n",
        "for tickerName in week_sequence.keys():\n",
        "    if tickerName != 'Apple':\n",
        "        data1 = week_sequence[tickerName]\n",
        "        data = np.concatenate((data, data1))\n",
        "        print(f\"data.shape {data.shape}\")\n",
        "\n",
        "import numpy as np\n",
        "data_m = median_data_dict['Apple']\n",
        "# 4. Bundle all sequences together\n",
        "for tickerName in median_data_dict.keys():\n",
        "    if tickerName != 'Apple':\n",
        "        data1 = median_data_dict[tickerName]\n",
        "        data_m = np.concatenate((data_m, data1))\n",
        "        print(f\"data.shape {data_m.shape}\")\n",
        "\n",
        "data_df = pd.DataFrame(data)\n",
        "data_df.to_csv(f\"all_assets_sequences.csv\")\n",
        "\n",
        "data_m_df = pd.DataFrame(data_m)\n",
        "data_m_df.to_csv(f\"median_sequences.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnHegSSq3QHK"
      },
      "source": [
        "## Parse Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdaFPy53TdP"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "arCRMwnw3Adz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "# from generate_timeseries import Periodic_1d\n",
        "from torch.distributions import uniform\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "# from mujoco_physics import HopperPhysics\n",
        "\n",
        "from sklearn import model_selection\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o3MTXbx3ctF"
      },
      "source": [
        "### HopperPhysics class for our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5_OW_ir3mhW"
      },
      "source": [
        "#### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Rf17d12X3iHr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from lib.utils import get_dict_template\n",
        "import lib.utils as utils\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wfk8BWz33vt"
      },
      "source": [
        "#### Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "404lfySk33Vj",
        "outputId": "cd4b2974-a362-4dd5-c362-6320e2e2ce06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are inside HopperPhysics class\n",
            "T is 6\n",
            "dim is 10\n",
            "median_dim is 1\n",
            "training_file name is training.csv\n"
          ]
        }
      ],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Authors: Yulia Rubanova and Ricky Chen\n",
        "###########################\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from lib.utils import get_dict_template\n",
        "import lib.utils as utils\n",
        "from torchvision.datasets.utils import download_url\n",
        "import pandas as pd\n",
        "\n",
        "class HopperPhysics(object):\n",
        "\n",
        "    T = 6\n",
        "    print(f\"We are inside HopperPhysics class\")\n",
        "    print(f\"T is {T}\")\n",
        "    D = 10\n",
        "    print(f\"dim is {D}\")\n",
        "\n",
        "    median_dim = 1\n",
        "    print(f\"median_dim is {median_dim}\")\n",
        "\n",
        "    # n_training_samples = 10000\n",
        "    # print(f\"n_training_samples is {n_training_samples}\")\n",
        "\n",
        "    training_file = 'training.csv'\n",
        "    print(f\"training_file name is {training_file}\")\n",
        "\n",
        "    def __init__(self, trainfile, medianfile, root, download = True, generate=False, device = torch.device(\"cpu\")):\n",
        "        print(f\"root is {root}\")\n",
        "        self.root = root\n",
        "        if download:\n",
        "            print(f\"Let's load dataset\")\n",
        "            X = pd.read_csv(os.path.join(root, trainfile), index_col=0)\n",
        "            y = pd.read_csv(os.path.join(root, medianfile), index_col=0)\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError('Dataset not found.' + ' You can use download=True to download it')\n",
        "\n",
        "        data_file = os.path.join(self.data_folder, self.training_file)\n",
        "        median_file = os.path.join(self.data_folder, 'median_sequences.csv')\n",
        "        print(f\"data_file is {data_file}\")\n",
        "        # print(f\"Using torch.Tensor(torch.load(data_file)).to(device) to get self.data\")\n",
        "        # self.data = torch.Tensor(X.values).to(device) # https://pytorch.org/docs/stable/generated/torch.load.html\n",
        "        # print(f\"self.data.shape is {self.data.shape}\")\n",
        "        # self.median_data = torch.Tensor(y.values).to(device)\n",
        "        # print(f\"self.median_data.shape is {self.median_data.shape}\")\n",
        "\n",
        "        # self.data = torch.reshape(self.data, (self.data.shape[0], T, D))\n",
        "        # self.median_data = torch.reshape(self.median_data, (self.median_data.shape[0], T, median_dim))\n",
        "        \n",
        "\n",
        "        # print(f\"self.data.shape is {self.data.shape}\")\n",
        "        # print(f\"self.median_data.shape is {self.median_data.shape}\")\n",
        "        # print(\"\\n\")\n",
        "        # self.data, self.data_min, self.data_max = utils.normalize_data(self.data)\n",
        "        # self.median_data, self.median_data_min, self.median_data_max = utils.normalize_data(self.median_data)\n",
        "        # self.dataset = torch.cat((self.data, self.median_data), dim=1)\n",
        "        self.dataset = list(zip(X.values.astype(np.float32), y.values.astype(np.float32)))\n",
        "        # print(f\"self.dataset.shape is {self.dataset.shape}\")\n",
        "        # self.dataset = list(zip(self.data, self.median_data))\n",
        "        # self.dataset = torch.Tensor(self.dataset).to(device)\n",
        "        # print(self.dataset[0])\n",
        "\n",
        "        self.device =device\n",
        "        self.n_training_samples = len(self.dataset)\n",
        "        print(f\"self.n_training_samples is {self.n_training_samples}\")\n",
        "\n",
        "    def _check_exists(self):\n",
        "        print(f\"we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\")\n",
        "        return os.path.exists(os.path.join(self.data_folder, self.training_file))\n",
        "\n",
        "    @property\n",
        "    def data_folder(self):\n",
        "        return self.root\n",
        "\n",
        "        # def __getitem__(self, index):\n",
        "        #     return self.data[index]\n",
        "\n",
        "    def get_dataset(self):\n",
        "        return self.dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def size(self, ind = None):\n",
        "        if ind is not None:\n",
        "            return self.data.shape[ind]\n",
        "            return self.data.shape\n",
        "                \n",
        "    def __repr__(self):\n",
        "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
        "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
        "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
        "        return fmt_str\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Crt3lUfGdXT"
      },
      "source": [
        "#### parse_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "L4xzuPIz_sk8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "# from generate_timeseries import Periodic_1d\n",
        "from torch.distributions import uniform\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn import model_selection\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sqr99IeBGgrk"
      },
      "outputs": [],
      "source": [
        "def parse_datasets(args, device):\n",
        "    \n",
        "\t# batch the data and median_data together and don't shuffle\n",
        "\tdef basic_collate_fn(batch, time_steps, args = args, device = device, data_type = \"train\"):\n",
        "    \t# batch looks like [(x0+y0), ... ]\n",
        "\t\t# data = batch[:, :int(T*D)] \n",
        "\t\t# error is TypeError: list indices must be integers or slices, not tuple\n",
        "\t\t# print(type(batch))\n",
        "\t\t# print(f\"T is {T}\")\n",
        "\t\t# print(f\"D is {D}\")\n",
        "\t\t# batch = torch.stack(batch)\n",
        "\t\t# print(f\"batch.shape is {batch.shape}\")\n",
        "\t\t# data = batch[:, :int(T*D)] \n",
        "\t\t# print(f\"data.shape is {data.shape}\")\n",
        "\t\t# # error is TypeError: list indices must be integers or slices, not tuple\n",
        "\t\t# median_data = batch[:, int(T*D):]\n",
        "\t\t# print(f\"median_data.shape is {median_data.shape}\")\n",
        "\n",
        "\t\t# # median_data = torch.cat(batch[:, int(T*D):], dim=0)\n",
        "\t\tdata_list, median_data_list = [], []\n",
        "\t\tfor (data, median) in batch:\n",
        "\t\t\tdata_list.append(data)\n",
        "\t\t\tmedian_data_list.append(median)\n",
        "\t\tdata = torch.tensor(data_list).to(device)\n",
        "\t\tmedian_data = torch.tensor(median_data_list).to(device)\n",
        "\t\tprint(f\"data.shape is {data.shape}\")\n",
        "\t\tprint(f\"median_data.shape is {median_data.shape}\")\n",
        "\n",
        "\t\tdata_dict = {\n",
        "\t\t\t\"data\": data, \n",
        "\t\t\t\"median_data\": median_data,\n",
        "\t\t\t\"time_steps\": time_steps}\n",
        "\t\t\n",
        "\t\t# data_dict = utils.split_and_subsample_batch(data_dict, args, data_type = data_type)\n",
        "\t\tclone_data = data_dict[\"data\"].clone().to(device)\n",
        "\t\tclone_median_data = data_dict[\"median_data\"].clone().to(device)\n",
        "\t\tclone_data = torch.reshape(clone_data, (clone_data.size(0), T, D))\n",
        "\t\tprint(f\"clone_data.shape is {clone_data.shape}\")\n",
        "\t\tclone_median_data = torch.reshape(clone_median_data, (clone_median_data.size(0), T, 1))\n",
        "\t\tprint(f\"clone_median_data.shape is {clone_median_data.shape}\")\n",
        "\t\tdata_dict = {\"observed_data\": clone_data,\n",
        "\t\t\t\"observed_tp\": data_dict[\"time_steps\"].clone(),\n",
        "\t\t\t\"data_to_predict\": clone_median_data,\n",
        "\t\t\t\"tp_to_predict\": data_dict[\"time_steps\"].clone()}\n",
        "\t\tprint(f\"data_dict has keys as {data_dict.keys()}\")\n",
        "\t\tprint(f\"data_dict['observed_data'].shape is {data_dict['observed_data'].shape}\")\n",
        "\t\tdata_dict[\"observed_mask\"] = None \n",
        "\t\tdata_dict[\"mask_predicted_data\"] = None \n",
        "\t\tdata_dict[\"labels\"] = None \n",
        "\t\tdata_dict[\"mode\"] = \"interp\"\n",
        "\t\tprint(f\"data_dict['mode'] is {data_dict['mode']}\")\n",
        "\t\treturn data_dict\n",
        "\n",
        "\tdataset_name = args.dataset\n",
        "\tprint(f\"dataset_name is {dataset_name}\")\n",
        "\tn_total_tp = args.timepoints\n",
        "\tmax_t_extrap = args.max_t / args.timepoints * n_total_tp\n",
        "\n",
        "\t##################################################################\n",
        "\t# MuJoCo dataset\n",
        "\tif dataset_name == \"hopper\":\n",
        "\t\tdataset_obj = HopperPhysics(trainfile, medianfile, root='data', download=True, generate=False, device = device)\n",
        "\t\tdataset = dataset_obj.get_dataset()\n",
        "\t\t# print(f\"dataset.shape is {dataset.shape}\")\n",
        "\t\t# dataset = dataset.to(device)\n",
        "\t\tn_tp_data = T\n",
        "\t\tprint(f\"n_tp_data is {n_tp_data}\")\n",
        "\n",
        "\t\t# Time steps that are used later on for exrapolation\n",
        "\t\ttime_steps = torch.arange(start=0, end = n_tp_data, step=1).float().to(device)\n",
        "\t\ttime_steps = time_steps / len(time_steps)\n",
        "\n",
        "\t\t# dataset = dataset.to(device)\n",
        "\t\ttime_steps = time_steps.to(device)\n",
        "\t\tprint(f\"time_steps is {time_steps}\")\n",
        "\n",
        "\t\t# if not args.extrap:\n",
        "\t\t# \t# Creating dataset for interpolation\n",
        "\t\t# \t# sample time points from different parts of the timeline, \n",
        "\t\t# \t# so that the model learns from different parts of hopper trajectory\n",
        "\t\t# \tn_traj = len(dataset)\n",
        "\t\t# \tn_tp_data = dataset.shape[1]\n",
        "\t\t# \tn_reduced_tp = args.timepoints\n",
        "\n",
        "\t\t# \t# sample time points from different parts of the timeline, \n",
        "\t\t# \t# so that the model learns from different parts of hopper trajectory\n",
        "\t\t# \tstart_ind = np.random.randint(0, high=n_tp_data - n_reduced_tp +1, size=n_traj)\n",
        "\t\t# \tend_ind = start_ind + n_reduced_tp\n",
        "\t\t# \tsliced = []\n",
        "\t\t# \tfor i in range(n_traj):\n",
        "\t\t# \t\t  sliced.append(dataset[i, start_ind[i] : end_ind[i], :])\n",
        "\t\t# \tdataset = torch.stack(sliced).to(device)\n",
        "\t\t# \ttime_steps = time_steps[:n_reduced_tp]\n",
        "\n",
        "\t\t# Split into train and test by the time sequences\n",
        "\t\t# train_y, test_y = utils.split_train_test(dataset, train_fraq = 0.8)\n",
        "\t\tn_samples = len(dataset)\n",
        "\t\tprint(f\"n_samples is {n_samples}\")\n",
        "\t\ttrain_freq = 0.8\n",
        "\t\ttrain_y = dataset[:int(n_samples*train_freq)]\n",
        "\t\ttest_y = dataset[int(n_samples*train_freq):]\n",
        "\t\t# print(f\"train_y.shape is {train_y.shape}\")\n",
        "\t\t# print(f\"test_y.shape is {test_y.shape}\")\n",
        "\n",
        "\t\t\n",
        "\n",
        "\t\tinput_dim = D\n",
        "\t\tprint(f\"input_dim is {input_dim}\")\n",
        "\n",
        "\t\tbatch_size = min(args.batch_size, args.n)\n",
        "\t\tprint(f\"batch_size is {batch_size}\")\n",
        "\t\ttrain_dataloader = DataLoader(train_y, batch_size = batch_size, shuffle=False,\n",
        "\t\t\tcollate_fn= lambda batch: basic_collate_fn(batch, time_steps, data_type = \"train\"))\n",
        "\t\tprint(f\"train_dataloader.batch_size is {train_dataloader.batch_size}\")\n",
        "\t\ttest_dataloader = DataLoader(test_y, batch_size = n_samples, shuffle=False,\n",
        "\t\t\tcollate_fn= lambda batch: basic_collate_fn(batch, time_steps, data_type = \"test\"))\n",
        "\t\tprint(f\"test_dataloader.batch_size is {test_dataloader.batch_size}\")\n",
        "\t\t\n",
        "\t\tdata_objects = {\"dataset_obj\": dataset_obj, \n",
        "\t\t\t\t\t\"train_dataloader\": utils.inf_generator(train_dataloader), \n",
        "\t\t\t\t\t\"test_dataloader\": utils.inf_generator(test_dataloader),\n",
        "\t\t\t\t\t\"input_dim\": input_dim,\n",
        "\t\t\t\t\t\"n_train_batches\": len(train_dataloader),\n",
        "\t\t\t\t\t\"n_test_batches\": len(test_dataloader)}\n",
        "\t\treturn data_objects\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0n99_hXGmzh",
        "outputId": "afcad46d-bfd5-4960-fffb-511f9338c9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T is 6\n",
            "dim is {D}\n",
            "median_dim is {median_dim}\n",
            "dataset_name is hopper\n",
            "root is data\n",
            "Let's load dataset\n",
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "data_file is data/training.csv\n",
            "self.n_training_samples is 24291\n",
            "n_tp_data is 6\n",
            "time_steps is tensor([0.0000, 0.1667, 0.3333, 0.5000, 0.6667, 0.8333])\n",
            "n_samples is 24291\n",
            "input_dim is 10\n",
            "batch_size is 50\n",
            "train_dataloader.batch_size is 50\n",
            "test_dataloader.batch_size is 24291\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dataset_obj': Dataset HopperPhysics\n",
              "     Number of datapoints: 24291\n",
              "     Root Location: data,\n",
              " 'input_dim': 10,\n",
              " 'n_test_batches': 1,\n",
              " 'n_train_batches': 389,\n",
              " 'test_dataloader': <generator object inf_generator at 0x7fc4cc5d87d0>,\n",
              " 'train_dataloader': <generator object inf_generator at 0x7fc4cc5d89d0>}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainfile = 'training.csv'\n",
        "medianfile = 'median_sequences.csv'\n",
        "T = 6\n",
        "print(f\"T is {T}\")\n",
        "D = 10\n",
        "print(\"dim is {D}\")\n",
        "\n",
        "median_dim = 1\n",
        "print(\"median_dim is {median_dim}\")\n",
        "parse_datasets(args, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC6zjfV_rVFI",
        "outputId": "92dba1a4-b955-4d64-c8f2-14fbc62eaa1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_name is hopper\n",
            "root is data\n",
            "Let's load dataset\n",
            "we will check os.path.exists(os.path.join(self.data_folder, self.training_file)). If it exists, return\n",
            "data_file is data/training.csv\n",
            "self.n_training_samples is 24291\n",
            "n_tp_data is 6\n",
            "time_steps is tensor([0.0000, 0.1667, 0.3333, 0.5000, 0.6667, 0.8333])\n",
            "n_samples is 24291\n",
            "input_dim is 10\n",
            "batch_size is 50\n",
            "train_dataloader.batch_size is 50\n",
            "test_dataloader.batch_size is 24291\n",
            "input_dim is 10\n"
          ]
        }
      ],
      "source": [
        "data_obj = parse_datasets(args, device)\n",
        "input_dim = data_obj[\"input_dim\"]\n",
        "print(f\"input_dim is {input_dim}\")\n",
        "\n",
        "classif_per_tp = False\n",
        "if (\"classif_per_tp\" in data_obj):\n",
        "    # do classification per time point rather than on a time series as a whole\n",
        "    classif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "    raise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kSG0vfAvrU4z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFlqlf8HrSAl"
      },
      "source": [
        "## n_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZtbabAJKrb1f"
      },
      "outputs": [],
      "source": [
        "n_labels = 1\n",
        "if args.classif:\n",
        "    if (\"n_labels\" in data_obj):\n",
        "        n_labels = data_obj[\"n_labels\"]\n",
        "    else:\n",
        "        raise Exception(\"Please provide number of labels for classification task\")\n",
        "\n",
        "##################################################################\n",
        "# Create the model\n",
        "obsrv_std = 0.01\n",
        "if args.dataset == \"hopper\":\n",
        "    obsrv_std = 1e-3 \n",
        "\n",
        "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "\n",
        "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "m-ik63ltbcBS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qssfnpjKreS7"
      },
      "source": [
        "## args.latent_ode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNguhET4Tjt5"
      },
      "source": [
        "#### encoder_decoder.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EEVZd5ZOTn6s"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "import lib.utils as utils\n",
        "from torch.distributions import Categorical, Normal\n",
        "import lib.utils as utils\n",
        "from torch.nn.modules.rnn import LSTM, GRU\n",
        "from lib.utils import get_device\n",
        "\n",
        "\n",
        "# GRU description: \n",
        "# http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/\n",
        "class GRU_unit(nn.Module):\n",
        "\tdef __init__(self, latent_dim, input_dim, \n",
        "\t\tupdate_gate = None,\n",
        "\t\treset_gate = None,\n",
        "\t\tnew_state_net = None,\n",
        "\t\tn_units = 100,\n",
        "\t\tdevice = torch.device(\"cpu\")):\n",
        "\t\tsuper(GRU_unit, self).__init__()\n",
        "\t\tprint(f\"Inside GRU unit\")\n",
        "\t\tprint(f\"\\n\")\n",
        "\t\tprint(f\"self.update_gate = nn.Sequential(\" +\n",
        "\t\t\t   \" nn.Linear(latent_dim * 2 + input_dim, n_units),\" +\n",
        "\t\t\t   \" nn.Tanh(),\" +\n",
        "\t\t\t   \" nn.Linear(n_units, latent_dim),\" +\n",
        "\t\t\t   \" nn.Sigmoid())\")\n",
        "\t\tprint(f\"self.reset_gate = nn.Sequential(\" +\n",
        "\t\t\t   \" nn.Linear(latent_dim * 2 + input_dim, n_units),\" +\n",
        "\t\t\t   \" nn.Tanh(),\" +\n",
        "\t\t\t   \" nn.Linear(n_units, latent_dim),\" +\n",
        "\t\t\t   \" nn.Sigmoid())\")\n",
        "\t\tprint(f\"self.new_state_net = nn.Sequential(\" +\n",
        "\t\t\t   \" nn.Linear(latent_dim * 2 + input_dim, n_units),\" +\n",
        "\t\t\t   \" nn.Tanh(),\" +\n",
        "\t\t\t   \" nn.Linear(n_units, latent_dim),\" +\n",
        "\t\t\t   \" nn.Sigmoid())\")\n",
        "\n",
        "\t\tif update_gate is None:\n",
        "\t\t\tself.update_gate = nn.Sequential(\n",
        "\t\t\t   nn.Linear(latent_dim * 2 + input_dim, n_units),\n",
        "\t\t\t   nn.Tanh(),\n",
        "\t\t\t   nn.Linear(n_units, latent_dim),\n",
        "\t\t\t   nn.Sigmoid())\n",
        "\t\t\tutils.init_network_weights(self.update_gate)\n",
        "\t\telse: \n",
        "\t\t\tself.update_gate  = update_gate\n",
        "\n",
        "\t\tif reset_gate is None:\n",
        "\t\t\tself.reset_gate = nn.Sequential(\n",
        "\t\t\t   nn.Linear(latent_dim * 2 + input_dim, n_units),\n",
        "\t\t\t   nn.Tanh(),\n",
        "\t\t\t   nn.Linear(n_units, latent_dim),\n",
        "\t\t\t   nn.Sigmoid())\n",
        "\t\t\tutils.init_network_weights(self.reset_gate)\n",
        "\t\telse: \n",
        "\t\t\tself.reset_gate  = reset_gate\n",
        "\n",
        "\t\tif new_state_net is None:\n",
        "\t\t\tself.new_state_net = nn.Sequential(\n",
        "\t\t\t   nn.Linear(latent_dim * 2 + input_dim, n_units),\n",
        "\t\t\t   nn.Tanh(),\n",
        "\t\t\t   nn.Linear(n_units, latent_dim * 2))\n",
        "\t\t\tutils.init_network_weights(self.new_state_net)\n",
        "\t\telse: \n",
        "\t\t\tself.new_state_net  = new_state_net\n",
        "\n",
        "\n",
        "\tdef forward(self, y_mean, y_std, x, masked_update = False):\n",
        "\t\ty_concat = torch.cat([y_mean, y_std, x], -1)  \n",
        "\n",
        "\t\tupdate_gate = self.update_gate(y_concat)\n",
        "\t\treset_gate = self.reset_gate(y_concat)\n",
        "\t\tconcat = torch.cat([y_mean * reset_gate, y_std * reset_gate, x], -1)\n",
        "\t\t\n",
        "\t\tnew_state, new_state_std = utils.split_last_dim(self.new_state_net(concat))\n",
        "\t\tnew_state_std = new_state_std.abs()\n",
        "\n",
        "\t\tnew_y = (1-update_gate) * new_state + update_gate * y_mean\n",
        "\t\tnew_y_std = (1-update_gate) * new_state_std + update_gate * y_std\n",
        "\n",
        "\t\tassert(not torch.isnan(new_y).any())\n",
        "\n",
        "\t\t# if masked_update:\n",
        "    \t# \t\t# IMPORTANT: assumes that x contains both data and mask\n",
        "\t\t# \t# update only the hidden states for hidden state only if at least one feature is present for the current time point\n",
        "\t\t# \tn_data_dims = x.size(-1)//2\n",
        "\t\t# \tmask = x[:, :, n_data_dims:]\n",
        "\t\t# \tutils.check_mask(x[:, :, :n_data_dims], mask)\n",
        "\t\t\t\n",
        "\t\t# \tmask = (torch.sum(mask, -1, keepdim = True) > 0).float()\n",
        "\n",
        "\t\t# \tassert(not torch.isnan(mask).any())\n",
        "\n",
        "\t\t# \tnew_y = mask * new_y + (1-mask) * y_mean\n",
        "\t\t# \tnew_y_std = mask * new_y_std + (1-mask) * y_std\n",
        "\n",
        "\t\t# \tif torch.isnan(new_y).any():\n",
        "\t\t# \t\tprint(\"new_y is nan!\")\n",
        "\t\t# \t\tprint(mask)\n",
        "\t\t# \t\tprint(y_mean)\n",
        "\t\t# \t\tprint(prev_new_y)\n",
        "\t\t# \t\texit()\n",
        "\n",
        "\t\tnew_y_std = new_y_std.abs()\n",
        "\t\tprint(f\"new_y.shape is {new_y.shape}\")\n",
        "\t\tprint(f\"new_y_std.shape is {new_y_std.shape}\")\n",
        "\t\treturn new_y, new_y_std\n",
        "\n",
        "class Encoder_z0_ODE_RNN(nn.Module):\n",
        "\t# Derive z0 by running ode backwards.\n",
        "\t# For every y_i we have two versions: encoded from data and derived from ODE by running it backwards from t_i+1 to t_i\n",
        "\t# Compute a weighted sum of y_i from data and y_i from ode. Use weighted y_i as an initial value for ODE runing from t_i to t_i-1\n",
        "\t# Continue until we get to z0\n",
        "\tdef __init__(self, latent_dim, input_dim, z0_diffeq_solver = None, \n",
        "\t\tz0_dim = None, GRU_update = None, \n",
        "\t\tn_gru_units = 100, \n",
        "\t\tdevice = torch.device(\"cpu\")):\n",
        "\t\t\n",
        "\t\tsuper(Encoder_z0_ODE_RNN, self).__init__()\n",
        "\n",
        "\t\tif z0_dim is None:\n",
        "\t\t\tself.z0_dim = latent_dim\n",
        "\t\telse:\n",
        "\t\t\tself.z0_dim = z0_dim\n",
        "\n",
        "\t\tif GRU_update is None:\n",
        "\t\t\tself.GRU_update = GRU_unit(latent_dim, input_dim, \n",
        "\t\t\t\tn_units = n_gru_units, \n",
        "\t\t\t\tdevice=device).to(device)\n",
        "\t\telse:\n",
        "\t\t\tself.GRU_update = GRU_update\n",
        "\n",
        "\t\tself.z0_diffeq_solver = z0_diffeq_solver\n",
        "\t\tself.latent_dim = latent_dim\n",
        "\t\tself.input_dim = input_dim\n",
        "\t\tself.device = device\n",
        "\t\tself.extra_info = None\n",
        "\n",
        "\t\tself.transform_z0 = nn.Sequential(\n",
        "\t\t   nn.Linear(latent_dim * 2, 100),\n",
        "\t\t   nn.Tanh(),\n",
        "\t\t   nn.Linear(100, self.z0_dim * 2),)\n",
        "\t\tutils.init_network_weights(self.transform_z0)\n",
        "\n",
        "\n",
        "\tdef forward(self, data, time_steps, run_backwards = True, save_info = False):\n",
        "\t\t# data, time_steps -- observations and their time stamps\n",
        "\t\t# IMPORTANT: assumes that 'data' already has mask concatenated to it \n",
        "\t\tassert(not torch.isnan(data).any())\n",
        "\t\tassert(not torch.isnan(time_steps).any())\n",
        "\n",
        "\t\tn_traj, n_tp, n_dims = data.size()\n",
        "\t\tif len(time_steps) == 1:\n",
        "\t\t\tprev_y = torch.zeros((1, n_traj, self.latent_dim)).to(self.device)\n",
        "\t\t\tprev_std = torch.zeros((1, n_traj, self.latent_dim)).to(self.device)\n",
        "\n",
        "\t\t\txi = data[:,0,:].unsqueeze(0)\n",
        "\n",
        "\t\t\tlast_yi, last_yi_std = self.GRU_update(prev_y, prev_std, xi)\n",
        "\t\t\textra_info = None\n",
        "\t\telse:\n",
        "\t\t\t\n",
        "\t\t\tlast_yi, last_yi_std, _, extra_info = self.run_odernn(\n",
        "\t\t\t\tdata, time_steps, run_backwards = run_backwards,\n",
        "\t\t\t\tsave_info = save_info)\n",
        "\n",
        "\t\tmeans_z0 = last_yi.reshape(1, n_traj, self.latent_dim)\n",
        "\t\tstd_z0 = last_yi_std.reshape(1, n_traj, self.latent_dim)\n",
        "\n",
        "\t\tmean_z0, std_z0 = utils.split_last_dim( self.transform_z0( torch.cat((means_z0, std_z0), -1)))\n",
        "\t\tstd_z0 = std_z0.abs()\n",
        "\t\tif save_info:\n",
        "\t\t\tself.extra_info = extra_info\n",
        "\n",
        "\t\treturn mean_z0, std_z0\n",
        "\n",
        "\n",
        "\tdef run_odernn(self, data, time_steps, \n",
        "\t\trun_backwards = True, save_info = False):\n",
        "\t\t# IMPORTANT: assumes that 'data' already has mask concatenated to it \n",
        "\n",
        "\t\tn_traj, n_tp, n_dims = data.size()\n",
        "\t\textra_info = []\n",
        "\n",
        "\t\tt0 = time_steps[-1]\n",
        "\t\tif run_backwards:\n",
        "\t\t\tt0 = time_steps[0]\n",
        "\n",
        "\t\tdevice = get_device(data)\n",
        "\n",
        "\t\tprev_y = torch.zeros((1, n_traj, self.latent_dim)).to(device)\n",
        "\t\tprev_std = torch.zeros((1, n_traj, self.latent_dim)).to(device)\n",
        "\n",
        "\t\tprev_t, t_i = time_steps[-1] + 0.01,  time_steps[-1]\n",
        "\n",
        "\t\tinterval_length = time_steps[-1] - time_steps[0]\n",
        "\t\tminimum_step = interval_length / 50\n",
        "\n",
        "\t\t#print(\"minimum step: {}\".format(minimum_step))\n",
        "\n",
        "\t\t# assert(not torch.isnan(data).any())\n",
        "\t\t# assert(not torch.isnan(time_steps).any())\n",
        "\n",
        "\t\tlatent_ys = []\n",
        "\t\t# Run ODE backwards and combine the y(t) estimates using gating\n",
        "\t\ttime_points_iter = range(0, len(time_steps))\n",
        "\t\tif run_backwards:\n",
        "\t\t\ttime_points_iter = reversed(time_points_iter)\n",
        "\n",
        "\t\tfor i in time_points_iter:\n",
        "\t\t\tif (prev_t - t_i) < minimum_step:\n",
        "\t\t\t\ttime_points = torch.stack((prev_t, t_i))\n",
        "\t\t\t\tinc = self.z0_diffeq_solver.ode_func(prev_t, prev_y) * (t_i - prev_t)\n",
        "\n",
        "\t\t\t\t# assert(not torch.isnan(inc).any())\n",
        "\n",
        "\t\t\t\tode_sol = prev_y + inc\n",
        "\t\t\t\tode_sol = torch.stack((prev_y, ode_sol), 2).to(device)\n",
        "\n",
        "\t\t\t\t# assert(not torch.isnan(ode_sol).any())\n",
        "\t\t\telse:\n",
        "\t\t\t\tn_intermediate_tp = max(2, ((prev_t - t_i) / minimum_step).int())\n",
        "\n",
        "\t\t\t\ttime_points = utils.linspace_vector(prev_t, t_i, n_intermediate_tp)\n",
        "\t\t\t\tode_sol = self.z0_diffeq_solver(prev_y, time_points)\n",
        "\n",
        "\t\t\t\t# assert(not torch.isnan(ode_sol).any())\n",
        "\n",
        "\t\t\tif torch.mean(ode_sol[:, :, 0, :]  - prev_y) >= 0.001:\n",
        "\t\t\t\tprint(\"Error: first point of the ODE is not equal to initial value\")\n",
        "\t\t\t\tprint(torch.mean(ode_sol[:, :, 0, :]  - prev_y))\n",
        "\t\t\t\texit()\n",
        "\t\t\t#assert(torch.mean(ode_sol[:, :, 0, :]  - prev_y) < 0.001)\n",
        "\n",
        "\t\t\tyi_ode = ode_sol[:, :, -1, :]\n",
        "\t\t\txi = data[:,i,:].unsqueeze(0)\n",
        "\t\t\t\n",
        "\t\t\tyi, yi_std = self.GRU_update(yi_ode, prev_std, xi)\n",
        "\n",
        "\t\t\tprev_y, prev_std = yi, yi_std\t\t\t\n",
        "\t\t\tprev_t, t_i = time_steps[i],  time_steps[i-1]\n",
        "\n",
        "\t\t\tlatent_ys.append(yi)\n",
        "\n",
        "\t\t\tif save_info:\n",
        "\t\t\t\td = {\"yi_ode\": yi_ode.detach(), #\"yi_from_data\": yi_from_data,\n",
        "\t\t\t\t\t \"yi\": yi.detach(), \"yi_std\": yi_std.detach(), \n",
        "\t\t\t\t\t \"time_points\": time_points.detach(), \"ode_sol\": ode_sol.detach()}\n",
        "\t\t\t\textra_info.append(d)\n",
        "\n",
        "\t\tlatent_ys = torch.stack(latent_ys, 1)\n",
        "\n",
        "\t\t# assert(not torch.isnan(yi).any())\n",
        "\t\t# assert(not torch.isnan(yi_std).any())\n",
        "\n",
        "\t\treturn yi, yi_std, latent_ys, extra_info\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\tdef __init__(self, latent_dim, input_dim):\n",
        "\t\tsuper(Decoder, self).__init__()\n",
        "\t\t# decode data from latent space where we are solving an ODE back to the data space\n",
        "\n",
        "\t\tdecoder = nn.Sequential(\n",
        "\t\t   nn.Linear(latent_dim, input_dim),)\n",
        "\n",
        "\t\tutils.init_network_weights(decoder)\t\n",
        "\t\tself.decoder = decoder\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\t\treturn self.decoder(data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NKKXX17cWKL"
      },
      "source": [
        "#### likelihood_eval.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pV3BP_ILcZK8"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import gc\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "#import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.utils import get_device\n",
        "# from lib.encoder_decoder import *\n",
        "# from lib.likelihood_eval import *\n",
        "\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions import kl_divergence, Independent\n",
        "\n",
        "\n",
        "def gaussian_log_likelihood(mu_2d, data_2d, obsrv_std, indices = None):\n",
        "\tn_data_points = mu_2d.size()[-1]\n",
        "\n",
        "\tif n_data_points > 0:\n",
        "\t\tgaussian = Independent(Normal(loc = mu_2d, scale = obsrv_std.repeat(n_data_points)), 1)\n",
        "\t\tlog_prob = gaussian.log_prob(data_2d) \n",
        "\t\tlog_prob = log_prob / n_data_points \n",
        "\telse:\n",
        "\t\tlog_prob = torch.zeros([1]).to(get_device(data_2d)).squeeze()\n",
        "\treturn log_prob\n",
        "\n",
        "\n",
        "# def poisson_log_likelihood(masked_log_lambdas, masked_data, indices, int_lambdas):\n",
        "# \t# masked_log_lambdas and masked_data \n",
        "# \tn_data_points = masked_data.size()[-1]\n",
        "\n",
        "# \tif n_data_points > 0:\n",
        "# \t\tlog_prob = torch.sum(masked_log_lambdas) - int_lambdas[indices]\n",
        "# \t\t#log_prob = log_prob / n_data_points\n",
        "# \telse:\n",
        "# \t\tlog_prob = torch.zeros([1]).to(get_device(masked_data)).squeeze()\n",
        "# \treturn log_prob\n",
        "\n",
        "def compute_masked_likelihood(mu, data, mask, likelihood_func):\n",
        "\t# Compute the likelihood per patient and per attribute so that we don't priorize patients with more measurements\n",
        "\tn_traj_samples, n_traj, n_timepoints, n_dims = data.size()\n",
        "\n",
        "\tres = []\n",
        "\tfor i in range(n_traj_samples):\n",
        "\t\tfor k in range(n_traj):\n",
        "\t\t\tfor j in range(n_dims):\n",
        "\t\t\t\tdata_masked = torch.masked_select(data[i,k,:,j], mask[i,k,:,j].bool())\n",
        "\t\t\t\t\n",
        "\t\t\t\t#assert(torch.sum(data_masked == 0.) < 10)\n",
        "\n",
        "\t\t\t\tmu_masked = torch.masked_select(mu[i,k,:,j], mask[i,k,:,j].bool())\n",
        "\t\t\t\tlog_prob = likelihood_func(mu_masked, data_masked, indices = (i,k,j))\n",
        "\t\t\t\tres.append(log_prob)\n",
        "\t# shape: [n_traj*n_traj_samples, 1]\n",
        "\n",
        "\tres = torch.stack(res, 0).to(get_device(data))\n",
        "\tres = res.reshape((n_traj_samples, n_traj, n_dims))\n",
        "\t# Take mean over the number of dimensions\n",
        "\tres = torch.mean(res, -1) # !!!!!!!!!!! changed from sum to mean\n",
        "\tres = res.transpose(0,1)\n",
        "\treturn res\n",
        "\n",
        "\n",
        "def masked_gaussian_log_density(mu, data, obsrv_std, mask = None):\n",
        "\t# these cases are for plotting through plot_estim_density\n",
        "\tif (len(mu.size()) == 3):\n",
        "\t\t# add additional dimension for gp samples\n",
        "\t\tmu = mu.unsqueeze(0)\n",
        "\n",
        "\tif (len(data.size()) == 2):\n",
        "\t\t# add additional dimension for gp samples and time step\n",
        "\t\tdata = data.unsqueeze(0).unsqueeze(2)\n",
        "\telif (len(data.size()) == 3):\n",
        "\t\t# add additional dimension for gp samples\n",
        "\t\tdata = data.unsqueeze(0)\n",
        "\n",
        "\tn_traj_samples, n_traj, n_timepoints, n_dims = mu.size()\n",
        "\n",
        "\tassert(data.size()[-1] == n_dims)\n",
        "\n",
        "\t# Shape after permutation: [n_traj, n_traj_samples, n_timepoints, n_dims]\n",
        "\tif mask is None:\n",
        "\t\tmu_flat = mu.reshape(n_traj_samples*n_traj, n_timepoints * n_dims)\n",
        "\t\tn_traj_samples, n_traj, n_timepoints, n_dims = data.size()\n",
        "\t\tdata_flat = data.reshape(n_traj_samples*n_traj, n_timepoints * n_dims)\n",
        "\t\n",
        "\t\tres = gaussian_log_likelihood(mu_flat, data_flat, obsrv_std)\n",
        "\t\tres = res.reshape(n_traj_samples, n_traj).transpose(0,1)\n",
        "\telse:\n",
        "\t\t# Compute the likelihood per patient so that we don't priorize patients with more measurements\n",
        "\t\tfunc = lambda mu, data, indices: gaussian_log_likelihood(mu, data, obsrv_std = obsrv_std, indices = indices)\n",
        "\t\tres = compute_masked_likelihood(mu, data, mask, func)\n",
        "\treturn res\n",
        "\n",
        "\n",
        "\n",
        "def mse(mu, data, indices = None):\n",
        "\tn_data_points = mu.size()[-1]\n",
        "\n",
        "\tif n_data_points > 0:\n",
        "\t\tmse = nn.MSELoss()(mu, data)\n",
        "\telse:\n",
        "\t\tmse = torch.zeros([1]).to(get_device(data)).squeeze()\n",
        "\treturn mse\n",
        "\n",
        "\n",
        "def compute_mse(mu, data, mask = None):\n",
        "\t# these cases are for plotting through plot_estim_density\n",
        "\tif (len(mu.size()) == 3):\n",
        "\t\t# add additional dimension for gp samples\n",
        "\t\tmu = mu.unsqueeze(0)\n",
        "\n",
        "\tif (len(data.size()) == 2):\n",
        "\t\t# add additional dimension for gp samples and time step\n",
        "\t\tdata = data.unsqueeze(0).unsqueeze(2)\n",
        "\telif (len(data.size()) == 3):\n",
        "\t\t# add additional dimension for gp samples\n",
        "\t\tdata = data.unsqueeze(0)\n",
        "\n",
        "\tn_traj_samples, n_traj, n_timepoints, n_dims = mu.size()\n",
        "\tassert(data.size()[-1] == n_dims)\n",
        "\n",
        "\t# Shape after permutation: [n_traj, n_traj_samples, n_timepoints, n_dims]\n",
        "\tif mask is None:\n",
        "\t\tmu_flat = mu.reshape(n_traj_samples*n_traj, n_timepoints * n_dims)\n",
        "\t\tn_traj_samples, n_traj, n_timepoints, n_dims = data.size()\n",
        "\t\tdata_flat = data.reshape(n_traj_samples*n_traj, n_timepoints * n_dims)\n",
        "\t\tres = mse(mu_flat, data_flat)\n",
        "\telse:\n",
        "\t\t# Compute the likelihood per patient so that we don't priorize patients with more measurements\n",
        "\t\tres = compute_masked_likelihood(mu, data, mask, mse)\n",
        "\treturn res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_poisson_proc_likelihood(truth, pred_y, info, mask = None):\n",
        "\t# Compute Poisson likelihood\n",
        "\t# https://math.stackexchange.com/questions/344487/log-likelihood-of-a-realization-of-a-poisson-process\n",
        "\t# Sum log lambdas across all time points\n",
        "\tif mask is None:\n",
        "\t\tpoisson_log_l = torch.sum(info[\"log_lambda_y\"], 2) - info[\"int_lambda\"]\n",
        "\t\t# Sum over data dims\n",
        "\t\tpoisson_log_l = torch.mean(poisson_log_l, -1)\n",
        "\telse:\n",
        "\t\t# Compute likelihood of the data under the predictions\n",
        "\t\ttruth_repeated = truth.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\t\tmask_repeated = mask.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\n",
        "\t\t# Compute the likelihood per patient and per attribute so that we don't priorize patients with more measurements\n",
        "\t\tint_lambda = info[\"int_lambda\"]\n",
        "\t\tf = lambda log_lam, data, indices: poisson_log_likelihood(log_lam, data, indices, int_lambda)\n",
        "\t\tpoisson_log_l = compute_masked_likelihood(info[\"log_lambda_y\"], truth_repeated, mask_repeated, f)\n",
        "\t\tpoisson_log_l = poisson_log_l.permute(1,0)\n",
        "\t\t# Take mean over n_traj\n",
        "\t\t#poisson_log_l = torch.mean(poisson_log_l, 1)\n",
        "\t\t\n",
        "\t# poisson_log_l shape: [n_traj_samples, n_traj]\n",
        "\treturn poisson_log_l\n",
        "\n",
        "\t\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enja7rcNbXpm"
      },
      "source": [
        "#### base_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CBGQIN2gb8dl"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "import lib.utils as utils\n",
        "\n",
        "# from lib.likelihood_eval import *\n",
        "\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.nn.modules.rnn import GRUCell, LSTMCell, RNNCellBase\n",
        "\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions import Independent\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "def create_classifier(z0_dim, n_labels):\n",
        "\treturn nn.Sequential(\n",
        "\t\t\tnn.Linear(z0_dim, 300),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(300, 300),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(300, n_labels),)\n",
        "\n",
        "class VAE_Baseline(nn.Module):\n",
        "\tdef __init__(self, input_dim, latent_dim, \n",
        "\t\tz0_prior, device,\n",
        "\t\tobsrv_std = 0.01, \n",
        "\t\tuse_binary_classif = False,\n",
        "\t\tclassif_per_tp = False,\n",
        "\t\tuse_poisson_proc = False,\n",
        "\t\tlinear_classifier = False,\n",
        "\t\tn_labels = 1,\n",
        "\t\ttrain_classif_w_reconstr = False):\n",
        "\n",
        "\t\tsuper(VAE_Baseline, self).__init__()\n",
        "\t\t\n",
        "\t\tself.input_dim = input_dim\n",
        "\t\tself.latent_dim = latent_dim\n",
        "\t\tself.device = device\n",
        "\t\tself.n_labels = n_labels\n",
        "\n",
        "\t\tself.obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "\n",
        "\t\tself.z0_prior = z0_prior\n",
        "\t\tself.use_binary_classif = use_binary_classif\n",
        "\t\tself.classif_per_tp = classif_per_tp\n",
        "\t\tself.use_poisson_proc = use_poisson_proc\n",
        "\t\tself.linear_classifier = linear_classifier\n",
        "\t\tself.train_classif_w_reconstr = train_classif_w_reconstr\n",
        "\n",
        "\t\tz0_dim = latent_dim\n",
        "\t\tif use_poisson_proc:\n",
        "\t\t\tz0_dim += latent_dim\n",
        "\n",
        "\t\tif use_binary_classif: \n",
        "\t\t\tif linear_classifier:\n",
        "\t\t\t\tself.classifier = nn.Sequential(\n",
        "\t\t\t\t\tnn.Linear(z0_dim, n_labels))\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.classifier = create_classifier(z0_dim, n_labels)\n",
        "\t\t\tutils.init_network_weights(self.classifier)\n",
        "\n",
        "\n",
        "\tdef get_gaussian_likelihood(self, truth, pred_y, mask = None):\n",
        "\t\t# pred_y shape [n_traj_samples, n_traj, n_tp, n_dim]\n",
        "\t\t# truth shape  [n_traj, n_tp, n_dim]\n",
        "\t\tn_traj, n_tp, n_dim = truth.size()\n",
        "\n",
        "\t\t# Compute likelihood of the data under the predictions\n",
        "\t\ttruth_repeated = truth.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\t\t\n",
        "\t\tif mask is not None:\n",
        "\t\t\tmask = mask.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\t\tlog_density_data = masked_gaussian_log_density(pred_y, truth_repeated, \n",
        "\t\t\tobsrv_std = self.obsrv_std, mask = mask)\n",
        "\t\tlog_density_data = log_density_data.permute(1,0)\n",
        "\t\tlog_density = torch.mean(log_density_data, 1)\n",
        "\n",
        "\t\t# shape: [n_traj_samples]\n",
        "\t\treturn log_density\n",
        "\n",
        "\n",
        "\tdef get_mse(self, truth, pred_y, mask = None):\n",
        "\t\t# pred_y shape [n_traj_samples, n_traj, n_tp, n_dim]\n",
        "\t\t# truth shape  [n_traj, n_tp, n_dim]\n",
        "\t\tn_traj, n_tp, n_dim = truth.size()\n",
        "\n",
        "\t\t# Compute likelihood of the data under the predictions\n",
        "\t\ttruth_repeated = truth.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\t\t\n",
        "\t\tif mask is not None:\n",
        "\t\t\tmask = mask.repeat(pred_y.size(0), 1, 1, 1)\n",
        "\n",
        "\t\t# Compute likelihood of the data under the predictions\n",
        "\t\tlog_density_data = compute_mse(pred_y, truth_repeated, mask = mask)\n",
        "\t\t# shape: [1]\n",
        "\t\treturn torch.mean(log_density_data)\n",
        "\n",
        "\n",
        "\tdef compute_all_losses(self, batch_dict, n_traj_samples = 1, kl_coef = 1.):\n",
        "\t\t# Condition on subsampled points\n",
        "\t\t# Make predictions for all the points\n",
        "\t\tpred_y, info = self.get_reconstruction(batch_dict[\"tp_to_predict\"], \n",
        "\t\t\tbatch_dict[\"observed_data\"], batch_dict[\"observed_tp\"], \n",
        "\t\t\tmask = batch_dict[\"observed_mask\"], n_traj_samples = n_traj_samples,\n",
        "\t\t\tmode = batch_dict[\"mode\"])\n",
        "\n",
        "\t\t#print(\"get_reconstruction done -- computing likelihood\")\n",
        "\t\tfp_mu, fp_std, fp_enc = info[\"first_point\"]\n",
        "\t\tfp_std = fp_std.abs()\n",
        "\t\tfp_distr = Normal(fp_mu, fp_std)\n",
        "\n",
        "\t\t# assert(torch.sum(fp_std < 0) == 0.)\n",
        "\n",
        "\t\tkldiv_z0 = kl_divergence(fp_distr, self.z0_prior)\n",
        "\n",
        "\t\tif torch.isnan(kldiv_z0).any():\n",
        "\t\t\tprint(fp_mu)\n",
        "\t\t\tprint(fp_std)\n",
        "\t\t\traise Exception(\"kldiv_z0 is Nan!\")\n",
        "\n",
        "\t\t# Mean over number of latent dimensions\n",
        "\t\t# kldiv_z0 shape: [n_traj_samples, n_traj, n_latent_dims] if prior is a mixture of gaussians (KL is estimated)\n",
        "\t\t# kldiv_z0 shape: [1, n_traj, n_latent_dims] if prior is a standard gaussian (KL is computed exactly)\n",
        "\t\t# shape after: [n_traj_samples]\n",
        "\t\tkldiv_z0 = torch.mean(kldiv_z0,(1,2))\n",
        "\n",
        "\t\t# Compute likelihood of all the points\n",
        "\t\trec_likelihood = self.get_gaussian_likelihood(\n",
        "\t\t\tbatch_dict[\"data_to_predict\"], pred_y,\n",
        "\t\t\tmask = batch_dict[\"mask_predicted_data\"])\n",
        "\n",
        "\t\tmse = self.get_mse(\n",
        "\t\t\tbatch_dict[\"data_to_predict\"], pred_y,\n",
        "\t\t\tmask = batch_dict[\"mask_predicted_data\"])\n",
        "\n",
        "\t\tpois_log_likelihood = torch.Tensor([0.]).to(get_device(batch_dict[\"data_to_predict\"]))\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tpois_log_likelihood = compute_poisson_proc_likelihood(\n",
        "\t\t\t\tbatch_dict[\"data_to_predict\"], pred_y, \n",
        "\t\t\t\tinfo, mask = batch_dict[\"mask_predicted_data\"])\n",
        "\t\t\t# Take mean over n_traj\n",
        "\t\t\tpois_log_likelihood = torch.mean(pois_log_likelihood, 1)\n",
        "\n",
        "\t\t################################\n",
        "\t\t# Compute CE loss for binary classification on Physionet\n",
        "\t\tdevice = get_device(batch_dict[\"data_to_predict\"])\n",
        "\t\tce_loss = torch.Tensor([0.]).to(device)\n",
        "\t\tif (batch_dict[\"labels\"] is not None) and self.use_binary_classif:\n",
        "\n",
        "\t\t\tif (batch_dict[\"labels\"].size(-1) == 1) or (len(batch_dict[\"labels\"].size()) == 1):\n",
        "\t\t\t\tce_loss = compute_binary_CE_loss(\n",
        "\t\t\t\t\tinfo[\"label_predictions\"], \n",
        "\t\t\t\t\tbatch_dict[\"labels\"])\n",
        "\t\t\telse:\n",
        "\t\t\t\tce_loss = compute_multiclass_CE_loss(\n",
        "\t\t\t\t\tinfo[\"label_predictions\"], \n",
        "\t\t\t\t\tbatch_dict[\"labels\"],\n",
        "\t\t\t\t\tmask = batch_dict[\"mask_predicted_data\"])\n",
        "\n",
        "\t\t# IWAE loss\n",
        "\t\tloss = - torch.logsumexp(rec_likelihood -  kl_coef * kldiv_z0,0)\n",
        "\t\tif torch.isnan(loss):\n",
        "\t\t\tloss = - torch.mean(rec_likelihood - kl_coef * kldiv_z0,0)\n",
        "\t\t\t\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tloss = loss - 0.1 * pois_log_likelihood \n",
        "\n",
        "\t\tif self.use_binary_classif:\n",
        "\t\t\tif self.train_classif_w_reconstr:\n",
        "\t\t\t\tloss = loss +  ce_loss * 100\n",
        "\t\t\telse:\n",
        "\t\t\t\tloss =  ce_loss\n",
        "\n",
        "\t\tresults = {}\n",
        "\t\tresults['pred_y'] = pred_y\n",
        "\t\tresults['true_y'] = batch_dict[\"data_to_predict\"]\n",
        "\t\tresults[\"loss\"] = torch.mean(loss)\n",
        "\t\tresults[\"likelihood\"] = torch.mean(rec_likelihood).detach()\n",
        "\t\tresults[\"mse\"] = torch.mean(mse).detach()\n",
        "\t\tresults[\"pois_likelihood\"] = torch.mean(pois_log_likelihood).detach()\n",
        "\t\tresults[\"ce_loss\"] = torch.mean(ce_loss).detach()\n",
        "\t\tresults[\"kl_first_p\"] =  torch.mean(kldiv_z0).detach()\n",
        "\t\tresults[\"std_first_p\"] = torch.mean(fp_std).detach()\n",
        "\n",
        "\t\tif batch_dict[\"labels\"] is not None and self.use_binary_classif:\n",
        "\t\t\tresults[\"label_predictions\"] = info[\"label_predictions\"].detach()\n",
        "\n",
        "\t\treturn results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt-zaGyLTo7l"
      },
      "source": [
        "#### latent_ode.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vdwYYTxqTr_m"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "#import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.utils import get_device\n",
        "# from lib.encoder_decoder import *\n",
        "# from lib.likelihood_eval import *\n",
        "\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions import kl_divergence, Independent\n",
        "# from lib.base_models import VAE_Baseline\n",
        "\n",
        "\n",
        "\n",
        "class LatentODE(VAE_Baseline):\n",
        "\tdef __init__(self, input_dim, latent_dim, encoder_z0, decoder, diffeq_solver, \n",
        "\t\tz0_prior, device, obsrv_std = None, \n",
        "\t\tuse_binary_classif = False, use_poisson_proc = False,\n",
        "\t\tlinear_classifier = False,\n",
        "\t\tclassif_per_tp = False,\n",
        "\t\tn_labels = 1,\n",
        "\t\ttrain_classif_w_reconstr = False):\n",
        "\n",
        "\t\tsuper(LatentODE, self).__init__(\n",
        "\t\t\tinput_dim = input_dim, latent_dim = latent_dim, \n",
        "\t\t\tz0_prior = z0_prior, \n",
        "\t\t\tdevice = device, obsrv_std = obsrv_std, \n",
        "\t\t\tuse_binary_classif = use_binary_classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp, \n",
        "\t\t\tlinear_classifier = linear_classifier,\n",
        "\t\t\tuse_poisson_proc = use_poisson_proc,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = train_classif_w_reconstr)\n",
        "\t\t\n",
        "\t\tprint(\"LatentODE: input_dim: {}, latent_dim: {}, use_binary_classif: {}, use_poisson_proc: {}\".format(input_dim, latent_dim, use_binary_classif, use_poisson_proc))\n",
        "\n",
        "\t\tself.encoder_z0 = encoder_z0\n",
        "\t\tself.diffeq_solver = diffeq_solver\n",
        "\t\tself.decoder = decoder\n",
        "\t\tself.use_poisson_proc = use_poisson_proc\n",
        "\n",
        "\tdef get_reconstruction(self, time_steps_to_predict, truth, truth_time_steps, \n",
        "\t\tmask = None, n_traj_samples = 1, run_backwards = True, mode = None):\n",
        "\n",
        "\t\tif isinstance(self.encoder_z0, Encoder_z0_ODE_RNN) or \\\n",
        "\t\t\tisinstance(self.encoder_z0, Encoder_z0_RNN):\n",
        "\n",
        "\t\t\ttruth_w_mask = truth\n",
        "\t\t\t# if mask is not None:\n",
        "    \t\t# \t\ttruth_w_mask = torch.cat((truth, mask), -1)\n",
        "\t\t\tfirst_point_mu, first_point_std = self.encoder_z0(\n",
        "\t\t\t\ttruth_w_mask, truth_time_steps, run_backwards = run_backwards)\n",
        "\n",
        "\t\t\tmeans_z0 = first_point_mu.repeat(n_traj_samples, 1, 1)\n",
        "\t\t\tsigma_z0 = first_point_std.repeat(n_traj_samples, 1, 1)\n",
        "\t\t\tfirst_point_enc = utils.sample_standard_gaussian(means_z0, sigma_z0)\n",
        "\n",
        "\t\telse:\n",
        "\t\t\traise Exception(\"Unknown encoder type {}\".format(type(self.encoder_z0).__name__))\n",
        "\t\t\n",
        "\t\tfirst_point_std = first_point_std.abs()\n",
        "\t\tassert(torch.sum(first_point_std < 0) == 0.)\n",
        "\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tn_traj_samples, n_traj, n_dims = first_point_enc.size()\n",
        "\t\t\t# append a vector of zeros to compute the integral of lambda\n",
        "\t\t\tzeros = torch.zeros([n_traj_samples, n_traj,self.input_dim]).to(get_device(truth))\n",
        "\t\t\tfirst_point_enc_aug = torch.cat((first_point_enc, zeros), -1)\n",
        "\t\t\tmeans_z0_aug = torch.cat((means_z0, zeros), -1)\n",
        "\t\telse:\n",
        "\t\t\tfirst_point_enc_aug = first_point_enc\n",
        "\t\t\tmeans_z0_aug = means_z0\n",
        "\t\t\t\n",
        "\t\tassert(not torch.isnan(time_steps_to_predict).any())\n",
        "\t\tassert(not torch.isnan(first_point_enc).any())\n",
        "\t\tassert(not torch.isnan(first_point_enc_aug).any())\n",
        "\n",
        "\t\t# Shape of sol_y [n_traj_samples, n_samples, n_timepoints, n_latents]\n",
        "\t\tsol_y = self.diffeq_solver(first_point_enc_aug, time_steps_to_predict)\n",
        "\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tsol_y, log_lambda_y, int_lambda, _ = self.diffeq_solver.ode_func.extract_poisson_rate(sol_y)\n",
        "\n",
        "\t\t\tassert(torch.sum(int_lambda[:,:,0,:]) == 0.)\n",
        "\t\t\tassert(torch.sum(int_lambda[0,0,-1,:] <= 0) == 0.)\n",
        "\n",
        "\t\tpred_x = self.decoder(sol_y)\n",
        "\n",
        "\t\tall_extra_info = {\n",
        "\t\t\t\"first_point\": (first_point_mu, first_point_std, first_point_enc),\n",
        "\t\t\t\"latent_traj\": sol_y.detach()\n",
        "\t\t}\n",
        "\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\t# intergral of lambda from the last step of ODE Solver\n",
        "\t\t\tall_extra_info[\"int_lambda\"] = int_lambda[:,:,-1,:]\n",
        "\t\t\tall_extra_info[\"log_lambda_y\"] = log_lambda_y\n",
        "\n",
        "\t\tif self.use_binary_classif:\n",
        "\t\t\tif self.classif_per_tp:\n",
        "\t\t\t\tall_extra_info[\"label_predictions\"] = self.classifier(sol_y)\n",
        "\t\t\telse:\n",
        "\t\t\t\tall_extra_info[\"label_predictions\"] = self.classifier(first_point_enc).squeeze(-1)\n",
        "\n",
        "\t\treturn pred_x, all_extra_info\n",
        "\n",
        "\n",
        "\tdef sample_traj_from_prior(self, time_steps_to_predict, n_traj_samples = 1):\n",
        "\t\t# input_dim = starting_point.size()[-1]\n",
        "\t\t# starting_point = starting_point.view(1,1,input_dim)\n",
        "\n",
        "\t\t# Sample z0 from prior\n",
        "\t\tstarting_point_enc = self.z0_prior.sample([n_traj_samples, 1, self.latent_dim]).squeeze(-1)\n",
        "\n",
        "\t\tstarting_point_enc_aug = starting_point_enc\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tn_traj_samples, n_traj, n_dims = starting_point_enc.size()\n",
        "\t\t\t# append a vector of zeros to compute the integral of lambda\n",
        "\t\t\tzeros = torch.zeros(n_traj_samples, n_traj,self.input_dim).to(self.device)\n",
        "\t\t\tstarting_point_enc_aug = torch.cat((starting_point_enc, zeros), -1)\n",
        "\n",
        "\t\tsol_y = self.diffeq_solver.sample_traj_from_prior(starting_point_enc_aug, time_steps_to_predict, \n",
        "\t\t\tn_traj_samples = 3)\n",
        "\n",
        "\t\tif self.use_poisson_proc:\n",
        "\t\t\tsol_y, log_lambda_y, int_lambda, _ = self.diffeq_solver.ode_func.extract_poisson_rate(sol_y)\n",
        "\t\t\n",
        "\t\treturn self.decoder(sol_y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJuMwP4_UbNd"
      },
      "source": [
        "#### ode_func.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bLibvdVLUew4"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.spectral_norm import spectral_norm\n",
        "\n",
        "import lib.utils as utils\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "class ODEFunc(nn.Module):\n",
        "\tdef __init__(self, input_dim, latent_dim, ode_func_net, device = torch.device(\"cpu\")):\n",
        "\t\t\"\"\"\n",
        "\t\tinput_dim: dimensionality of the input\n",
        "\t\tlatent_dim: dimensionality used for ODE. Analog of a continous latent state\n",
        "\t\t\"\"\"\n",
        "\t\tprint(f\"Inside ODEFunc class\")\n",
        "\t\tsuper(ODEFunc, self).__init__()\n",
        "\n",
        "\t\tself.input_dim = input_dim\n",
        "\t\tprint(f\"input_dim is {input_dim}\")\n",
        "\t\tprint(f\"latent_dim is {latent_dim}\")\n",
        "\t\tself.device = device\n",
        "\n",
        "\t\tutils.init_network_weights(ode_func_net)\n",
        "\t\tself.gradient_net = ode_func_net\n",
        "\n",
        "\tdef forward(self, t_local, y, backwards = False):\n",
        "\t\t\"\"\"\n",
        "\t\tPerform one step in solving ODE. Given current data point y and current time point t_local, returns gradient dy/dt at this time point\n",
        "\n",
        "\t\tt_local: current time point\n",
        "\t\ty: value at the current time point\n",
        "\t\t\"\"\"\n",
        "\t\tgrad = self.get_ode_gradient_nn(t_local, y)\n",
        "\t\tif backwards:\n",
        "\t\t\tgrad = -grad\n",
        "\t\treturn grad\n",
        "\n",
        "\tdef get_ode_gradient_nn(self, t_local, y):\n",
        "\t\treturn self.gradient_net(y)\n",
        "\n",
        "\tdef sample_next_point_from_prior(self, t_local, y):\n",
        "\t\t\"\"\"\n",
        "\t\tt_local: current time point\n",
        "\t\ty: value at the current time point\n",
        "\t\t\"\"\"\n",
        "\t\treturn self.get_ode_gradient_nn(t_local, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skmtjf_tVhSH"
      },
      "source": [
        "#### create_latent_ode_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "i1CtVTyEVol1"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# Latent ODEs for Irregularly-Sampled Time Series\n",
        "# Author: Yulia Rubanova\n",
        "###########################\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "import lib.utils as utils\n",
        "# from lib.latent_ode import LatentODE\n",
        "# from lib.encoder_decoder import *\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "\n",
        "from torch.distributions.normal import Normal\n",
        "# from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "def create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
        "\tclassif_per_tp = False, n_labels = 1):\n",
        "\n",
        "\tdim = args.latents\n",
        "\tprint(f\"Inside create_LatentODE_model\")\n",
        "\tprint(f\"dim is {dim}\")\n",
        "\tprint(\"\\n\")\n",
        "\tif args.poisson:\n",
        "\t\tlambda_net = utils.create_net(dim, input_dim, \n",
        "\t\t\tn_layers = 1, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\t# ODE function produces the gradient for latent state and for poisson rate\n",
        "\t\tode_func_net = utils.create_net(dim * 2, args.latents * 2, \n",
        "\t\t\tn_layers = args.gen_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\tgen_ode_func = ODEFunc_w_Poisson(\n",
        "\t\t\tinput_dim = input_dim, \n",
        "\t\t\tlatent_dim = args.latents * 2,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tlambda_net = lambda_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\telse:\n",
        "\t\tdim = args.latents\n",
        "\t\tprint(f\"Making ode_func_net\") \n",
        "\t\tode_func_net = utils.create_net(dim, args.latents, \n",
        "\t\t\tn_layers = args.gen_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\t\tprint(f\"Making gen_ode_func\")\n",
        "\n",
        "\t\tgen_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = input_dim, \n",
        "\t\t\tlatent_dim = args.latents, \n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\tz0_diffeq_solver = None\n",
        "\tn_rec_dims = args.rec_dims\n",
        "\tenc_input_dim = int(input_dim)  # we concatenate the mask\n",
        "\tgen_data_dim = 1\n",
        "\tprint(f\"gen_data_dim is {gen_data_dim}\")\n",
        "\n",
        "\tz0_dim = args.latents\n",
        "\tif args.poisson:\n",
        "\t\tz0_dim += args.latents # predict the initial poisson rate\n",
        "\n",
        "\tif args.z0_encoder == \"odernn\":\n",
        "\t\tprint(f\"Making ode_func_net for odernn\")\n",
        "\t\tode_func_net = utils.create_net(n_rec_dims, n_rec_dims, \n",
        "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\tprint(f\"Making rec_ode_func using ODEFunc\")\n",
        "\t\trec_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = enc_input_dim, \n",
        "\t\t\tlatent_dim = n_rec_dims,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\t\tz0_diffeq_solver = DiffeqSolver(enc_input_dim, rec_ode_func, \"euler\", args.latents, \n",
        "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\t\t\n",
        "\t\tencoder_z0 = Encoder_z0_ODE_RNN(n_rec_dims, enc_input_dim, z0_diffeq_solver, \n",
        "\t\t\tz0_dim = z0_dim, n_gru_units = args.gru_units, device = device).to(device)\n",
        "\n",
        "\telif args.z0_encoder == \"rnn\":\n",
        "\t\tencoder_z0 = Encoder_z0_RNN(z0_dim, enc_input_dim,\n",
        "\t\t\tlstm_output_size = n_rec_dims, device = device).to(device)\n",
        "\telse:\n",
        "\t\traise Exception(\"Unknown encoder for Latent ODE model: \" + args.z0_encoder)\n",
        "\n",
        "\tdecoder = Decoder(args.latents, gen_data_dim).to(device)\n",
        "\n",
        "\tdiffeq_solver = DiffeqSolver(gen_data_dim, gen_ode_func, 'dopri5', args.latents, \n",
        "\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\n",
        "\tmodel = LatentODE(\n",
        "\t\tinput_dim = gen_data_dim, \n",
        "\t\tlatent_dim = args.latents, \n",
        "\t\tencoder_z0 = encoder_z0, \n",
        "\t\tdecoder = decoder, \n",
        "\t\tdiffeq_solver = diffeq_solver, \n",
        "\t\tz0_prior = z0_prior, \n",
        "\t\tdevice = device,\n",
        "\t\tobsrv_std = obsrv_std,\n",
        "\t\tuse_poisson_proc = args.poisson, \n",
        "\t\tuse_binary_classif = args.classif,\n",
        "\t\tlinear_classifier = args.linear_classif,\n",
        "\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\tn_labels = n_labels,\n",
        "\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t).to(device)\n",
        "\n",
        "\treturn model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN78wf9Arg3w",
        "outputId": "e5cdc91c-4347-4030-d0e6-c121e037a1fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inside create_LatentODE_model\n",
            "dim is 6\n",
            "\n",
            "\n",
            "Making ode_func_net\n",
            "Inside create_net function\n",
            "n_input for layers is 6\n",
            "n_units for layers is 100\n",
            "n_layers is 1\n",
            "nonlinear is <class 'torch.nn.modules.activation.Tanh'>\n",
            "for i in range(n_layers):\n",
            "    layers.append(nonlinear())\n",
            "    layers.append(nn.Linear(n_units, n_units))\n",
            "layers.append(nonlinear())\n",
            "layers.append(nn.Linear(n_units, n_outputs))\n",
            "n_outputs is 6\n",
            "Making gen_ode_func\n",
            "Inside ODEFunc class\n",
            "input_dim is 10\n",
            "latent_dim is 6\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "gen_data_dim is 1\n",
            "Making ode_func_net for odernn\n",
            "Inside create_net function\n",
            "n_input for layers is 20\n",
            "n_units for layers is 100\n",
            "n_layers is 1\n",
            "nonlinear is <class 'torch.nn.modules.activation.Tanh'>\n",
            "for i in range(n_layers):\n",
            "    layers.append(nonlinear())\n",
            "    layers.append(nn.Linear(n_units, n_units))\n",
            "layers.append(nonlinear())\n",
            "layers.append(nn.Linear(n_units, n_outputs))\n",
            "n_outputs is 20\n",
            "Making rec_ode_func using ODEFunc\n",
            "Inside ODEFunc class\n",
            "input_dim is 10\n",
            "latent_dim is 20\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside DiffeqSolver\n",
            "Inside GRU unit\n",
            "\n",
            "\n",
            "self.update_gate = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "self.reset_gate = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "self.new_state_net = nn.Sequential( nn.Linear(latent_dim * 2 + input_dim, n_units), nn.Tanh(), nn.Linear(n_units, latent_dim), nn.Sigmoid())\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside init_network_weights function\n",
            "std is 0.1\n",
            "Inside DiffeqSolver\n",
            "LatentODE: input_dim: 1, latent_dim: 6, use_binary_classif: False, use_poisson_proc: False\n"
          ]
        }
      ],
      "source": [
        "if args.latent_ode:\n",
        "    model = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
        "        classif_per_tp = classif_per_tp,\n",
        "        n_labels = n_labels)\n",
        "else:\n",
        "\traise Exception(\"Model not specified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-4MgE2N9Va"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEQZ18scN_A-",
        "outputId": "c4cf44e7-9379-47bc-89f1-697d6386b081"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content\n",
            "-f\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimizer is Adamax (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.01\n",
            "    weight_decay: 0\n",
            ")\n",
            "num_batches is 389\n"
          ]
        }
      ],
      "source": [
        "file_name = os.path.abspath('')\n",
        "log_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
        "if not os.path.exists(\"logs/\"):\n",
        "    utils.makedirs(\"logs/\")\n",
        "logger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(''))\n",
        "logger.info(input_command)\n",
        "\n",
        "optimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
        "print(f\"optimizer is {optimizer}\")\n",
        "num_batches = data_obj[\"n_train_batches\"]\n",
        "print(f\"num_batches is {num_batches}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY3AHPpoZ6Ga",
        "outputId": "1641e987-4724-4be0-a65d-50b9a4b3afbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0072530675223532\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007245814454830846\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007238568640376015\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007231330071735639\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007224098741663904\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00721687464292224\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007209657768279317\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007202448110511038\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007195245662400527\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007188050416738126\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007180862366321388\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007173681503955066\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0071665078224511115\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00715934131462866\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0071521819733140314\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007145029791340718\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007137884761549377\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0071307468767878275\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0071236161299110395\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007116492513781128\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007109376021267347\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00710226664524608\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007095164378600834\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0070880692142222335\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007080981145008011\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007073900163863003\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00706682626369914\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007059759437435441\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007052699677998006\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0070456469783200075\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007038601331341688\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007031562730010346\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007024531167280336\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007017506636113055\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007010489129476942\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.007003478640347465\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006996475161707118\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00698947868654541\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006982489207858865\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006975506718651006\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006968531211932355\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006961562680720423\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0069546011180397025\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006947646516921663\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006940698870404741\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006933758171534336\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006926824413362802\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006919897588949439\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0069129776913604895\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006906064713669129\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0068991586489554595\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006892259490306504\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006885367230816198\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006878481863585382\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006871603381721796\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0068647317783400745\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006857867046561735\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006851009179515173\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006844158170335657\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006837314012165321\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006830476698153156\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006823646221455003\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006816822575233548\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006810005752658314\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006803195746905656\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006796392551158751\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006789596158607592\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006782806562448984\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.006776023755886535\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([32, 60])\n",
            "median_data.shape is torch.Size([32, 6])\n",
            "clone_data.shape is torch.Size([32, 6, 10])\n",
            "clone_median_data.shape is torch.Size([32, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([32, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 32, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 32, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "Computing loss... 0\n",
            "Inside inf_generator function\n",
            "data.shape is torch.Size([4859, 60])\n",
            "median_data.shape is torch.Size([4859, 6])\n",
            "clone_data.shape is torch.Size([4859, 6, 10])\n",
            "clone_median_data.shape is torch.Size([4859, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([4859, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Experiment 46595\n",
            "Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1890767232.000000 | Likelihood -1890767232.000000 | KL fp 301.9954 | FP STD 1.5072|\n",
            "KL coef: 0.0\n",
            "Train loss (one batch): 183904544.0\n",
            "Train CE loss (one batch): 0.0\n",
            "Test MSE: 3781.5347\n",
            "Poisson likelihood: 0.0\n",
            "CE loss: 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004914695783451435\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004909781087667983\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004904871306580316\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004899966435273735\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004895066468838461\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0048901714023696224\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004885281230967253\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004880395949736286\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00487551555378655\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004870640038232763\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00486576939819453\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004860903628796336\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004856042725167539\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004851186682442372\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00484633549575993\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00484148916026417\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004836647671103905\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004831811023432802\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004826979212409369\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00482215223319696\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0048173300809637625\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004812512750882798\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004807700238131916\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004802892537893784\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0047980896453558896\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004793291555710534\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004788498264154823\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004783709765890668\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004778926056124778\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004774147130068653\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004769372982938585\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004764603609955646\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0047598390063456905\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004755079167339345\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0047503240881720055\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004745573764083834\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00474082819031975\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0047360873621294305\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004731351274767301\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004726619923492534\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004721893303569041\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004717171410265472\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004712454238855206\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004707741784616351\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004703034042831735\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004698331008788903\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004693632677780114\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004688939045102334\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004684250106057232\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004679565855951175\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0046748862900952235\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004670211403805128\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004665541192401323\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004660875651208921\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004656214775557712\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004651558560782154\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004646907002221372\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004642260095219151\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004637617835123932\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004632980217288808\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004628347237071519\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004623718889834448\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004619095170944614\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004614476075773669\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.004609861599697895\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0046052517380981975\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0046006464863601\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00459604583987374\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0045914497940338665\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([32, 60])\n",
            "median_data.shape is torch.Size([32, 6])\n",
            "clone_data.shape is torch.Size([32, 6, 10])\n",
            "clone_median_data.shape is torch.Size([32, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([32, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 32, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 32, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "Computing loss... 0\n",
            "data.shape is torch.Size([4859, 60])\n",
            "median_data.shape is torch.Size([4859, 6])\n",
            "clone_data.shape is torch.Size([4859, 6, 10])\n",
            "clone_median_data.shape is torch.Size([4859, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([4859, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Experiment 46595\n",
            "Epoch 0002 [Test seq (cond on sampled tp)] | Loss 1856517120.000000 | Likelihood -1856517120.000000 | KL fp 354.8120 | FP STD 1.8834|\n",
            "KL coef: 0.0\n",
            "Train loss (one batch): 406027968.0\n",
            "Train CE loss (one batch): 0.0\n",
            "Test MSE: 3713.0352\n",
            "Poisson likelihood: 0.0\n",
            "CE loss: 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033302095381622333\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003326879328624071\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033235524492954472\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033202288968461518\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033169086679493056\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033135917592813564\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003310278167522075\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033069678893545527\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0033036609214651983\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003300357260543733\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032970569032831896\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032937598463799065\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032904660865335266\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003287175620446993\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032838884448265463\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032806045563817197\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003277323951825338\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003274046627873513\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003270772581245639\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032675018086643936\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003264234306855729\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032609700725488733\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032577091024763244\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003254451393373848\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003251196941980474\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032479457450384935\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003244697799293455\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032414531014941616\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032382116483926676\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003234973436744275\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032317384633075304\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032285067248442227\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032252782181193787\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032220529399012592\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003218830886961358\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032156120560743965\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032123964440183223\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032091840475743038\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0032059748635267296\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003202768888663203\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031995661197745397\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031963665536547652\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031931701871011106\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031899770169140093\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003186787039897095\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003183600252857198\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031804166526043405\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003177236235951736\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003174058999715784\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031708849407160685\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031677140557753525\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003164546341719577\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031613817953778573\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031582204135824797\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031550621931688973\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031519071309757283\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031487552238447527\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031456064686209077\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031424608621522868\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031393184012901347\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031361790828888444\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003133042903805956\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031299098609021496\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031267799510412476\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031236531710902063\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.003120529517919116\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031174089884011967\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031142915794127955\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0031111772878333827\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([32, 60])\n",
            "median_data.shape is torch.Size([32, 6])\n",
            "clone_data.shape is torch.Size([32, 6, 10])\n",
            "clone_median_data.shape is torch.Size([32, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([32, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "first_point.shape is torch.Size([1, 32, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 32, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 32, 20])\n",
            "new_y_std.shape is torch.Size([1, 32, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 32, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 32, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 32, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "Computing loss... 0\n",
            "data.shape is torch.Size([4859, 60])\n",
            "median_data.shape is torch.Size([4859, 6])\n",
            "clone_data.shape is torch.Size([4859, 6, 10])\n",
            "clone_median_data.shape is torch.Size([4859, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([4859, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "first_point.shape is torch.Size([1, 4859, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 4859, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 4859, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 4859, 20])\n",
            "new_y_std.shape is torch.Size([1, 4859, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 4859, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Experiment 46595\n",
            "Epoch 0003 [Test seq (cond on sampled tp)] | Loss 1157321728.000000 | Likelihood -1157321728.000000 | KL fp 186.3289 | FP STD 1.3046|\n",
            "KL coef: 0.0\n",
            "Train loss (one batch): 102907720.0\n",
            "Train CE loss (one batch): 0.0\n",
            "Test MSE: 2314.6436\n",
            "Poisson likelihood: 0.0\n",
            "CE loss: 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00251404907999559\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0025115350309155944\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002509023495884679\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002506514472388794\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002504007957916405\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0025015039499584886\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00249900244600853\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024965034435625215\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002494006940118959\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024915129331788397\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002489021420245661\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002486532398825415\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024840458664265896\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002481561820560163\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002479080258739603\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024766011784808635\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024741245773023824\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024716504527250802\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002469178802272355\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002466709623470083\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024642429138466127\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002461778670932766\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002459316892261833\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024568575753695712\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024544007177942015\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024519463170764072\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024494943707593308\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024470448763885713\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024445978315121826\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024421532336806706\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00243971108044699\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002437271369366543\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002434834097997176\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002432399263899179\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00242996686463528\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002427536897770645\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002425109360872874\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024226842515120014\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024202615672604894\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002417841305693229\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024154234643875357\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002413008040923148\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002410595032882225\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024081844378493426\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024057762534114933\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002403370477158082\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0024009671066809236\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023985661395742428\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023961675734346685\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023937714058612338\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023913776344553724\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002388986256820917\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002386597270564096\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002384210673293532\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002381826462620238\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002379444636157618\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023770651915214604\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002374688126329939\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002372313438203609\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023699411247654054\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.00236757118364064\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023652036124569994\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023628384088445423\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023604755704356977\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002358115094865262\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002355756979770397\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023534012227906264\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023510478215678357\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.002348696773746268\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "learning rate is 0.0023463480769725215\n",
            "kl_coef is 0.0\n",
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n"
          ]
        }
      ],
      "source": [
        "import lib.utils as utils\n",
        "for itr in range(1, num_batches * (args.niters + 1)):\n",
        "    optimizer.zero_grad()\n",
        "    utils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
        "    print(f\"learning rate is {optimizer.param_groups[0]['lr']}\")\n",
        "    wait_until_kl_inc = 10\n",
        "    if itr // num_batches < wait_until_kl_inc:\n",
        "        kl_coef = 0.\n",
        "    else:\n",
        "        kl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
        "    print(f\"kl_coef is {kl_coef}\")\n",
        "    batch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
        "    train_res = model.compute_all_losses(batch_dict, n_traj_samples = 1, kl_coef = kl_coef)\n",
        "    train_res[\"loss\"].backward()\n",
        "    optimizer.step()\n",
        "    n_iters_to_viz = 1\n",
        "\n",
        "    if itr % (n_iters_to_viz * num_batches) == 0:\n",
        "    \twith torch.no_grad():\n",
        "            test_res = compute_loss_all_batches(model, \n",
        "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
        "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
        "\t\t\t\t\texperimentID = experimentID,\n",
        "\t\t\t\t\tdevice = device,\n",
        "\t\t\t\t\tn_traj_samples = 1, kl_coef = kl_coef)\n",
        "            message = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
        "\t\t\t\t\titr//num_batches, \n",
        "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
        "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
        "            \n",
        "            logger.info(\"Experiment \" + str(experimentID))\n",
        "            logger.info(message)\n",
        "            logger.info(\"KL coef: {}\".format(kl_coef))\n",
        "            logger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
        "            logger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
        "\n",
        "            if \"auc\" in test_res:\n",
        "                logger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
        "\n",
        "            if \"mse\" in test_res:\n",
        "                logger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
        "\n",
        "            if \"accuracy\" in train_res:\n",
        "                logger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
        "\n",
        "            if \"accuracy\" in test_res:\n",
        "                logger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
        "\n",
        "            if \"pois_likelihood\" in test_res:\n",
        "                logger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
        "\n",
        "            if \"ce_loss\" in test_res:\n",
        "                logger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
        "\n",
        "\n",
        "            torch.save({\n",
        "\t\t\t\t'args': args,\n",
        "\t\t\t\t'state_dict': model.state_dict(),\n",
        "\t\t\t}, ckpt_path)\n",
        "    \n",
        "torch.save({\n",
        "    'args': args,\n",
        "    'state_dict': model.state_dict(),\n",
        "}, ckpt_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fFgGqNoSPVuC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_CyREmn--P"
      },
      "source": [
        "# Rough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsSduToXGvCf"
      },
      "outputs": [],
      "source": [
        "X = pd.read_csv(os.path.join('data', trainfile), index_col=0)\n",
        "y = pd.read_csv(os.path.join('data', medianfile), index_col=0)\n",
        "\n",
        "print(X.head())\n",
        "print(\"\\n\")\n",
        "print(y.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# result = pd.concat([X, y], axis=1, join='inner')\n",
        "# print(result.head())\n",
        "# data = torch.Tensor(X.values).to(device)\n",
        "# median_data = torch.Tensor(y.values).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 538,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FBSHueTGwZ2",
        "outputId": "883ef4d6-6235-4599-e8b8-eca621752a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24291"
            ]
          },
          "execution_count": 538,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = list(zip(X.values, y.values))\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybURGfxDG2CG",
        "outputId": "a957cb3f-87df-4814-efd9-f4688f259099"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19432"
            ]
          },
          "execution_count": 539,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_samples = len(data)\n",
        "len(data[:int(n_samples * 0.8)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 540,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "-ZDLg9FGQ04J",
        "outputId": "217b3f7e-c8db-4083-d33b-624e1a2de5b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using normalize_data()\n",
            "data.shape is (24291, 60)\n",
            "reshaped = data.reshape(-1, data.size(-1))\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-540-c919e14c6f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmedian_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_data_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_data_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedian_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"self.dataset.shape is {dataset.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/utils.py\u001b[0m in \u001b[0;36mnormalize_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using normalize_data()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data.shape is {data.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ],
      "source": [
        "data, data_min, data_max = utils.normalize_data(data)\n",
        "median_data, median_data_min, median_data_max = utils.normalize_data(median_data)\n",
        "dataset = torch.cat((data, median_data), dim=1)\n",
        "print(f\"self.dataset.shape is {dataset.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 541,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "rDw1X8-Eehu3",
        "outputId": "bd65c4df-14b5-4b1e-dcd9-924788c050bc"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-541-223310bc2512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ],
      "source": [
        "dataset[:, :int(60)].type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 542,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "eSVAZ59bel41",
        "outputId": "6e629b0c-37b0-4323-c6ed-d3c1b01c5801"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-542-05605063fb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"
          ]
        }
      ],
      "source": [
        "torch.stack(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XLqt9_9gBis",
        "outputId": "97d6d503-7a7f-4a4f-86b1-e08a8e1eafde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'data_to_predict': tensor([[[0.2281],\n",
              "          [0.2568],\n",
              "          [0.2712],\n",
              "          [0.3028],\n",
              "          [0.3268],\n",
              "          [0.3148]],\n",
              " \n",
              "         [[0.2568],\n",
              "          [0.2712],\n",
              "          [0.3028],\n",
              "          [0.3268],\n",
              "          [0.3148],\n",
              "          [0.2966]],\n",
              " \n",
              "         [[0.2712],\n",
              "          [0.3028],\n",
              "          [0.3268],\n",
              "          [0.3148],\n",
              "          [0.2966],\n",
              "          [0.2889]],\n",
              " \n",
              "         [[0.3028],\n",
              "          [0.3268],\n",
              "          [0.3148],\n",
              "          [0.2966],\n",
              "          [0.2889],\n",
              "          [0.2954]],\n",
              " \n",
              "         [[0.3268],\n",
              "          [0.3148],\n",
              "          [0.2966],\n",
              "          [0.2889],\n",
              "          [0.2954],\n",
              "          [0.3174]],\n",
              " \n",
              "         [[0.3148],\n",
              "          [0.2966],\n",
              "          [0.2889],\n",
              "          [0.2954],\n",
              "          [0.3174],\n",
              "          [0.3014]],\n",
              " \n",
              "         [[0.2966],\n",
              "          [0.2889],\n",
              "          [0.2954],\n",
              "          [0.3174],\n",
              "          [0.3014],\n",
              "          [0.3246]],\n",
              " \n",
              "         [[0.2889],\n",
              "          [0.2954],\n",
              "          [0.3174],\n",
              "          [0.3014],\n",
              "          [0.3246],\n",
              "          [0.3386]],\n",
              " \n",
              "         [[0.2954],\n",
              "          [0.3174],\n",
              "          [0.3014],\n",
              "          [0.3246],\n",
              "          [0.3386],\n",
              "          [0.3158]],\n",
              " \n",
              "         [[0.3174],\n",
              "          [0.3014],\n",
              "          [0.3246],\n",
              "          [0.3386],\n",
              "          [0.3158],\n",
              "          [0.3315]],\n",
              " \n",
              "         [[0.3014],\n",
              "          [0.3246],\n",
              "          [0.3386],\n",
              "          [0.3158],\n",
              "          [0.3315],\n",
              "          [0.3731]],\n",
              " \n",
              "         [[0.3246],\n",
              "          [0.3386],\n",
              "          [0.3158],\n",
              "          [0.3315],\n",
              "          [0.3731],\n",
              "          [0.3880]],\n",
              " \n",
              "         [[0.3386],\n",
              "          [0.3158],\n",
              "          [0.3315],\n",
              "          [0.3731],\n",
              "          [0.3880],\n",
              "          [0.3907]],\n",
              " \n",
              "         [[0.3158],\n",
              "          [0.3315],\n",
              "          [0.3731],\n",
              "          [0.3880],\n",
              "          [0.3907],\n",
              "          [0.3562]],\n",
              " \n",
              "         [[0.3315],\n",
              "          [0.3731],\n",
              "          [0.3880],\n",
              "          [0.3907],\n",
              "          [0.3562],\n",
              "          [0.3612]],\n",
              " \n",
              "         [[0.3731],\n",
              "          [0.3880],\n",
              "          [0.3907],\n",
              "          [0.3562],\n",
              "          [0.3612],\n",
              "          [0.3523]],\n",
              " \n",
              "         [[0.3880],\n",
              "          [0.3907],\n",
              "          [0.3562],\n",
              "          [0.3612],\n",
              "          [0.3523],\n",
              "          [0.3184]],\n",
              " \n",
              "         [[0.3907],\n",
              "          [0.3562],\n",
              "          [0.3612],\n",
              "          [0.3523],\n",
              "          [0.3184],\n",
              "          [0.3201]],\n",
              " \n",
              "         [[0.3562],\n",
              "          [0.3612],\n",
              "          [0.3523],\n",
              "          [0.3184],\n",
              "          [0.3201],\n",
              "          [0.3106]],\n",
              " \n",
              "         [[0.3612],\n",
              "          [0.3523],\n",
              "          [0.3184],\n",
              "          [0.3201],\n",
              "          [0.3106],\n",
              "          [0.3514]],\n",
              " \n",
              "         [[0.3523],\n",
              "          [0.3184],\n",
              "          [0.3201],\n",
              "          [0.3106],\n",
              "          [0.3514],\n",
              "          [0.3614]],\n",
              " \n",
              "         [[0.3184],\n",
              "          [0.3201],\n",
              "          [0.3106],\n",
              "          [0.3514],\n",
              "          [0.3614],\n",
              "          [0.3468]],\n",
              " \n",
              "         [[0.3201],\n",
              "          [0.3106],\n",
              "          [0.3514],\n",
              "          [0.3614],\n",
              "          [0.3468],\n",
              "          [0.3675]],\n",
              " \n",
              "         [[0.3106],\n",
              "          [0.3514],\n",
              "          [0.3614],\n",
              "          [0.3468],\n",
              "          [0.3675],\n",
              "          [0.2952]],\n",
              " \n",
              "         [[0.3514],\n",
              "          [0.3614],\n",
              "          [0.3468],\n",
              "          [0.3675],\n",
              "          [0.2952],\n",
              "          [0.2919]],\n",
              " \n",
              "         [[0.3614],\n",
              "          [0.3468],\n",
              "          [0.3675],\n",
              "          [0.2952],\n",
              "          [0.2919],\n",
              "          [0.2942]],\n",
              " \n",
              "         [[0.3468],\n",
              "          [0.3675],\n",
              "          [0.2952],\n",
              "          [0.2919],\n",
              "          [0.2942],\n",
              "          [0.2896]],\n",
              " \n",
              "         [[0.3675],\n",
              "          [0.2952],\n",
              "          [0.2919],\n",
              "          [0.2942],\n",
              "          [0.2896],\n",
              "          [0.2774]],\n",
              " \n",
              "         [[0.2952],\n",
              "          [0.2919],\n",
              "          [0.2942],\n",
              "          [0.2896],\n",
              "          [0.2774],\n",
              "          [0.2824]],\n",
              " \n",
              "         [[0.2919],\n",
              "          [0.2942],\n",
              "          [0.2896],\n",
              "          [0.2774],\n",
              "          [0.2824],\n",
              "          [0.2797]],\n",
              " \n",
              "         [[0.2942],\n",
              "          [0.2896],\n",
              "          [0.2774],\n",
              "          [0.2824],\n",
              "          [0.2797],\n",
              "          [0.2561]],\n",
              " \n",
              "         [[0.2896],\n",
              "          [0.2774],\n",
              "          [0.2824],\n",
              "          [0.2797],\n",
              "          [0.2561],\n",
              "          [0.2397]],\n",
              " \n",
              "         [[0.2774],\n",
              "          [0.2824],\n",
              "          [0.2797],\n",
              "          [0.2561],\n",
              "          [0.2397],\n",
              "          [0.2370]],\n",
              " \n",
              "         [[0.2824],\n",
              "          [0.2797],\n",
              "          [0.2561],\n",
              "          [0.2397],\n",
              "          [0.2370],\n",
              "          [0.2472]],\n",
              " \n",
              "         [[0.2797],\n",
              "          [0.2561],\n",
              "          [0.2397],\n",
              "          [0.2370],\n",
              "          [0.2472],\n",
              "          [0.2759]],\n",
              " \n",
              "         [[0.2561],\n",
              "          [0.2397],\n",
              "          [0.2370],\n",
              "          [0.2472],\n",
              "          [0.2759],\n",
              "          [0.2817]],\n",
              " \n",
              "         [[0.2397],\n",
              "          [0.2370],\n",
              "          [0.2472],\n",
              "          [0.2759],\n",
              "          [0.2817],\n",
              "          [0.2712]],\n",
              " \n",
              "         [[0.2370],\n",
              "          [0.2472],\n",
              "          [0.2759],\n",
              "          [0.2817],\n",
              "          [0.2712],\n",
              "          [0.2915]],\n",
              " \n",
              "         [[0.2472],\n",
              "          [0.2759],\n",
              "          [0.2817],\n",
              "          [0.2712],\n",
              "          [0.2915],\n",
              "          [0.2948]],\n",
              " \n",
              "         [[0.2759],\n",
              "          [0.2817],\n",
              "          [0.2712],\n",
              "          [0.2915],\n",
              "          [0.2948],\n",
              "          [0.3012]],\n",
              " \n",
              "         [[0.2817],\n",
              "          [0.2712],\n",
              "          [0.2915],\n",
              "          [0.2948],\n",
              "          [0.3012],\n",
              "          [0.3178]],\n",
              " \n",
              "         [[0.2712],\n",
              "          [0.2915],\n",
              "          [0.2948],\n",
              "          [0.3012],\n",
              "          [0.3178],\n",
              "          [0.3439]],\n",
              " \n",
              "         [[0.2915],\n",
              "          [0.2948],\n",
              "          [0.3012],\n",
              "          [0.3178],\n",
              "          [0.3439],\n",
              "          [0.3317]],\n",
              " \n",
              "         [[0.2948],\n",
              "          [0.3012],\n",
              "          [0.3178],\n",
              "          [0.3439],\n",
              "          [0.3317],\n",
              "          [0.3211]],\n",
              " \n",
              "         [[0.3012],\n",
              "          [0.3178],\n",
              "          [0.3439],\n",
              "          [0.3317],\n",
              "          [0.3211],\n",
              "          [0.3333]],\n",
              " \n",
              "         [[0.3178],\n",
              "          [0.3439],\n",
              "          [0.3317],\n",
              "          [0.3211],\n",
              "          [0.3333],\n",
              "          [0.3549]],\n",
              " \n",
              "         [[0.3439],\n",
              "          [0.3317],\n",
              "          [0.3211],\n",
              "          [0.3333],\n",
              "          [0.3549],\n",
              "          [0.3262]],\n",
              " \n",
              "         [[0.3317],\n",
              "          [0.3211],\n",
              "          [0.3333],\n",
              "          [0.3549],\n",
              "          [0.3262],\n",
              "          [0.3370]],\n",
              " \n",
              "         [[0.3211],\n",
              "          [0.3333],\n",
              "          [0.3549],\n",
              "          [0.3262],\n",
              "          [0.3370],\n",
              "          [0.3559]],\n",
              " \n",
              "         [[0.3333],\n",
              "          [0.3549],\n",
              "          [0.3262],\n",
              "          [0.3370],\n",
              "          [0.3559],\n",
              "          [0.3786]]]),\n",
              " 'labels': None,\n",
              " 'mask_predicted_data': None,\n",
              " 'mode': 'interp',\n",
              " 'observed_data': tensor([[[0.2204, 0.2271, 0.2252,  ..., 0.2511, 0.2781, 0.2616],\n",
              "          [0.2597, 0.2511, 0.2597,  ..., 0.2539, 0.2492, 0.2760],\n",
              "          [0.2741, 0.2635, 0.2674,  ..., 0.2865, 0.2980, 0.2990],\n",
              "          [0.2923, 0.2951, 0.2961,  ..., 0.3057, 0.2990, 0.2999],\n",
              "          [0.2999, 0.3325, 0.3306,  ..., 0.3239, 0.3239, 0.3162],\n",
              "          [0.3143, 0.3095, 0.3090,  ..., 0.3181, 0.3143, 0.2932]],\n",
              " \n",
              "         [[0.2597, 0.2511, 0.2597,  ..., 0.2539, 0.2492, 0.2760],\n",
              "          [0.2741, 0.2635, 0.2674,  ..., 0.2865, 0.2980, 0.2990],\n",
              "          [0.2923, 0.2951, 0.2961,  ..., 0.3057, 0.2990, 0.2999],\n",
              "          [0.2999, 0.3325, 0.3306,  ..., 0.3239, 0.3239, 0.3162],\n",
              "          [0.3143, 0.3095, 0.3090,  ..., 0.3181, 0.3143, 0.2932],\n",
              "          [0.2923, 0.3019, 0.3057,  ..., 0.3076, 0.2913, 0.2913]],\n",
              " \n",
              "         [[0.2741, 0.2635, 0.2674,  ..., 0.2865, 0.2980, 0.2990],\n",
              "          [0.2923, 0.2951, 0.2961,  ..., 0.3057, 0.2990, 0.2999],\n",
              "          [0.2999, 0.3325, 0.3306,  ..., 0.3239, 0.3239, 0.3162],\n",
              "          [0.3143, 0.3095, 0.3090,  ..., 0.3181, 0.3143, 0.2932],\n",
              "          [0.2923, 0.3019, 0.3057,  ..., 0.3076, 0.2913, 0.2913],\n",
              "          [0.2942, 0.2808, 0.2798,  ..., 0.2884, 0.2923, 0.2990]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.3418, 0.3456, 0.3476,  ..., 0.3220, 0.3178, 0.3126],\n",
              "          [0.3128, 0.3162, 0.3203,  ..., 0.3169, 0.3221, 0.3220],\n",
              "          [0.3204, 0.3275, 0.3273,  ..., 0.3439, 0.3451, 0.3358],\n",
              "          [0.3381, 0.3572, 0.3526,  ..., 0.3511, 0.3488, 0.3467],\n",
              "          [0.3496, 0.3319, 0.3254,  ..., 0.3243, 0.3269, 0.3327],\n",
              "          [0.3283, 0.3186, 0.3367,  ..., 0.3346, 0.3342, 0.3530]],\n",
              " \n",
              "         [[0.3128, 0.3162, 0.3203,  ..., 0.3169, 0.3221, 0.3220],\n",
              "          [0.3204, 0.3275, 0.3273,  ..., 0.3439, 0.3451, 0.3358],\n",
              "          [0.3381, 0.3572, 0.3526,  ..., 0.3511, 0.3488, 0.3467],\n",
              "          [0.3496, 0.3319, 0.3254,  ..., 0.3243, 0.3269, 0.3327],\n",
              "          [0.3283, 0.3186, 0.3367,  ..., 0.3346, 0.3342, 0.3530],\n",
              "          [0.3513, 0.3559, 0.3510,  ..., 0.3537, 0.3537, 0.3694]],\n",
              " \n",
              "         [[0.3204, 0.3275, 0.3273,  ..., 0.3439, 0.3451, 0.3358],\n",
              "          [0.3381, 0.3572, 0.3526,  ..., 0.3511, 0.3488, 0.3467],\n",
              "          [0.3496, 0.3319, 0.3254,  ..., 0.3243, 0.3269, 0.3327],\n",
              "          [0.3283, 0.3186, 0.3367,  ..., 0.3346, 0.3342, 0.3530],\n",
              "          [0.3513, 0.3559, 0.3510,  ..., 0.3537, 0.3537, 0.3694],\n",
              "          [0.3704, 0.3790, 0.3732,  ..., 0.3902, 0.3925, 0.3783]]]),\n",
              " 'observed_mask': None,\n",
              " 'observed_tp': tensor([0.0000, 0.1667, 0.3333, 0.5000, 0.6667, 0.8333]),\n",
              " 'tp_to_predict': tensor([0.0000, 0.1667, 0.3333, 0.5000, 0.6667, 0.8333])}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_obj[\"train_dataloader\"].__next__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtYvBrsaAOj1",
        "outputId": "3f094764-f2a5-4fca-e057-14243b86f338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([9, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 9, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "first_point.shape is torch.Size([1, 50, 20])\n",
            "pred_y.shape from odeint is torch.Size([10, 1, 50, 20])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 10, 20])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 20\n",
            "new_y.shape is torch.Size([1, 50, 20])\n",
            "new_y_std.shape is torch.Size([1, 50, 20])\n",
            "inside utils' split_last_dim function\n",
            "last_dim = data.size()[-1] is 6\n",
            "first_point.shape is torch.Size([1, 50, 6])\n",
            "pred_y.shape from odeint is torch.Size([6, 1, 50, 6])\n",
            "pred_y.shape after permute is torch.Size([1, 50, 6, 6])\n",
            "Should be shape: [n_traj_samples, n_traj, n_tp, n_dim]\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'ce_loss': tensor(0.),\n",
              " 'kl_first_p': tensor(1.3633),\n",
              " 'likelihood': tensor(-1140880.3750),\n",
              " 'loss': tensor(1140881.7500, grad_fn=<MeanBackward0>),\n",
              " 'mse': tensor(2.2818),\n",
              " 'pois_likelihood': tensor(0.),\n",
              " 'std_first_p': tensor(0.1712)}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compute_all_losses(data_obj[\"train_dataloader\"].__next__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Myjf_vpBYbqD",
        "outputId": "89a42bf1-f3c4-4c08-9830-c0948b15b3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.shape is torch.Size([50, 60])\n",
            "median_data.shape is torch.Size([50, 6])\n",
            "clone_data.shape is torch.Size([50, 6, 10])\n",
            "clone_median_data.shape is torch.Size([50, 6, 1])\n",
            "data_dict has keys as dict_keys(['observed_data', 'observed_tp', 'data_to_predict', 'tp_to_predict'])\n",
            "data_dict['observed_data'].shape is torch.Size([50, 6, 10])\n",
            "data_dict['mode'] is interp\n",
            "data_dict['observed_data'].size() is torch.Size([50, 6, 10])\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a1b5fcc3f089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_dataloader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/lib/utils.py\u001b[0m in \u001b[0;36mget_next_batch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# remove the time points where there are no observations in this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mnon_missing_tp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observed_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observed_data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observed_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_missing_tp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observed_tp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observed_tp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_missing_tp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [10] at index 0 does not match the shape of the indexed tensor [50, 6, 10] at index 1"
          ]
        }
      ],
      "source": [
        "utils.get_next_batch(data_obj[\"train_dataloader\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XosLIIlmlams"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "latentode_irregular_understanding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
